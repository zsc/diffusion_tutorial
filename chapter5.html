<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第5章：连续时间扩散模型 (PDE/SDE) - 扩散模型教程</title>
    <link rel="stylesheet" href="common.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
    <script src="common.js"></script>
</head>
<body>
    <div class="container">
        <div class="nav-bar">
            <a href="chapter4.html">← 上一章</a>
            <span>第5章 / 共14章</span>
            <a href="chapter6.html">下一章 →</a>
        </div>
        
        <h1>第5章：连续时间扩散模型 (PDE/SDE)</h1>
        
        <div class="chapter-intro">
            到目前为止，我们学习的扩散模型都是在离散时间步上定义的。但如果我们让时间步数趋于无穷，会发生什么？答案是：我们得到了随机微分方程（SDE）！Song等人在2021年的工作"Score-Based Generative Modeling through Stochastic Differential Equations"统一了之前的所有方法，并开启了连续时间建模的新纪元。本章将深入探讨SDE框架，以及相关的概率流ODE和Fokker-Planck方程。
        </div>

        <h2>5.1 从离散到连续：极限过程</h2>
        
        <h3>5.1.1 离散扩散过程的回顾</h3>
        
        <p>在前面的章节中，我们学习了离散时间的扩散模型。让我们回顾其核心结构，为理解连续时间做准备。</p>
        
        <h4>DDPM的前向过程</h4>
        
        <p>DDPM定义了一个马尔可夫链，逐步向数据添加噪声：</p>
        
        <div class="formula">
            $$q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)$$
        </div>
        
        <p>其中 $\beta_t$ 是预定义的噪声调度。通过重参数化技巧，我们可以直接从 $x_0$ 采样 $x_t$：</p>
        
        <div class="formula">
            $$x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1-\bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)$$
        </div>
        
        <p>其中 $\alpha_t = 1 - \beta_t$，$\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$。</p>
        
        <h4>关键观察：小步长近似</h4>
        
        <div class="note-box">
            <h4>离散步长的含义</h4>
            <p>当 $\beta_t$ 很小时，前向过程可以理解为：</p>
            <div class="formula">
                $$x_t = x_{t-1} - \frac{\beta_t}{2} x_{t-1} + \sqrt{\beta_t} z_{t-1}, \quad z_{t-1} \sim \mathcal{N}(0, I)$$
            </div>
            
            <p>这看起来像是一个离散化的方程：</p>
            <ul>
                <li>漂移项：$-\frac{\beta_t}{2} x_{t-1}$（向原点收缩）</li>
                <li>扩散项：$\sqrt{\beta_t} z_{t-1}$（添加随机性）</li>
            </ul>
        </div>
        
        <h4>Score-based模型的视角</h4>
        
        <p>在NCSN中，我们考虑不同噪声水平下的分布：</p>
        
        <div class="formula">
            $$p_\sigma(x) = \int p_{data}(x') \mathcal{N}(x; x', \sigma^2 I) dx'$$
        </div>
        
        <p>如果我们让 $\sigma$ 随时间连续变化，$\sigma(t)$，会发生什么？</p>
        
        <div class="example-box">
            <div class="example-title">离散与连续的对应</div>
            <table style="width: 100%; border-collapse: collapse; margin-top: 10px;">
                <tr style="background-color: #f0f0f0;">
                    <th style="border: 1px solid #ddd; padding: 8px;">离散时间</th>
                    <th style="border: 1px solid #ddd; padding: 8px;">连续时间</th>
                    <th style="border: 1px solid #ddd; padding: 8px;">含义</th>
                </tr>
                <tr>
                    <td style="border: 1px solid #ddd; padding: 8px;">$t \in \{0, 1, ..., T\}$</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">$t \in [0, T]$</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">时间变量</td>
                </tr>
                <tr>
                    <td style="border: 1px solid #ddd; padding: 8px;">$x_t - x_{t-1}$</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">$dx_t$</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">无穷小变化</td>
                </tr>
                <tr>
                    <td style="border: 1px solid #ddd; padding: 8px;">$\beta_t$</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">$\beta(t)dt$</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">噪声强度</td>
                </tr>
                <tr>
                    <td style="border: 1px solid #ddd; padding: 8px;">$z_t \sim \mathcal{N}(0, I)$</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">$dW_t$</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">布朗运动增量</td>
                </tr>
            </table>
        </div>
        
        <div class="code-block">
<pre># 可视化离散步长的影响
import torch
import numpy as np

def discrete_diffusion_path(x0, betas, return_all=True):
    """模拟离散扩散路径"""
    x = x0.clone()
    path = [x.clone()]
    
    for beta in betas:
        # 前向扩散步
        noise = torch.randn_like(x)
        x = np.sqrt(1 - beta) * x + np.sqrt(beta) * noise
        
        if return_all:
            path.append(x.clone())
    
    return torch.stack(path) if return_all else x

# 比较不同步数的路径
def compare_discretizations(x0, T=1.0, num_steps_list=[10, 50, 1000]):
    """比较不同离散化的效果"""
    paths = {}
    
    for num_steps in num_steps_list:
        # 线性噪声调度
        betas = torch.linspace(0.0001, 0.02, num_steps)
        
        # 调整到相同的总噪声量
        betas = betas * T / num_steps
        
        path = discrete_diffusion_path(x0, betas)
        paths[num_steps] = path
    
    # 分析路径的统计性质
    for num_steps, path in paths.items():
        final_mean = path[-1].mean()
        final_std = path[-1].std()
        print(f"步数={num_steps:4d}: 最终均值={final_mean:.3f}, 标准差={final_std:.3f}")
    
    return paths

# 演示
x0 = torch.randn(1000, 2)  # 1000个2D点
paths = compare_discretizations(x0)
print("\n观察：随着步数增加，离散路径趋于某个极限过程")</pre>
        </div>
        
        <h4>为什么需要连续时间？</h4>
        
        <div class="note-box">
            <h4>连续时间的优势</h4>
            <ol>
                <li><strong>理论优雅</strong>：可以使用强大的SDE理论工具</li>
                <li><strong>灵活采样</strong>：可以在任意时刻停止或评估</li>
                <li><strong>数值方法</strong>：可以使用高阶ODE/SDE求解器</li>
                <li><strong>统一框架</strong>：不同的离散模型成为同一SDE的不同离散化</li>
            </ol>
        </div>
        
        <h3>5.1.2 时间步趋于无穷的极限</h3>
        
        <p>现在让我们严格地推导当时间步数趋于无穷时会发生什么。这个过程揭示了SDE的自然出现。</p>
        
        <h4>极限过程的设置</h4>
        
        <p>考虑将时间区间 $[0, T]$ 分成 $N$ 份，每份长度 $\Delta t = T/N$。在离散设置中：</p>
        
        <div class="formula">
            $$x_{k+1} = \sqrt{1 - \beta_k} x_k + \sqrt{\beta_k} z_k, \quad z_k \sim \mathcal{N}(0, I)$$
        </div>
        
        <p>为了保持合理的扩散速度，我们需要让 $\beta_k = \tilde{\beta}(t_k) \Delta t$，其中 $\tilde{\beta}(t)$ 是连续函数。</p>
        
        <div class="theorem-box">
            <div class="theorem-title">关键洞察：Taylor展开</div>
            <p>当 $\Delta t \to 0$ 时，我们可以展开：</p>
            <div class="formula">
                $$\sqrt{1 - \tilde{\beta}(t)\Delta t} = 1 - \frac{\tilde{\beta}(t)}{2}\Delta t + O((\Delta t)^2)$$
            </div>
            
            <p>因此离散更新变为：</p>
            <div class="formula">
                $$x_{k+1} - x_k = -\frac{\tilde{\beta}(t_k)}{2} x_k \Delta t + \sqrt{\tilde{\beta}(t_k)\Delta t} z_k$$
            </div>
        </div>
        
        <h4>布朗运动的出现</h4>
        
        <p>关键观察：$\sqrt{\Delta t} z_k$ 在极限下收敛到布朗运动的增量！</p>
        
        <div class="note-box">
            <h4>从离散噪声到布朗运动</h4>
            <p>定义 $W_N(t) = \sum_{k=0}^{\lfloor t/\Delta t \rfloor} \sqrt{\Delta t} z_k$，则：</p>
            <ul>
                <li>$\mathbb{E}[W_N(t)] = 0$</li>
                <li>$\mathbb{E}[W_N(t)^2] = t$</li>
                <li>增量独立且正态分布</li>
            </ul>
            <p>根据Donsker定理，$W_N(t) \xrightarrow{d} W(t)$（标准布朗运动）。</p>
        </div>
        
        <h4>SDE的导出</h4>
        
        <p>取极限 $N \to \infty$（即 $\Delta t \to 0$），我们得到：</p>
        
        <div class="formula">
            $$dx_t = -\frac{\tilde{\beta}(t)}{2} x_t dt + \sqrt{\tilde{\beta}(t)} dW_t$$
        </div>
        
        <p>更一般地，我们可以写成：</p>
        
        <div class="formula">
            $$dx_t = f(x_t, t) dt + g(t) dW_t$$
        </div>
        
        <p>其中 $f(x_t, t) = -\frac{\tilde{\beta}(t)}{2} x_t$ 是漂移系数，$g(t) = \sqrt{\tilde{\beta}(t)}$ 是扩散系数。</p>
        
        <div class="example-box">
            <div class="example-title">具体例子：VP (Variance Preserving) SDE</div>
            <p>DDPM的连续时间极限给出VP-SDE：</p>
            <div class="formula">
                $$dx = -\frac{1}{2}\beta(t)x dt + \sqrt{\beta(t)} dW_t$$
            </div>
            
            <p>其中 $\beta(t)$ 是连续的噪声调度函数。常见选择：</p>
            <ul>
                <li>线性：$\beta(t) = \beta_{\min} + t(\beta_{\max} - \beta_{\min})$</li>
                <li>余弦：$\beta(t) = \pi \sin^2(\frac{t}{T} \cdot \frac{\pi}{2})$</li>
            </ul>
        </div>
        
        <div class="code-block">
<pre># 数值验证：离散过程收敛到SDE
import torch
import numpy as np
from scipy.stats import kstest

class DiscreteToSDE:
    """验证离散过程收敛到SDE的数值实验"""
    
    def __init__(self, beta_fn, T=1.0):
        self.beta_fn = beta_fn
        self.T = T
    
    def discrete_evolution(self, x0, N):
        """离散扩散过程"""
        dt = self.T / N
        x = x0.clone()
        
        for k in range(N):
            t = k * dt
            beta_dt = self.beta_fn(t) * dt
            
            # 离散更新
            noise = torch.randn_like(x)
            x = np.sqrt(1 - beta_dt) * x + np.sqrt(beta_dt) * noise
        
        return x
    
    def sde_solution(self, x0, t):
        """VP-SDE的解析解（当beta为常数时）"""
        # 对于一般的beta(t)，需要数值积分
        # 这里简化为常数情况
        beta_avg = self.beta_fn(self.T/2)  # 近似
        
        mean_factor = np.exp(-0.5 * beta_avg * t)
        var_factor = 1 - np.exp(-beta_avg * t)
        
        mean = mean_factor * x0
        std = np.sqrt(var_factor)
        
        return mean, std
    
    def test_convergence(self, x0, N_values=[10, 50, 100, 500, 1000]):
        """测试收敛性"""
        n_samples = 10000
        x0_batch = x0.repeat(n_samples, 1)
        
        results = {}
        
        for N in N_values:
            # 运行离散过程
            x_final = self.discrete_evolution(x0_batch, N)
            
            # 理论分布
            mean_theory, std_theory = self.sde_solution(x0, self.T)
            
            # 比较统计量
            mean_empirical = x_final.mean(dim=0)
            std_empirical = x_final.std(dim=0)
            
            # KS检验（对第一个维度）
            x_normalized = (x_final[:, 0] - mean_theory[0]) / std_theory
            ks_stat, p_value = kstest(x_normalized.numpy(), 'norm')
            
            results[N] = {
                'mean_error': torch.norm(mean_empirical - mean_theory).item(),
                'std_error': torch.norm(std_empirical - std_theory).item(),
                'ks_stat': ks_stat,
                'p_value': p_value
            }
        
        return results

# 运行实验
def demonstrate_convergence():
    # 定义beta函数
    beta_fn = lambda t: 0.1 + 10 * t  # 线性调度
    
    # 初始点
    x0 = torch.tensor([1.0, -0.5])
    
    # 测试收敛
    tester = DiscreteToSDE(beta_fn)
    results = tester.test_convergence(x0)
    
    print("离散过程 → SDE 收敛性分析")
    print("="*60)
    print(f"{'N':>6} | {'均值误差':>10} | {'标准差误差':>10} | {'KS统计量':>10} | {'p值':>10}")
    print("-"*60)
    
    for N, res in results.items():
        print(f"{N:6d} | {res['mean_error']:10.6f} | {res['std_error']:10.6f} | "
              f"{res['ks_stat']:10.6f} | {res['p_value']:10.6f}")
    
    print("\n结论：随着N增加，离散过程的分布收敛到SDE的理论分布")

demonstrate_convergence()</pre>
        </div>
        
        <h4>数学严格性</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">收敛定理（简化版）</div>
            <p>设离散过程 $\{X^N_k\}$ 由以下递归定义：</p>
            <div class="formula">
                $$X^N_{k+1} = X^N_k + f(X^N_k, t_k)\Delta t + g(t_k)\sqrt{\Delta t} Z_k$$
            </div>
            
            <p>在适当的正则性条件下（Lipschitz连续性等），当 $N \to \infty$ 时：</p>
            <div class="formula">
                $$X^N_{\lfloor t/\Delta t \rfloor} \xrightarrow{d} X_t$$
            </div>
            
            <p>其中 $X_t$ 是SDE的解：$dX_t = f(X_t, t)dt + g(t)dW_t$。</p>
        </div>
        
        <h3>5.1.3 SDE的直观理解</h3>
        
        <p>随机微分方程（SDE）初看起来可能很抽象，但它描述的是一个非常自然的现象：带有随机扰动的动力系统。让我们通过多个角度来建立直观理解。</p>
        
        <h4>粒子运动的视角</h4>
        
        <div class="note-box">
            <h4>布朗运动的发现</h4>
            <p>1827年，植物学家Robert Brown观察到花粉在水中的无规则运动。Einstein在1905年解释了这一现象：</p>
            <ul>
                <li>花粉受到水分子的随机碰撞</li>
                <li>宏观运动 = 确定性漂移 + 随机扰动</li>
                <li>这正是SDE描述的内容！</li>
            </ul>
        </div>
        
        <p>SDE的一般形式 $dx_t = f(x_t, t)dt + g(t)dW_t$ 可以理解为：</p>
        
        <div class="example-box">
            <div class="example-title">物理类比</div>
            <table style="width: 100%; border-collapse: collapse; margin-top: 10px;">
                <tr style="background-color: #f0f0f0;">
                    <th style="border: 1px solid #ddd; padding: 8px;">SDE项</th>
                    <th style="border: 1px solid #ddd; padding: 8px;">物理含义</th>
                    <th style="border: 1px solid #ddd; padding: 8px;">在扩散模型中</th>
                </tr>
                <tr>
                    <td style="border: 1px solid #ddd; padding: 8px;">$f(x_t, t)dt$</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">确定性力（如重力、摩擦）</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">向噪声分布的漂移</td>
                </tr>
                <tr>
                    <td style="border: 1px solid #ddd; padding: 8px;">$g(t)dW_t$</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">随机碰撞（热运动）</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">注入的高斯噪声</td>
                </tr>
                <tr>
                    <td style="border: 1px solid #ddd; padding: 8px;">$x_t$</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">粒子位置</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">数据点的状态</td>
                </tr>
            </table>
        </div>
        
        <h4>信号处理的视角</h4>
        
        <p>在信号处理中，SDE描述了信号如何被噪声逐渐破坏：</p>
        
        <div class="formula">
            $$\text{带噪信号}(t) = \text{衰减} \cdot \text{原始信号}(t) + \text{累积噪声}(t)$$
        </div>
        
        <p>这正对应于扩散模型的前向过程：清晰图像逐渐变成噪声。</p>
        
        <h4>概率演化的视角</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">从点到分布</div>
            <p>SDE不仅描述单个粒子的轨迹，更重要的是描述概率分布的演化：</p>
            <ul>
                <li>$x_0$ 开始是一个确定的点（或某个初始分布）</li>
                <li>随着时间推移，不确定性增加</li>
                <li>$p(x_t|x_0)$ 变得越来越分散</li>
                <li>最终收敛到某个稳态分布（如标准正态）</li>
            </ul>
        </div>
        
        <div class="code-block">
<pre># 可视化SDE的直观含义
import torch
import numpy as np

class SDEVisualization:
    """通过模拟展示SDE的不同方面"""
    
    def __init__(self, drift_fn, diffusion_fn):
        """
        Args:
            drift_fn: f(x, t) - 漂移函数
            diffusion_fn: g(t) - 扩散系数函数
        """
        self.f = drift_fn
        self.g = diffusion_fn
    
    def simulate_paths(self, x0, T, dt=0.01, n_paths=100):
        """模拟多条SDE路径"""
        n_steps = int(T / dt)
        paths = torch.zeros(n_paths, n_steps + 1, x0.shape[-1])
        paths[:, 0] = x0
        
        for i in range(n_steps):
            t = i * dt
            x = paths[:, i]
            
            # Euler-Maruyama方法
            drift = self.f(x, t) * dt
            diffusion = self.g(t) * np.sqrt(dt) * torch.randn_like(x)
            
            paths[:, i + 1] = x + drift + diffusion
        
        return paths
    
    def analyze_distribution_evolution(self, x0, T, checkpoints=[0.1, 0.5, 1.0, 2.0]):
        """分析分布随时间的演化"""
        print("分布演化分析")
        print("="*50)
        
        for t in checkpoints:
            if t > T:
                continue
                
            # 模拟到时刻t
            paths = self.simulate_paths(x0, t, n_paths=10000)
            final_x = paths[:, -1]
            
            # 统计量
            mean = final_x.mean(dim=0)
            std = final_x.std(dim=0)
            
            print(f"t = {t:.1f}:")
            print(f"  均值: {mean.numpy()}")
            print(f"  标准差: {std.numpy()}")
            print(f"  数据范围: [{final_x.min():.2f}, {final_x.max():.2f}]")
            print()

# 示例1：Ornstein-Uhlenbeck过程（均值回归）
def ou_drift(x, t, theta=1.0, mu=0.0):
    """OU过程的漂移：回归到均值mu"""
    return theta * (mu - x)

def constant_diffusion(t, sigma=1.0):
    """常数扩散系数"""
    return sigma

print("示例1: Ornstein-Uhlenbeck过程（金融中的均值回归模型）")
print("-"*50)
ou_sde = SDEVisualization(ou_drift, constant_diffusion)
x0 = torch.tensor([5.0])  # 从远离均值的点开始
ou_sde.analyze_distribution_evolution(x0, T=5.0)

# 示例2：扩散模型的VP-SDE
def vp_drift(x, t, beta_min=0.1, beta_max=20.0):
    """VP-SDE的漂移"""
    beta_t = beta_min + t * (beta_max - beta_min)
    return -0.5 * beta_t * x

def vp_diffusion(t, beta_min=0.1, beta_max=20.0):
    """VP-SDE的扩散系数"""
    beta_t = beta_min + t * (beta_max - beta_min)
    return np.sqrt(beta_t)

print("\n示例2: VP-SDE（扩散模型）")
print("-"*50)
vp_sde = SDEVisualization(vp_drift, vp_diffusion)
x0 = torch.randn(2)  # 2D随机初始点
vp_sde.analyze_distribution_evolution(x0, T=1.0)</pre>
        </div>
        
        <h4>几何视角：流形上的随机游走</h4>
        
        <p>在高维空间中，SDE可以理解为数据流形上的随机游走：</p>
        
        <div class="note-box">
            <h4>数据流形的破坏与重建</h4>
            <ol>
                <li><strong>前向SDE</strong>：将数据从低维流形"推离"到整个高维空间</li>
                <li><strong>反向SDE</strong>：学习如何将散布的点"拉回"到原始流形</li>
                <li><strong>分数函数</strong>：在每个点指示回到流形的方向</li>
            </ol>
        </div>
        
        <h4>控制论视角：噪声作为正则化</h4>
        
        <div class="example-box">
            <div class="example-title">为什么要加噪声？</div>
            <p>添加噪声看似是破坏信息，但实际上有多个好处：</p>
            <ul>
                <li><strong>覆盖支撑集</strong>：确保模型见过所有可能的输入</li>
                <li><strong>平滑优化景观</strong>：避免分数函数的奇异性</li>
                <li><strong>连接数据点</strong>：在数据点之间建立概率路径</li>
                <li><strong>隐式正则化</strong>：防止模型记忆训练数据</li>
            </ul>
        </div>
        
        <h4>信息论视角：熵的增加与减少</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">熵的演化</div>
            <p>前向SDE增加熵（不确定性），反向SDE减少熵：</p>
            <div class="formula">
                $$H[p_t] = H[p_0] + \int_0^t \mathbb{E}_{p_s}\left[\frac{|g(s)|^2}{2}\right] ds$$
            </div>
            <p>这解释了为什么：</p>
            <ul>
                <li>前向过程最终收敛到最大熵分布（高斯分布）</li>
                <li>反向过程需要学习分数函数来"注入"信息</li>
            </ul>
        </div>
        
        <div class="code-block">
<pre># 演示信息论视角
def entropy_evolution_demo():
    """展示熵随时间的变化"""
    import torch.distributions as dist
    
    # 初始分布：混合高斯（低熵）
    mix_weights = torch.tensor([0.3, 0.7])
    components = [
        dist.Normal(-2.0, 0.5),
        dist.Normal(2.0, 0.5)
    ]
    
    def estimate_entropy(samples):
        """估计样本的差分熵（使用KDE）"""
        # 简化：使用高斯核密度估计
        n = len(samples)
        h = 1.06 * samples.std() * (n ** (-1/5))  # Silverman's rule
        
        # 计算每个点的密度
        densities = []
        for x in samples[:100]:  # 子采样以加速
            kde = torch.exp(-0.5 * ((samples - x) / h) ** 2) / (h * np.sqrt(2 * np.pi))
            density = kde.mean()
            densities.append(density)
        
        # 熵 = -E[log p(x)]
        log_densities = torch.log(torch.tensor(densities) + 1e-10)
        entropy = -log_densities.mean()
        return entropy.item()
    
    # 模拟扩散过程
    t_values = [0, 0.1, 0.5, 1.0, 2.0]
    n_samples = 5000
    
    print("熵的演化（扩散过程）")
    print("="*40)
    
    for t in t_values:
        # 采样初始分布
        component_idx = torch.multinomial(mix_weights, n_samples, replacement=True)
        samples = torch.zeros(n_samples)
        for i, comp in enumerate(components):
            mask = component_idx == i
            samples[mask] = comp.sample((mask.sum(),))
        
        # 应用扩散（简化：直接加噪声）
        noise_scale = np.sqrt(1 - np.exp(-t))  # 对应VP-SDE
        signal_scale = np.exp(-t/2)
        
        diffused_samples = signal_scale * samples + noise_scale * torch.randn_like(samples)
        
        # 估计熵
        entropy = estimate_entropy(diffused_samples)
        
        # 理论最大熵（标准正态分布）
        max_entropy = 0.5 * np.log(2 * np.pi * np.e)
        
        print(f"t = {t:.1f}: 熵 ≈ {entropy:.3f} (最大熵 = {max_entropy:.3f})")
    
    print("\n观察：熵单调增加，趋向于高斯分布的最大熵")

entropy_evolution_demo()</pre>
        </div>
        
        <h4>实践指南：选择SDE的艺术</h4>
        
        <div class="note-box">
            <h4>不同SDE的特点</h4>
            <table style="width: 100%; border-collapse: collapse; margin-top: 10px;">
                <tr style="background-color: #f0f0f0;">
                    <th style="border: 1px solid #ddd; padding: 8px;">SDE类型</th>
                    <th style="border: 1px solid #ddd; padding: 8px;">特点</th>
                    <th style="border: 1px solid #ddd; padding: 8px;">适用场景</th>
                </tr>
                <tr>
                    <td style="border: 1px solid #ddd; padding: 8px;">VP-SDE</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">方差保持，信号逐渐衰减</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">图像生成（DDPM类）</td>
                </tr>
                <tr>
                    <td style="border: 1px solid #ddd; padding: 8px;">VE-SDE</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">方差爆炸，信号保持</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">分数匹配（NCSN类）</td>
                </tr>
                <tr>
                    <td style="border: 1px solid #ddd; padding: 8px;">sub-VP-SDE</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">介于两者之间</td>
                    <td style="border: 1px solid #ddd; padding: 8px;">通用框架</td>
                </tr>
            </table>
        </div>

        <h2>5.2 前向SDE：连续时间的扩散过程</h2>
        
        <h3>5.2.1 SDE的一般形式</h3>
        
        <p>现在让我们系统地研究用于扩散模型的SDE。我们将看到，不同的SDE选择对应于不同的离散扩散模型。</p>
        
        <h4>扩散SDE的标准形式</h4>
        
        <p>用于生成建模的前向SDE通常具有以下形式：</p>
        
        <div class="formula">
            $$dx = f(x, t) dt + g(t) dW_t$$
        </div>
        
        <p>其中：</p>
        <ul>
            <li>$x \in \mathbb{R}^d$ 是状态变量（如图像）</li>
            <li>$f: \mathbb{R}^d \times [0, T] \to \mathbb{R}^d$ 是漂移系数</li>
            <li>$g: [0, T] \to \mathbb{R}$ 是扩散系数（标量函数）</li>
            <li>$W_t$ 是标准布朗运动</li>
        </ul>
        
        <div class="note-box">
            <h4>为什么g(t)是标量？</h4>
            <p>在大多数扩散模型中，我们假设噪声在各个维度上是独立同分布的。这简化了理论分析和实际实现。更一般的情况下，$g(t)$ 可以是矩阵值函数。</p>
        </div>
        
        <h4>边缘分布的演化</h4>
        
        <p>给定初始分布 $p_0(x) = p_{data}(x)$，SDE诱导了一个时变的边缘分布 $p_t(x)$。我们希望：</p>
        
        <div class="theorem-box">
            <div class="theorem-title">设计目标</div>
            <ol>
                <li><strong>覆盖数据分布</strong>：$p_0(x) = p_{data}(x)$</li>
                <li><strong>收敛到已知分布</strong>：$p_T(x) \approx \pi(x)$，其中 $\pi$ 是易于采样的先验分布</li>
                <li><strong>平滑过渡</strong>：$p_t$ 随 $t$ 连续变化</li>
                <li><strong>可逆性</strong>：存在反向SDE从 $p_T$ 回到 $p_0$</li>
            </ol>
        </div>
        
        <h4>三种经典SDE家族</h4>
        
        <p>Song等人(2021)总结了三种主要的SDE家族：</p>
        
        <div class="example-box">
            <div class="example-title">1. Variance Exploding (VE) SDE</div>
            <div class="formula">
                $$dx = \sqrt{\frac{d[\sigma^2(t)]}{dt}} dW_t$$
            </div>
            <p>特点：</p>
            <ul>
                <li>没有漂移项（$f(x,t) = 0$）</li>
                <li>方差随时间增加：$\mathbb{E}[||x_t||^2] = ||x_0||^2 + \sigma^2(t)$</li>
                <li>对应于NCSN中的噪声注入过程</li>
            </ul>
        </div>
        
        <div class="example-box">
            <div class="example-title">2. Variance Preserving (VP) SDE</div>
            <div class="formula">
                $$dx = -\frac{1}{2}\beta(t)x dt + \sqrt{\beta(t)} dW_t$$
            </div>
            <p>特点：</p>
            <ul>
                <li>线性漂移项使信号衰减</li>
                <li>在适当的 $\beta(t)$ 下，方差保持接近常数</li>
                <li>对应于DDPM的连续时间扩展</li>
            </ul>
        </div>
        
        <div class="example-box">
            <div class="example-title">3. Sub-VP SDE</div>
            <div class="formula">
                $$dx = -\frac{1}{2}\beta(t)x dt + \sqrt{\beta(t)(1-e^{-2\int_0^t \beta(s)ds})} dW_t$$
            </div>
            <p>特点：</p>
            <ul>
                <li>漂移项与VP-SDE相同</li>
                <li>扩散系数被调整以确保良好的收敛性质</li>
                <li>提供更灵活的框架</li>
            </ul>
        </div>
        
        <div class="code-block">
<pre># 实现三种SDE家族
import torch
import numpy as np
from abc import ABC, abstractmethod

class SDE(ABC):
    """SDE基类"""
    
    def __init__(self, T=1.0):
        self.T = T
    
    @abstractmethod
    def drift(self, x, t):
        """漂移系数 f(x,t)"""
        pass
    
    @abstractmethod
    def diffusion(self, t):
        """扩散系数 g(t)"""
        pass
    
    @abstractmethod
    def marginal_prob(self, x0, t):
        """边缘分布 p(x_t|x_0) 的均值和标准差"""
        pass
    
    def sample_trajectory(self, x0, n_steps=1000):
        """使用Euler-Maruyama方法采样轨迹"""
        dt = self.T / n_steps
        trajectory = [x0]
        x = x0.clone()
        
        for i in range(n_steps):
            t = i * dt
            drift = self.drift(x, t) * dt
            diffusion = self.diffusion(t) * np.sqrt(dt) * torch.randn_like(x)
            x = x + drift + diffusion
            trajectory.append(x.clone())
        
        return torch.stack(trajectory)

class VESDE(SDE):
    """Variance Exploding SDE"""
    
    def __init__(self, sigma_min=0.01, sigma_max=50.0, T=1.0):
        super().__init__(T)
        self.sigma_min = sigma_min
        self.sigma_max = sigma_max
    
    def sigma(self, t):
        """噪声调度函数"""
        return self.sigma_min * (self.sigma_max / self.sigma_min) ** (t / self.T)
    
    def drift(self, x, t):
        return torch.zeros_like(x)
    
    def diffusion(self, t):
        sigma_t = self.sigma(t)
        # d\sigma^2/dt = 2\sigma d\sigma/dt
        return sigma_t * np.sqrt(2 * np.log(self.sigma_max / self.sigma_min) / self.T)
    
    def marginal_prob(self, x0, t):
        sigma_t = self.sigma(t)
        mean = x0
        std = sigma_t
        return mean, std

class VPSDE(SDE):
    """Variance Preserving SDE"""
    
    def __init__(self, beta_min=0.1, beta_max=20.0, T=1.0):
        super().__init__(T)
        self.beta_min = beta_min
        self.beta_max = beta_max
    
    def beta(self, t):
        """线性噪声调度"""
        return self.beta_min + (self.beta_max - self.beta_min) * t / self.T
    
    def drift(self, x, t):
        return -0.5 * self.beta(t) * x
    
    def diffusion(self, t):
        return np.sqrt(self.beta(t))
    
    def marginal_prob(self, x0, t):
        # 线性SDE的解析解
        log_mean_coeff = -0.25 * t**2 * (self.beta_max - self.beta_min) / self.T - 0.5 * t * self.beta_min
        mean = torch.exp(log_mean_coeff) * x0
        std = torch.sqrt(1 - torch.exp(2 * log_mean_coeff))
        return mean, std

class SubVPSDE(SDE):
    """Sub-VP SDE"""
    
    def __init__(self, beta_min=0.1, beta_max=20.0, T=1.0):
        super().__init__(T)
        self.beta_min = beta_min
        self.beta_max = beta_max
    
    def beta(self, t):
        return self.beta_min + (self.beta_max - self.beta_min) * t / self.T
    
    def drift(self, x, t):
        return -0.5 * self.beta(t) * x
    
    def diffusion(self, t):
        # 简化：使用近似积分
        integral = 0.5 * t**2 * (self.beta_max - self.beta_min) / self.T + t * self.beta_min
        return np.sqrt(self.beta(t) * (1 - np.exp(-2 * integral)))
    
    def marginal_prob(self, x0, t):
        # 与VP-SDE相同的边缘均值
        log_mean_coeff = -0.25 * t**2 * (self.beta_max - self.beta_min) / self.T - 0.5 * t * self.beta_min
        mean = torch.exp(log_mean_coeff) * x0
        # 但标准差不同
        integral = 0.5 * t**2 * (self.beta_max - self.beta_min) / self.T + t * self.beta_min
        std = torch.sqrt(1 - torch.exp(-integral))
        return mean, std

# 比较不同SDE的性质
def compare_sdes():
    """比较三种SDE的边缘分布"""
    x0 = torch.randn(2)  # 2D初始点
    
    sdes = {
        'VE-SDE': VESDE(),
        'VP-SDE': VPSDE(),
        'Sub-VP': SubVPSDE()
    }
    
    t_values = torch.linspace(0, 1.0, 5)
    
    print("不同SDE的边缘分布演化")
    print("="*70)
    print(f"{'SDE类型':^10} | {'t':^5} | {'均值范数':^12} | {'标准差':^12} | {'信噪比':^12}")
    print("-"*70)
    
    for name, sde in sdes.items():
        for t in t_values:
            mean, std = sde.marginal_prob(x0, t)
            mean_norm = torch.norm(mean)
            snr = mean_norm / (std + 1e-8)  # 信噪比
            
            print(f"{name:^10} | {t:5.2f} | {mean_norm:12.6f} | {std:12.6f} | {snr:12.6f}")
        print("-"*70)

compare_sdes()</pre>
        </div>
        
        <h4>从ODE视角理解SDE</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">确定性 vs 随机性</div>
            <p>SDE可以看作是ODE加上随机扰动：</p>
            <div class="formula">
                $$\underbrace{dx = f(x,t)dt}_{\text{ODE部分}} + \underbrace{g(t)dW_t}_{\text{随机扰动}}$$
            </div>
            
            <p>这种分解有助于：</p>
            <ul>
                <li>理解概率流ODE（去除随机项后的确定性动力学）</li>
                <li>设计数值求解器（借鉴ODE方法）</li>
                <li>分析稳定性和收敛性</li>
            </ul>
        </div>
        
        <h4>选择SDE的实用指南</h4>
        
        <div class="note-box">
            <h4>如何选择适合的SDE？</h4>
            <ol>
                <li><strong>VE-SDE</strong>：
                    <ul>
                        <li>适合高分辨率图像</li>
                        <li>保留原始信号结构</li>
                        <li>但最终分布难以控制</li>
                    </ul>
                </li>
                <li><strong>VP-SDE</strong>：
                    <ul>
                        <li>最终收敛到标准正态</li>
                        <li>理论分析更简单</li>
                        <li>与DDPM兼容</li>
                    </ul>
                </li>
                <li><strong>Sub-VP-SDE</strong>：
                    <ul>
                        <li>更灵活的框架</li>
                        <li>可以调节收敛速度</li>
                        <li>数值稳定性更好</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h3>5.2.2 常见的SDE选择</h3>
        
        <p>在实践中，选择合适的SDE至关重要。不同的选择会影响模型的训练稳定性、生成质量和采样效率。让我们深入探讨实际应用中的SDE设计。</p>
        
        <h4>噪声调度的设计</h4>
        
        <p>SDE的核心是噪声调度函数，它控制着扩散过程的速度和特性。</p>
        
        <div class="example-box">
            <div class="example-title">常见的噪声调度</div>
            <ol>
                <li><strong>线性调度</strong>（Linear Schedule）
                    <div class="formula">$$\beta(t) = \beta_{\text{min}} + t(\beta_{\text{max}} - \beta_{\text{min}})$$</div>
                    <ul>
                        <li>简单直观</li>
                        <li>DDPM的原始选择</li>
                        <li>可能在开始时太快，结束时太慢</li>
                    </ul>
                </li>
                
                <li><strong>余弦调度</strong>（Cosine Schedule）
                    <div class="formula">$$\bar{\alpha}(t) = \cos\left(\frac{t/T + s}{1 + s} \cdot \frac{\pi}{2}\right)^2$$</div>
                    <ul>
                        <li>由Nichol & Dhariwal (2021)提出</li>
                        <li>在整个过程中更均匀地破坏信息</li>
                        <li>特别适合高分辨率图像</li>
                    </ul>
                </li>
                
                <li><strong>二次调度</strong>（Quadratic Schedule）
                    <div class="formula">$$\beta(t) = \beta_{\text{min}} + (\beta_{\text{max}} - \beta_{\text{min}})t^2$$</div>
                    <ul>
                        <li>开始时缓慢，后期加速</li>
                        <li>保留更多的早期信息</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <div class="code-block">
<pre># 实现和比较不同的噪声调度
import torch
import numpy as np

class NoiseSchedule:
    """噪声调度的基类"""
    
    def __init__(self, T=1.0):
        self.T = T
    
    def beta(self, t):
        """返回时刻t的beta值"""
        raise NotImplementedError
    
    def alpha_bar(self, t):
        """返回累积alpha值"""
        # 对于连续时间，需要积分
        # 这里使用数值近似
        n_steps = 1000
        dt = t / n_steps
        alpha_bar = 1.0
        
        for i in range(n_steps):
            t_i = i * dt
            alpha_bar *= (1 - self.beta(t_i) * dt)
        
        return alpha_bar
    
    def snr(self, t):
        """信噪比 (Signal-to-Noise Ratio)"""
        alpha_bar = self.alpha_bar(t)
        return alpha_bar / (1 - alpha_bar + 1e-8)

class LinearSchedule(NoiseSchedule):
    """线性噪声调度"""
    
    def __init__(self, beta_min=0.0001, beta_max=0.02, T=1.0):
        super().__init__(T)
        self.beta_min = beta_min
        self.beta_max = beta_max
    
    def beta(self, t):
        return self.beta_min + (t / self.T) * (self.beta_max - self.beta_min)

class CosineSchedule(NoiseSchedule):
    """余弦噪声调度"""
    
    def __init__(self, s=0.008, T=1.0):
        super().__init__(T)
        self.s = s
    
    def alpha_bar(self, t):
        # 直接定义alpha_bar而不是beta
        return np.cos((t / self.T + self.s) / (1 + self.s) * np.pi / 2) ** 2
    
    def beta(self, t):
        # 从alpha_bar推导beta
        dt = 1e-5
        alpha_bar_t = self.alpha_bar(t)
        alpha_bar_t_dt = self.alpha_bar(min(t + dt, self.T))
        
        # beta = 1 - alpha_t = 1 - alpha_bar_t / alpha_bar_{t-1}
        return 1 - alpha_bar_t_dt / (alpha_bar_t + 1e-8)

class QuadraticSchedule(NoiseSchedule):
    """二次噪声调度"""
    
    def __init__(self, beta_min=0.0001, beta_max=0.02, T=1.0):
        super().__init__(T)
        self.beta_min = beta_min
        self.beta_max = beta_max
    
    def beta(self, t):
        return self.beta_min + (t / self.T) ** 2 * (self.beta_max - self.beta_min)

# 比较不同调度的特性
def compare_schedules():
    """可视化和比较不同的噪声调度"""
    schedules = {
        'Linear': LinearSchedule(),
        'Cosine': CosineSchedule(),
        'Quadratic': QuadraticSchedule()
    }
    
    t_values = np.linspace(0, 1.0, 11)
    
    print("噪声调度比较")
    print("="*80)
    print(f"{'Schedule':^10} | {'t':^5} | {'beta(t)':^10} | {'alpha_bar(t)':^12} | {'SNR':^10} | {'log10(SNR)':^10}")
    print("-"*80)
    
    for name, schedule in schedules.items():
        for t in t_values:
            beta_t = schedule.beta(t)
            alpha_bar_t = schedule.alpha_bar(t)
            snr_t = schedule.snr(t)
            log_snr = np.log10(snr_t + 1e-10)
            
            print(f"{name:^10} | {t:5.2f} | {beta_t:10.6f} | {alpha_bar_t:12.6f} | {snr_t:10.2f} | {log_snr:10.2f}")
        print("-"*80)
    
    # 分析关键指标
    print("\n关键观察：")
    print("1. Linear: SNR下降最快，可能导致早期信息丢失过快")
    print("2. Cosine: SNR下降更均匀，在中间阶段保留更多信息")
    print("3. Quadratic: 早期保留最多信息，后期快速下降")

compare_schedules()</pre>
        </div>
        
        <h4>离散化与连续时间的对应</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">从离散到连续的映射</div>
            <p>给定离散扩散模型的参数 $\{\beta_i\}_{i=1}^T$，如何构造对应的连续SDE？</p>
            
            <ol>
                <li><strong>时间映射</strong>：将离散步骤 $i \in \{1, ..., T\}$ 映射到连续时间 $t \in [0, 1]$：
                    <div class="formula">$$t = i/T$$</div>
                </li>
                
                <li><strong>插值beta函数</strong>：
                    <div class="formula">$$\beta(t) = T \cdot \beta_{\lfloor tT \rfloor}$$</div>
                    需要乘以T来保持正确的时间尺度。
                </li>
                
                <li><strong>验证等价性</strong>：确保离散采样和SDE模拟给出相似的边缘分布。</li>
            </ol>
        </div>
        
        <h4>特殊SDE设计</h4>
        
        <div class="example-box">
            <div class="example-title">1. 保持数据范围的SDE</div>
            <p>对于图像数据（通常在[-1, 1]范围内），我们可能希望设计保持这个范围的SDE：</p>
            
            <div class="formula">
                $$dx = -\frac{\beta(t)}{2}(x - \tanh(x))dt + \sqrt{\beta(t)} dW_t$$
            </div>
            
            <p>这里的非线性漂移项 $\tanh(x)$ 在边界附近提供"推力"，防止样本逃离有效范围。</p>
        </div>
        
        <div class="example-box">
            <div class="example-title">2. 条件SDE</div>
            <p>对于条件生成，我们可以修改SDE以包含条件信息 $y$：</p>
            
            <div class="formula">
                $$dx = f(x, t, y)dt + g(t)dW_t$$
            </div>
            
            <p>常见选择：</p>
            <ul>
                <li>条件漂移：$f(x, t, y) = -\frac{\beta(t)}{2}x + h(y, t)$</li>
                <li>条件扩散：$g(t, y) = \sqrt{\beta(t)} \cdot \sigma(y)$</li>
            </ul>
        </div>
        
        <div class="code-block">
<pre># 特殊SDE的实现
class BoundedSDE(SDE):
    """保持数据在有界范围内的SDE"""
    
    def __init__(self, beta_fn, bounds=(-1, 1), T=1.0):
        super().__init__(T)
        self.beta_fn = beta_fn
        self.lower, self.upper = bounds
        self.range = self.upper - self.lower
    
    def drift(self, x, t):
        beta_t = self.beta_fn(t)
        # 归一化到[-1, 1]
        x_norm = 2 * (x - self.lower) / self.range - 1
        # 非线性漂移
        drift_norm = -0.5 * beta_t * (x_norm - torch.tanh(x_norm))
        # 转换回原始范围
        return drift_norm * self.range / 2
    
    def diffusion(self, t):
        return np.sqrt(self.beta_fn(t))

class ConditionalVPSDE(SDE):
    """条件VP-SDE"""
    
    def __init__(self, beta_min=0.1, beta_max=20.0, condition_dim=128, T=1.0):
        super().__init__(T)
        self.beta_min = beta_min
        self.beta_max = beta_max
        self.condition_dim = condition_dim
        
        # 条件编码器（简化示例）
        self.condition_encoder = torch.nn.Sequential(
            torch.nn.Linear(condition_dim, 256),
            torch.nn.ReLU(),
            torch.nn.Linear(256, 1)
        )
    
    def beta(self, t):
        return self.beta_min + (self.beta_max - self.beta_min) * t / self.T
    
    def drift(self, x, t, condition=None):
        base_drift = -0.5 * self.beta(t) * x
        
        if condition is not None:
            # 条件调制
            with torch.no_grad():
                modulation = self.condition_encoder(condition)
                base_drift = base_drift * (1 + 0.1 * modulation)
        
        return base_drift
    
    def diffusion(self, t, condition=None):
        base_diffusion = np.sqrt(self.beta(t))
        
        if condition is not None:
            # 条件可以影响噪声强度
            return base_diffusion
        
        return base_diffusion

# 测试特殊SDE
def test_special_sdes():
    """测试特殊设计的SDE"""
    print("\n特殊SDE测试")
    print("="*60)
    
    # 1. 有界SDE
    print("1. 有界SDE（保持数据在[-1, 1]内）")
    beta_fn = lambda t: 0.1 + 10 * t
    bounded_sde = BoundedSDE(beta_fn, bounds=(-1, 1))
    
    # 测试边界行为
    x_boundary = torch.tensor([0.9, -0.9, 0.0])
    drift = bounded_sde.drift(x_boundary, 0.5)
    print(f"边界点的漂移: {drift.numpy()}")
    print("观察：接近边界的点有向内的漂移\n")
    
    # 2. 条件SDE
    print("2. 条件SDE")
    cond_sde = ConditionalVPSDE()
    
    # 不同条件下的漂移
    x = torch.randn(3)
    t = 0.5
    
    # 无条件
    drift_uncond = cond_sde.drift(x, t, condition=None)
    
    # 有条件
    condition = torch.randn(128)
    drift_cond = cond_sde.drift(x, t, condition=condition)
    
    print(f"无条件漂移: {drift_uncond.numpy()}")
    print(f"有条件漂移: {drift_cond.numpy()}")
    print(f"差异: {(drift_cond - drift_uncond).numpy()}")

test_special_sdes()</pre>
        </div>
        
        <h4>实用建议：如何选择和调试SDE</h4>
        
        <div class="note-box">
            <h4>SDE设计清单</h4>
            <ol>
                <li><strong>检查信噪比曲线</strong>
                    <ul>
                        <li>log SNR应该从正值（高信号）单调下降到负值（高噪声）</li>
                        <li>下降速度影响信息保留和生成质量的平衡</li>
                    </ul>
                </li>
                
                <li><strong>验证最终分布</strong>
                    <ul>
                        <li>$p_T(x)$应该接近先验分布（如标准正态）</li>
                        <li>可以通过蒙特卡罗模拟验证</li>
                    </ul>
                </li>
                
                <li><strong>测试数值稳定性</strong>
                    <ul>
                        <li>确保drift和diffusion项在整个时间范围内有界</li>
                        <li>避免在t=0或t=T附近出现数值问题</li>
                    </ul>
                </li>
                
                <li><strong>考虑计算效率</strong>
                    <ul>
                        <li>简单的函数形式（如线性）计算更快</li>
                        <li>复杂的调度可能提供更好的质量但增加计算成本</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <div class="example-box">
            <div class="example-title">经验法则</div>
            <ul>
                <li><strong>低分辨率图像</strong>：线性调度通常足够</li>
                <li><strong>高分辨率图像</strong>：余弦调度表现更好</li>
                <li><strong>非图像数据</strong>：可能需要专门设计的SDE</li>
                <li><strong>条件生成</strong>：考虑让条件影响噪声调度</li>
            </ul>
        </div>
        
        <h3>5.2.3 边缘分布的演化</h3>
        
        <p>理解边缘分布 $p_t(x)$ 如何随时间演化是掌握扩散模型的关键。这不仅关系到理论分析，更直接影响到实际的训练和采样。</p>
        
        <h4>边缘分布的定义</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">边缘分布</div>
            <p>给定SDE $dx_t = f(x_t, t)dt + g(t)dW_t$ 和初始分布 $p_0(x)$，边缘分布定义为：</p>
            <div class="formula">
                $$p_t(x) = \int p(x_t = x | x_0) p_0(x_0) dx_0$$
            </div>
            
            <p>其中 $p(x_t | x_0)$ 是转移核（transition kernel），描述了从 $x_0$ 到 $x_t$ 的概率转移。</p>
        </div>
        
        <h4>线性SDE的解析解</h4>
        
        <p>对于线性SDE（如VP-SDE），我们可以得到边缘分布的显式解。</p>
        
        <div class="example-box">
            <div class="example-title">以VP-SDE为例</div>
            <p>对于 $dx = -\frac{1}{2}\beta(t)x dt + \sqrt{\beta(t)} dW_t$，转移核为：</p>
            <div class="formula">
                $$p(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}(t)} x_0, (1-\bar{\alpha}(t))I)$$
            </div>
            
            <p>其中：</p>
            <div class="formula">
                $$\bar{\alpha}(t) = \exp\left(-\int_0^t \beta(s) ds\right)$$
            </div>
            
            <p>这个结果告诉我们：</p>
            <ul>
                <li>均值随时间指数衰减</li>
                <li>方差逐渐增加到接近1</li>
                <li>最终分布接近标准正态</li>
            </ul>
        </div>
        
        <div class="code-block">
<pre># 可视化边缘分布的演化
import torch
import numpy as np
from scipy import stats

class MarginalDistribution:
    """计算和分析SDE的边缘分布"""
    
    def __init__(self, sde):
        self.sde = sde
    
    def sample_marginal(self, x0, t, n_samples=1000):
        """通过蒙特卡罗采样边缘分布"""
        if hasattr(self.sde, 'marginal_prob'):
            # 如果有解析解，直接使用
            mean, std = self.sde.marginal_prob(x0, t)
            samples = mean + std * torch.randn(n_samples, *x0.shape)
        else:
            # 否则通过模拟
            samples = []
            for _ in range(n_samples):
                trajectory = self.sde.sample_trajectory(x0, n_steps=100)
                samples.append(trajectory[-1])
            samples = torch.stack(samples)
        
        return samples
    
    def analyze_evolution(self, x0, time_points):
        """分析边缘分布随时间的变化"""
        results = []
        
        for t in time_points:
            samples = self.sample_marginal(x0, t, n_samples=5000)
            
            # 统计量
            mean = samples.mean(dim=0)
            std = samples.std(dim=0)
            
            # 峰度和偏度（用于检测非高斯性）
            kurtosis = ((samples - mean) ** 4).mean() / (std ** 4) - 3
            skewness = ((samples - mean) ** 3).mean() / (std ** 3)
            
            # KL散度（与标准正态的距离）
            # 简化：使用moment matching估计
            kl_div = 0.5 * (mean.norm()**2 + std.norm()**2 - std.log().sum() - len(mean))
            
            results.append({
                't': t,
                'mean': mean.numpy(),
                'std': std.numpy(), 
                'kurtosis': kurtosis.item(),
                'skewness': skewness.item(),
                'kl_to_normal': kl_div.item()
            })
        
        return results

# 演示不同SDE的边缘分布演化
def demonstrate_marginal_evolution():
    """演示不同SDE的边缘分布演化"""
    # 初始化不同SDE
    from functools import partial
    
    # 重新定义简单的SDE类以避免循环引用
    class SimpleVPSDE:
        def __init__(self, beta_min=0.1, beta_max=20.0, T=1.0):
            self.beta_min = beta_min
            self.beta_max = beta_max
            self.T = T
        
        def marginal_prob(self, x0, t):
            log_mean_coeff = -0.25 * t**2 * (self.beta_max - self.beta_min) / self.T - 0.5 * t * self.beta_min
            mean = torch.exp(log_mean_coeff) * x0
            std = torch.sqrt(1 - torch.exp(2 * log_mean_coeff))
            return mean, std
    
    class SimpleVESDE:
        def __init__(self, sigma_min=0.01, sigma_max=50.0, T=1.0):
            self.sigma_min = sigma_min
            self.sigma_max = sigma_max
            self.T = T
        
        def marginal_prob(self, x0, t):
            sigma_t = self.sigma_min * (self.sigma_max / self.sigma_min) ** (t / self.T)
            mean = x0
            std = sigma_t
            return mean, std
    
    # 初始化
    x0 = torch.tensor([1.0, -0.5])  # 2D初始点
    time_points = [0.0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0]
    
    sdes = {
        'VP-SDE': SimpleVPSDE(),
        'VE-SDE': SimpleVESDE()
    }
    
    print("边缘分布演化分析")
    print("="*90)
    
    for sde_name, sde in sdes.items():
        print(f"\n{sde_name}：")
        print("-"*90)
        print(f"{'t':^5} | {'均值范数':^12} | {'标准差':^12} | {'峰度':^10} | {'偏度':^10} | {'KL散度':^12}")
        print("-"*90)
        
        analyzer = MarginalDistribution(sde)
        results = analyzer.analyze_evolution(x0, time_points)
        
        for res in results:
            mean_norm = np.linalg.norm(res['mean'])
            std_avg = np.mean(res['std'])
            
            print(f"{res['t']:5.2f} | {mean_norm:12.6f} | {std_avg:12.6f} | "
                  f"{res['kurtosis']:10.4f} | {res['skewness']:10.4f} | {res['kl_to_normal']:12.6f}")
    
    print("\n关键观察：")
    print("1. VP-SDE: 均值逐渐衰减到零，标准差趋近于1")
    print("2. VE-SDE: 均值保持不变，标准差爆炸式增长")
    print("3. 两者的峰度和偏度都接近零，说明分布接近高斯")

demonstrate_marginal_evolution()</pre>
        </div>
        
        <h4>Fokker-Planck方程：密度演化的PDE</h4>
        
        <p>边缘分布的演化可以用Fokker-Planck方程（也称为Kolmogorov前向方程）来描述：</p>
        
        <div class="theorem-box">
            <div class="theorem-title">Fokker-Planck方程</div>
            <p>对于SDE $dx = f(x,t)dt + g(t)dW_t$，概率密度 $p_t(x)$ 满足：</p>
            <div class="formula">
                $$\frac{\partial p_t(x)}{\partial t} = -\nabla \cdot (f(x,t)p_t(x)) + \frac{g(t)^2}{2} \Delta p_t(x)$$
            </div>
            
            <p>其中：</p>
            <ul>
                <li>$\nabla \cdot$ 是散度算子</li>
                <li>$\Delta$ 是拉普拉斯算子</li>
                <li>第一项是漂移项（传输）</li>
                <li>第二项是扩散项（平滑）</li>
            </ul>
        </div>
        
        <h4>分数函数与边缘分布</h4>
        
        <p>分数函数 $\nabla \log p_t(x)$ 在扩散模型中扮演着核心角色。它描述了概率密度增长最快的方向。</p>
        
        <div class="note-box">
            <h4>分数函数的性质</h4>
            <ol>
                <li><strong>梯度流</strong>：$\nabla \log p_t(x)$ 指向高概率区域</li>
                <li><strong>归一化</strong>：不需要知道归一化常数</li>
                <li><strong>光滑性</strong>：随着噪声增加，分数函数变得更平滑</li>
                <li><strong>可学习性</strong>：可以用神经网络近似</li>
            </ol>
        </div>
        
        <div class="example-box">
            <div class="example-title">特殊情况：高斯分布</div>
            <p>对于高斯分布 $p(x) = \mathcal{N}(x; \mu, \Sigma)$：</p>
            <div class="formula">
                $$\nabla \log p(x) = -\Sigma^{-1}(x - \mu)$$
            </div>
            
            <p>这是一个线性函数，指向均值点！</p>
        </div>
        
        <div class="code-block">
<pre># 分析分数函数随时间的变化
class ScoreFunctionAnalysis:
    """分析分数函数的演化"""
    
    def __init__(self, sde):
        self.sde = sde
    
    def analytical_score(self, x, x0, t):
        """计算解析分数函数（仅适用于线性SDE）"""
        if hasattr(self.sde, 'marginal_prob'):
            mean, std = self.sde.marginal_prob(x0, t)
            # 对于高斯分布：score = -(x - mean) / std^2
            score = -(x - mean) / (std ** 2 + 1e-8)
            return score
        else:
            raise NotImplementedError("需要解析边缘分布")
    
    def score_magnitude_analysis(self, x0, t_values, x_test_points):
        """分析分数函数的幅度"""
        results = []
        
        for t in t_values:
            scores = []
            for x in x_test_points:
                score = self.analytical_score(x, x0, t)
                scores.append(torch.norm(score).item())
            
            results.append({
                't': t,
                'mean_magnitude': np.mean(scores),
                'max_magnitude': np.max(scores),
                'min_magnitude': np.min(scores)
            })
        
        return results

# 演示分数函数的演化
def demonstrate_score_evolution():
    """演示分数函数随时间的变化"""
    # 使用VP-SDE
    class SimpleVPSDE:
        def __init__(self, beta_min=0.1, beta_max=20.0, T=1.0):
            self.beta_min = beta_min
            self.beta_max = beta_max
            self.T = T
        
        def marginal_prob(self, x0, t):
            log_mean_coeff = -0.25 * t**2 * (self.beta_max - self.beta_min) / self.T - 0.5 * t * self.beta_min
            mean = torch.exp(log_mean_coeff) * x0
            std = torch.sqrt(1 - torch.exp(2 * log_mean_coeff))
            return mean, std
    
    sde = SimpleVPSDE()
    analyzer = ScoreFunctionAnalysis(sde)
    
    # 设置
    x0 = torch.tensor([1.0])
    t_values = [0.1, 0.3, 0.5, 0.7, 0.9]
    x_test_points = [torch.tensor([x]) for x in np.linspace(-3, 3, 20)]
    
    print("\n分数函数幅度分析")
    print("="*60)
    print(f"{'t':^5} | {'平均幅度':^12} | {'最大幅度':^12} | {'最小幅度':^12}")
    print("-"*60)
    
    results = analyzer.score_magnitude_analysis(x0, t_values, x_test_points)
    
    for res in results:
        print(f"{res['t']:5.2f} | {res['mean_magnitude']:12.6f} | "
              f"{res['max_magnitude']:12.6f} | {res['min_magnitude']:12.6f}")
    
    print("\n观察：")
    print("1. 随着t增加，分数函数的幅度逐渐减小")
    print("2. 这反映了分布变得更加平坦（接近均匀分布）")
    print("3. 在噪声很大时，分数函数几乎为零")

demonstrate_score_evolution()</pre>
        </div>
        
        <h4>实际应用：训练时的边缘分布</h4>
        
        <div class="note-box">
            <h4>训练时的采样策略</h4>
            <p>在训练扩散模型时，我们需要：</p>
            <ol>
                <li><strong>采样时间 $t \sim \mathcal{U}[0, T]$</strong></li>
                <li><strong>采样数据点 $x_0 \sim p_{data}$</strong></li>
                <li><strong>根据 $p(x_t|x_0)$ 生成噪声样本 $x_t$</strong></li>
                <li><strong>训练模型预测噪声或分数</strong></li>
            </ol>
            
            <p>边缘分布的解析形式使得第3步变得非常高效！</p>
        </div>
        
        <div class="example-box">
            <div class="example-title">重要性采样</div>
            <p>不同的时间点对学习的难度不同。我们可以使用重要性采样：</p>
            
            <div class="formula">
                $$p(t) \propto \mathbb{E}_{x_0, x_t}[||\nabla_{x_t} \log p(x_t|x_0)||^2]$$
            </div>
            
            <p>这使得模型更多地关注"难"的时间点。</p>
        </div>

        <h2>5.3 反向时间SDE：去噪过程</h2>
        
        <h3>5.3.1 Anderson定理</h3>
        
        <p>Anderson定理是扩散模型理论的基石之一。它告诉我们，任何满足一定条件的前向SDE都存在一个对应的反向时间SDE，而这正是生成过程的数学基础。</p>
        
        <h4>定理的背景</h4>
        
        <p>在物理学中，时间反演（time reversal）是一个重要概念。对于确定性系统，时间反演通常很简单。但对于随机过程，情况就复杂得多。Anderson在1982年的工作回答了这个问题。</p>
        
        <div class="theorem-box">
            <div class="theorem-title">Anderson定理（简化版）</div>
            <p>考虑前向SDE：</p>
            <div class="formula">
                $$dx = f(x, t) dt + g(t) dW_t, \quad t \in [0, T]$$
            </div>
            
            <p>定义反向时间 $\tau = T - t$，则存在反向SDE：</p>
            <div class="formula">
                $$dx = [f(x, T-\tau) - g(T-\tau)^2 \nabla_x \log p_{T-\tau}(x)] d\tau + g(T-\tau) d\bar{W}_\tau$$
            </div>
            
            <p>其中：</p>
            <ul>
                <li>$\bar{W}_\tau$ 是关于反向时间的布朗运动</li>
                <li>$p_t(x)$ 是前向过程在时刻 $t$ 的边缘分布</li>
                <li>$\nabla_x \log p_t(x)$ 是分数函数</li>
            </ul>
        </div>
        
        <h4>直观理解</h4>
        
        <div class="note-box">
            <h4>为什么需要分数函数？</h4>
            <p>反向过程不仅仅是前向过程的"倒带"。关键差异在于：</p>
            <ol>
                <li><strong>信息不对称</strong>：前向过程丢失信息，反向过程需要恢复信息</li>
                <li><strong>概率流</strong>：反向过程需要知道"哪里来的概率更高"</li>
                <li><strong>分数作为指引</strong>：$\nabla \log p_t(x)$ 正好指向高概率方向</li>
            </ol>
        </div>
        
        <div class="example-box">
            <div class="example-title">一个简单的例子：Ornstein-Uhlenbeck过程</div>
            <p>考虑前向OU过程：</p>
            <div class="formula">
                $$dx = -\theta x dt + \sigma dW_t$$
            </div>
            
            <p>其稳态分布为 $\mathcal{N}(0, \frac{\sigma^2}{2\theta})$。分数函数为：</p>
            <div class="formula">
                $$\nabla \log p_{\infty}(x) = -\frac{2\theta}{\sigma^2} x$$
            </div>
            
            <p>因此反向SDE为：</p>
            <div class="formula">
                $$dx = \left[-\theta x - \sigma^2 \cdot \left(-\frac{2\theta}{\sigma^2} x\right)\right] d\tau + \sigma d\bar{W}_\tau = \theta x d\tau + \sigma d\bar{W}_\tau$$
            </div>
            
            <p>注意漂移项的符号变了！</p>
        </div>
        
        <div class="code-block">
<pre># 验证Anderson定理
import torch
import numpy as np

class SDEReversal:
    """验证和演示时间反演SDE"""
    
    def __init__(self, forward_drift, forward_diffusion, score_fn):
        """
        Args:
            forward_drift: f(x, t) - 前向漂移
            forward_diffusion: g(t) - 前向扩散
            score_fn: \nabla log p_t(x) - 分数函数
        """
        self.f = forward_drift
        self.g = forward_diffusion
        self.score = score_fn
    
    def reverse_drift(self, x, t, T):
        """计算反向SDE的漂移项"""
        # 时间变换
tau = t
        forward_time = T - tau
        
        # Anderson公式
        f_reverse = self.f(x, forward_time) - self.g(forward_time)**2 * self.score(x, forward_time)
        
        return f_reverse
    
    def simulate_forward_backward(self, x0, T, n_steps=100):
        """模拟前向和反向过程"""
        dt = T / n_steps
        
        # 前向过程
        forward_path = [x0]
        x = x0.clone()
        
        for i in range(n_steps):
            t = i * dt
            drift = self.f(x, t) * dt
            diffusion = self.g(t) * np.sqrt(dt) * torch.randn_like(x)
            x = x + drift + diffusion
            forward_path.append(x.clone())
        
        # 反向过程
        reverse_path = [x]
        
        for i in range(n_steps):
            tau = i * dt
            drift = self.reverse_drift(x, tau, T) * dt
            diffusion = self.g(T - tau) * np.sqrt(dt) * torch.randn_like(x)
            x = x + drift + diffusion
            reverse_path.append(x.clone())
        
        return torch.stack(forward_path), torch.stack(reverse_path)

# 示例：VP-SDE的时间反演
def demonstrate_vp_sde_reversal():
    """演示VP-SDE的时间反演"""
    # VP-SDE参数
    beta_min, beta_max = 0.1, 20.0
    T = 1.0
    
    def beta(t):
        return beta_min + (beta_max - beta_min) * t / T
    
    def forward_drift(x, t):
        return -0.5 * beta(t) * x
    
    def forward_diffusion(t):
        return np.sqrt(beta(t))
    
    def score_fn(x, t):
        # 对于VP-SDE，边缘分布是高斯的
        # p_t(x|x_0) = N(x; sqrt(alpha_bar_t) * x_0, (1 - alpha_bar_t) * I)
        # 但我们需要边缘分数 \nabla log p_t(x)
        # 这在实践中是通过神经网络学习的
        # 这里用一个简化的近似
        alpha_bar = np.exp(-0.5 * beta_min * t - 0.25 * (beta_max - beta_min) * t**2 / T)
        return -x / (1 - alpha_bar + 1e-8)
    
    # 创建反演器
    reverser = SDEReversal(forward_drift, forward_diffusion, score_fn)
    
    # 模拟
    x0 = torch.randn(2)  # 2D初始点
    forward_path, reverse_path = reverser.simulate_forward_backward(x0, T, n_steps=100)
    
    # 分析结果
    print("时间反演SDE分析")
    print("="*60)
    print(f"初始点: {x0.numpy()}")
    print(f"前向终点: {forward_path[-1].numpy()}")
    print(f"反向终点: {reverse_path[-1].numpy()}")
    print(f"\n前向过程统计:")
    print(f"  初始范数: {torch.norm(forward_path[0]).item():.3f}")
    print(f"  终点范数: {torch.norm(forward_path[-1]).item():.3f}")
    print(f"\n反向过程统计:")
    print(f"  初始范数: {torch.norm(reverse_path[0]).item():.3f}")
    print(f"  终点范数: {torch.norm(reverse_path[-1]).item():.3f}")
    
    # 路径对比
    forward_norms = [torch.norm(x).item() for x in forward_path]
    reverse_norms = [torch.norm(x).item() for x in reverse_path]
    
    print(f"\n路径分析:")
    print(f"前向路径范数变化: {forward_norms[0]:.3f} → {forward_norms[-1]:.3f}")
    print(f"反向路径范数变化: {reverse_norms[0]:.3f} → {reverse_norms[-1]:.3f}")
    print("\n注意: 由于随机性，反向过程不会完美回到原点，")
    print("但会回到同样的分布！")

demonstrate_vp_sde_reversal()</pre>
        </div>
        
        <h4>数学严格性</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">存在性条件</div>
            <p>Anderson定理成立需要以下条件：</p>
            <ol>
                <li><strong>正则性</strong>：$f(x,t)$ 和 $g(t)$ 满足Lipschitz条件</li>
                <li><strong>非退化性</strong>：$g(t) > 0$ 对所有 $t \in [0,T]$</li>
                <li><strong>分数存在</strong>：$\nabla \log p_t(x)$ 存在且满足适当的增长条件</li>
            </ol>
        </div>
        
        <h4>与其他理论的联系</h4>
        
        <div class="note-box">
            <h4>联系与应用</h4>
            <ol>
                <li><strong>Jarzynski等式</strong>：在非平衡统计物理中的应用</li>
                <li><strong>最优传输</strong>：Schrödinger bridge问题的特例</li>
                <li><strong>信息论</strong>：与信息熵的增减相关</li>
                <li><strong>BSDE</strong>：反向SDE可以看作一类特殊的BSDE</li>
            </ol>
        </div>
        
        <div class="example-box">
            <div class="example-title">实践意义</div>
            <p>Anderson定理对扩散模型的重要性：</p>
            <ul>
                <li><strong>理论保证</strong>：确保了反向过程的存在性</li>
                <li><strong>学习目标</strong>：明确了需要学习的是分数函数</li>
                <li><strong>采样算法</strong>：提供了从噪声生成数据的数学公式</li>
                <li><strong>理论分析</strong>：可以分析生成过程的性质</li>
            </ul>
        </div>
        
        <h3>5.3.2 反向SDE的推导</h3>
        
        <p>反向SDE是扩散模型的核心，它告诉我们如何从噪声生成数据。这个推导虽然技术性较强，但其物理直觉非常清晰。</p>
        
        <h4>时间反演的基本想法</h4>
        
        <div class="note-box">
            <h4>直觉：电影倒放</h4>
            <p>想象你录制了墨水在水中扩散的过程：</p>
            <ul>
                <li><strong>正向播放</strong>：墨水从一点扩散到整个水体</li>
                <li><strong>反向播放</strong>：分散的墨水神奇地聚集回一点</li>
            </ul>
            <p>反向SDE就是找到这个"倒放过程"的数学描述。</p>
        </div>
        
        <h4>Anderson定理的应用</h4>
        
        <p>根据Anderson定理，如果前向过程是：</p>
        
        <div class="formula">
            $$dx = f(x, t)dt + g(t)dw$$
        </div>
        
        <p>那么反向过程（时间从T到0）是：</p>
        
        <div class="formula">
            $$dx = \left[f(x, t) - g(t)^2 \nabla_x \log p_t(x)\right]dt + g(t)d\bar{w}$$
        </div>
        
        <p>其中$\bar{w}$是反向布朗运动。</p>
        
        <h4>关键洞察：分数函数的作用</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">为什么需要分数函数？</div>
            <p>比较前向和反向SDE，唯一的区别是多了一项：$-g(t)^2 \nabla_x \log p_t(x)$</p>
            <p>这项的作用是：</p>
            <ul>
                <li><strong>补偿扩散</strong>：抵消随机项带来的扩散效应</li>
                <li><strong>指引方向</strong>：指向概率密度增加的方向</li>
                <li><strong>时变修正</strong>：随时间调整"拉回"的强度</li>
            </ul>
        </div>
        
        <h4>推导步骤（简化版）</h4>
        
        <div class="example-box">
            <div class="example-title">关键步骤</div>
            <ol>
                <li><strong>考虑联合分布</strong>：$(x_t, t)$的演化</li>
                <li><strong>应用Fokker-Planck方程</strong>：得到$p_t(x)$的演化</li>
                <li><strong>时间反演</strong>：令$\tau = T - t$</li>
                <li><strong>匹配系数</strong>：使反向过程的FP方程与原方程一致</li>
            </ol>
        </div>
        
        <h4>具体例子：VP-SDE的反向过程</h4>
        
        <p>对于VP-SDE（方差保持）：</p>
        
        <div class="formula">
            $$dx = -\frac{1}{2}\beta(t)x dt + \sqrt{\beta(t)}dw$$
        </div>
        
        <p>其反向SDE是：</p>
        
        <div class="formula">
            $$dx = \left[-\frac{1}{2}\beta(t)x - \beta(t)\nabla_x \log p_t(x)\right]dt + \sqrt{\beta(t)}d\bar{w}$$
        </div>
        
        <div class="code-block">
<pre># 验证反向SDE的正确性
import torch
import torch.nn as nn

class ReverseSDE:
    """反向SDE的数值验证"""
    
    def __init__(self, beta_schedule):
        """
        Args:
            beta_schedule: 函数，返回时刻t的beta(t)
        """
        self.beta = beta_schedule
    
    def forward_marginal(self, x0, t):
        """计算前向过程的边缘分布 p(x_t|x_0)"""
        # 对于VP-SDE，有解析解
        alpha_bar = torch.exp(-0.5 * self.integral_beta(t))
        mean = alpha_bar * x0
        var = 1 - alpha_bar**2
        return mean, var
    
    def integral_beta(self, t):
        """计算 ∫_0^t beta(s) ds"""
        # 简单起见，假设beta(t) = beta_min + t*(beta_max - beta_min)
        beta_min, beta_max = 0.1, 20.0
        return beta_min * t + 0.5 * (beta_max - beta_min) * t**2
    
    def score_function(self, xt, x0, t):
        """计算真实的分数函数（用于验证）"""
        mean, var = self.forward_marginal(x0, t)
        score = -(xt - mean) / var
        return score
    
    def verify_reverse_sde(self, x0, T=1.0, dt=0.01):
        """验证反向SDE确实能恢复x0"""
        print("验证反向SDE")
        print("="*50)
        
        # 1. 前向过程：x0 -> xT
        t = 0
        x = x0.clone()
        trajectory_forward = [x.clone()]
        
        while t < T:
            beta_t = self.beta(t)
            drift = -0.5 * beta_t * x
            diffusion = torch.sqrt(beta_t * dt) * torch.randn_like(x)
            x = x + drift * dt + diffusion
            t += dt
            trajectory_forward.append(x.clone())
        
        xT = x
        print(f"前向过程完成: x0 = {x0.numpy():.3f} -> xT = {xT.numpy():.3f}")
        
        # 2. 反向过程：xT -> x0
        t = T
        x = xT.clone()
        trajectory_reverse = [x.clone()]
        
        while t > dt:
            beta_t = self.beta(t)
            # 使用真实分数（实际中需要学习）
            score = self.score_function(x, x0, t)
            
            # 反向SDE
            drift = -0.5 * beta_t * x - beta_t * score
            diffusion = torch.sqrt(beta_t * dt) * torch.randn_like(x)
            x = x + drift * dt + diffusion
            t -= dt
            trajectory_reverse.append(x.clone())
        
        x0_recovered = x
        print(f"反向过程完成: xT = {xT.numpy():.3f} -> x0_recovered = {x0_recovered.numpy():.3f}")
        print(f"恢复误差: {torch.abs(x0 - x0_recovered).item():.4f}")
        
        # 3. 分析轨迹
        forward_std = torch.stack(trajectory_forward).std()
        reverse_std = torch.stack(trajectory_reverse).std()
        print(f"\n轨迹分析:")
        print(f"前向轨迹标准差: {forward_std:.3f} (扩散)")
        print(f"反向轨迹标准差: {reverse_std:.3f} (聚集)")
        
        return trajectory_forward, trajectory_reverse

# 测试
def beta_schedule(t, beta_min=0.1, beta_max=20.0):
    """线性beta调度"""
    return beta_min + t * (beta_max - beta_min)

reverse_sde = ReverseSDE(beta_schedule)
x0 = torch.tensor([2.0])
reverse_sde.verify_reverse_sde(x0)</pre>
        </div>
        
        <h4>物理类比：势能场中的粒子</h4>
        
        <div class="note-box">
            <h4>分数函数作为"力"</h4>
            <p>反向SDE可以理解为粒子在势能场中的运动：</p>
            <ul>
                <li><strong>原始漂移项</strong> $f(x,t)$：外加的确定性力</li>
                <li><strong>分数修正项</strong> $-g^2\nabla\log p$：势能场的梯度力</li>
                <li><strong>随机项</strong> $g(t)d\bar{w}$：热运动</li>
            </ul>
            <p>分数函数创造了一个"势能井"，将粒子拉向数据分布的高概率区域。</p>
        </div>
        
        <h4>实用考虑</h4>
        
        <div class="example-box">
            <div class="example-title">实现反向SDE的挑战</div>
            <ol>
                <li><strong>分数估计</strong>：需要神经网络学习$\nabla\log p_t(x)$</li>
                <li><strong>数值稳定性</strong>：小的$dt$带来大的计算成本</li>
                <li><strong>边界条件</strong>：$t=0$附近需要特殊处理</li>
                <li><strong>随机性控制</strong>：如何平衡确定性和随机性</li>
            </ol>
        </div>
        
        <div class="code-block">
<pre># 实用的反向采样器
class PracticalReverseSDESampler:
    """实际使用的反向SDE采样器"""
    
    def __init__(self, score_model, beta_schedule):
        self.score_model = score_model
        self.beta = beta_schedule
    
    def sample(self, shape, T=1.0, dt=0.01, device='cpu'):
        """从噪声生成样本"""
        # 初始化为高斯噪声
        x = torch.randn(shape, device=device)
        
        # 时间步
        timesteps = torch.linspace(T, dt, int(T/dt), device=device)
        
        for t in timesteps:
            # 估计分数
            with torch.no_grad():
                score = self.score_model(x, t)
            
            # 计算系数
            beta_t = self.beta(t)
            drift_coeff = -0.5 * beta_t
            score_coeff = -beta_t
            noise_coeff = torch.sqrt(beta_t * dt)
            
            # 反向SDE更新
            drift = drift_coeff * x + score_coeff * score
            noise = torch.randn_like(x)
            
            x = x + drift * dt + noise_coeff * noise
            
            # 可选：动态调整步长或使用高阶求解器
            if t < 0.1:  # 接近t=0时减小步长
                dt = dt * 0.5
        
        return x</pre>
        </div>
        
        <h4>总结：反向SDE的意义</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">核心要点</div>
            <ul>
                <li>反向SDE = 前向SDE + 分数修正</li>
                <li>分数函数是连接前向和反向过程的桥梁</li>
                <li>物理直觉：从无序到有序需要"信息注入"</li>
                <li>计算挑战：准确估计分数函数是关键</li>
            </ul>
        </div>
        
        <h3>5.3.3 分数函数的作用</h3>
        
        <p>分数函数 $\nabla_x \log p_t(x)$ 是连续时间扩散模型的核心。它不仅是数学上的必需品，更有深刻的几何和物理意义。</p>
        
        <h4>几何意义：指向高概率区域</h4>
        
        <div class="note-box">
            <h4>梯度上升的视角</h4>
            <p>分数函数指向概率密度增加最快的方向：</p>
            <ul>
                <li>在低概率区域，它指向高概率区域</li>
                <li>在概率峰值附近，它的幅度较小</li>
                <li>它定义了概率景观上的"最陡上升路径"</li>
            </ul>
        </div>
        
        <h4>动力学意义：时变的引导</h4>
        
        <p>分数函数在不同时刻扮演不同角色：</p>
        
        <div class="theorem-box">
            <div class="theorem-title">时间演化的三个阶段</div>
            <ol>
                <li><strong>早期（$t \approx 0$）</strong>：
                    <ul>
                        <li>数据分布还很清晰</li>
                        <li>分数函数提供精确的局部结构信息</li>
                        <li>主要作用：保持数据的精细特征</li>
                    </ul>
                </li>
                <li><strong>中期（$0 < t < T$）</strong>：
                    <ul>
                        <li>数据结构部分模糊</li>
                        <li>分数函数引导全局结构的形成</li>
                        <li>主要作用：建立大尺度的模式</li>
                    </ul>
                </li>
                <li><strong>后期（$t \approx T$）</strong>：
                    <ul>
                        <li>接近纯噪声分布</li>
                        <li>分数函数提供初始的方向指引</li>
                        <li>主要作用：从噪声中"点燃"生成过程</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>信息论意义：负熵流</h4>
        
        <div class="example-box">
            <div class="example-title">分数函数与信息</div>
            <p>从信息论角度看，分数函数代表了"信息梯度"：</p>
            <ul>
                <li><strong>前向过程</strong>：信息逐渐丢失，熵增加</li>
                <li><strong>反向过程</strong>：分数函数注入信息，熵减少</li>
                <li><strong>平衡点</strong>：分数函数恰好补偿扩散造成的信息损失</li>
            </ul>
        </div>
        
        <h4>与其他概念的联系</h4>
        
        <div class="note-box">
            <h4>1. 与Stein分数的关系</h4>
            <p>分数函数满足Stein恒等式：</p>
            <div class="formula">
                $$\mathbb{E}_{p_t}[\nabla_x \log p_t(x)] = 0$$
            </div>
            <p>这保证了分数函数的"平衡性"——它不会整体偏向某个方向。</p>
        </div>
        
        <div class="note-box">
            <h4>2. 与最优传输的关系</h4>
            <p>在某些条件下，分数函数定义了从$p_t$到$p_0$的最优传输映射的速度场。这建立了扩散模型与最优传输理论的桥梁。</p>
        </div>
        
        <div class="note-box">
            <h4>3. 与能量模型的关系</h4>
            <p>如果定义能量函数$E_t(x) = -\log p_t(x)$，则：</p>
            <div class="formula">
                $$\nabla_x \log p_t(x) = -\nabla_x E_t(x)$$
            </div>
            <p>分数函数就是能量函数的负梯度，指向能量下降的方向。</p>
        </div>
        
        <h4>实践中的重要性</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">为什么学习分数函数？</div>
            <ol>
                <li><strong>参数化简单</strong>：
                    <ul>
                        <li>不需要归一化常数</li>
                        <li>可以用标准神经网络表示</li>
                        <li>训练目标明确（去噪任务）</li>
                    </ul>
                </li>
                <li><strong>局部性质</strong>：
                    <ul>
                        <li>只需要局部信息</li>
                        <li>不需要全局积分</li>
                        <li>计算效率高</li>
                    </ul>
                </li>
                <li><strong>稳定性好</strong>：
                    <ul>
                        <li>梯度匹配是稳定的优化问题</li>
                        <li>避免了密度估计的数值问题</li>
                        <li>适合高维数据</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>分数函数的多尺度特性</h4>
        
        <div class="example-box">
            <div class="example-title">跨尺度的信息编码</div>
            <p>分数函数在不同噪声水平下编码不同尺度的信息：</p>
            <ul>
                <li><strong>低噪声</strong>：编码精细纹理、边缘等高频信息</li>
                <li><strong>中等噪声</strong>：编码物体形状、整体结构</li>
                <li><strong>高噪声</strong>：编码全局布局、大尺度模式</li>
            </ul>
            <p>这种多尺度特性使得扩散模型能够生成具有丰富细节的高质量样本。</p>
        </div>
        
        <h4>总结：分数函数的核心地位</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">关键认识</div>
            <p>分数函数是扩散模型的"灵魂"：</p>
            <ul>
                <li>它编码了数据分布的所有信息</li>
                <li>它连接了前向扩散和反向生成</li>
                <li>它统一了多个理论视角（SDE、ODE、能量模型）</li>
                <li>它提供了实用的参数化和训练方法</li>
            </ul>
            <p>理解分数函数就是理解扩散模型的关键。</p>
        </div>

        <h2>5.4 概率流ODE：确定性的替代</h2>
        
        <h3>5.4.1 从SDE到ODE</h3>
        
        <p>一个令人惊讶的发现是：每个SDE都有一个对应的ODE，它们产生相同的边缘分布演化。这个ODE被称为概率流ODE（Probability Flow ODE）。</p>
        
        <h4>核心思想：去除随机性</h4>
        
        <div class="note-box">
            <h4>从随机到确定</h4>
            <p>SDE包含两部分：</p>
            <ul>
                <li><strong>确定性漂移</strong>：$f(x,t)dt$</li>
                <li><strong>随机扩散</strong>：$g(t)dw$</li>
            </ul>
            <p>概率流ODE通过修改漂移项来补偿随机项的效果，使得整体演化变成确定性的。</p>
        </div>
        
        <h4>概率流ODE的形式</h4>
        
        <p>对于前向SDE：</p>
        <div class="formula">
            $$dx = f(x,t)dt + g(t)dw$$
        </div>
        
        <p>对应的概率流ODE是：</p>
        <div class="formula">
            $$\frac{dx}{dt} = f(x,t) - \frac{1}{2}g(t)^2\nabla_x \log p_t(x)$$
        </div>
        
        <div class="theorem-box">
            <div class="theorem-title">关键性质</div>
            <ul>
                <li>ODE是确定性的——给定初始条件，轨迹唯一确定</li>
                <li>边缘分布相同——$p_t(x)$的演化与SDE一致</li>
                <li>可逆性——可以精确地前向和反向求解</li>
            </ul>
        </div>
        
        <h4>直观理解：流场视角</h4>
        
        <div class="example-box">
            <div class="example-title">流体动力学类比</div>
            <p>可以把概率流ODE理解为不可压缩流体的流动：</p>
            <ul>
                <li><strong>流体元素</strong>：概率质量的小块</li>
                <li><strong>速度场</strong>：$v(x,t) = f(x,t) - \frac{1}{2}g(t)^2\nabla\log p_t$</li>
                <li><strong>流线</strong>：ODE的解轨迹</li>
                <li><strong>守恒律</strong>：概率总量守恒</li>
            </ul>
        </div>
        
        <h4>为什么这个ODE有效？</h4>
        
        <p>概率流ODE的设计基于以下观察：</p>
        
        <div class="note-box">
            <h4>Fokker-Planck方程的分解</h4>
            <p>SDE对应的Fokker-Planck方程可以写成：</p>
            <div class="formula">
                $$\frac{\partial p_t}{\partial t} = -\nabla \cdot (p_t v_{total})$$
            </div>
            <p>其中总速度场：</p>
            <div class="formula">
                $$v_{total} = \underbrace{f(x,t)}_{\text{漂移}} - \underbrace{\frac{1}{2}g(t)^2\nabla\log p_t}_{\text{扩散修正}}$$
            </div>
        </div>
        
        <h4>SDE vs ODE：轨迹的差异</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">两种演化方式的对比</div>
            <table style="width: 100%; margin-top: 15px;">
                <tr>
                    <th style="width: 33%; text-align: left;">特性</th>
                    <th style="width: 33%; text-align: left;">SDE</th>
                    <th style="width: 34%; text-align: left;">概率流ODE</th>
                </tr>
                <tr>
                    <td>轨迹性质</td>
                    <td>随机、不可预测</td>
                    <td>确定性、可预测</td>
                </tr>
                <tr>
                    <td>计算复杂度</td>
                    <td>需要多次采样</td>
                    <td>单次求解即可</td>
                </tr>
                <tr>
                    <td>可逆性</td>
                    <td>统计意义上可逆</td>
                    <td>精确可逆</td>
                </tr>
                <tr>
                    <td>适用场景</td>
                    <td>生成多样性样本</td>
                    <td>图像编辑、插值</td>
                </tr>
            </table>
        </div>
        
        <h4>概率流ODE的优势</h4>
        
        <div class="example-box">
            <div class="example-title">为什么使用ODE？</div>
            <ol>
                <li><strong>精确编码</strong>：
                    <ul>
                        <li>可以将数据精确编码为潜在表示</li>
                        <li>支持语义操作和编辑</li>
                    </ul>
                </li>
                <li><strong>数值稳定性</strong>：
                    <ul>
                        <li>可以使用高阶ODE求解器</li>
                        <li>自适应步长控制</li>
                    </ul>
                </li>
                <li><strong>理论分析</strong>：
                    <ul>
                        <li>更容易分析收敛性</li>
                        <li>可以研究流形结构</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>与神经ODE的联系</h4>
        
        <div class="note-box">
            <h4>统一框架</h4>
            <p>概率流ODE可以看作一种特殊的神经ODE：</p>
            <ul>
                <li>状态：数据点 $x$</li>
                <li>时间：噪声水平 $t$</li>
                <li>动力学：由分数函数参数化</li>
            </ul>
            <p>这建立了扩散模型与连续深度模型之间的桥梁。</p>
        </div>
        
        <h3>5.4.2 概率流的性质</h3>
        
        <p>概率流ODE具有一系列优美的数学性质，这些性质使它成为理解和应用扩散模型的重要工具。</p>
        
        <h4>1. 体积保持性（Liouville定理）</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">概率质量守恒</div>
            <p>概率流保持相空间的体积元：</p>
            <div class="formula">
                $$\nabla \cdot v(x,t) = 0$$
            </div>
            <p>其中 $v(x,t) = f(x,t) - \frac{1}{2}g(t)^2\nabla\log p_t(x)$ 是速度场。</p>
            <p>这意味着：</p>
            <ul>
                <li>流动是不可压缩的</li>
                <li>局部概率密度沿流线保持不变</li>
                <li>拓扑性质得以保持</li>
            </ul>
        </div>
        
        <h4>2. 双射性与可逆性</h4>
        
        <div class="note-box">
            <h4>一一对应关系</h4>
            <p>概率流ODE建立了以下双射：</p>
            <ul>
                <li>$\phi_t: \mathcal{X}_0 \rightarrow \mathcal{X}_t$（前向流）</li>
                <li>$\phi_t^{-1}: \mathcal{X}_t \rightarrow \mathcal{X}_0$（反向流）</li>
            </ul>
            <p>每个数据点 $x_0$ 对应唯一的噪声表示 $x_T$，反之亦然。</p>
        </div>
        
        <h4>3. 最优传输视角</h4>
        
        <div class="example-box">
            <div class="example-title">动态最优传输</div>
            <p>在某些条件下，概率流ODE给出了从 $p_0$ 到 $p_T$ 的最优传输路径：</p>
            <ul>
                <li><strong>路径最短</strong>：在适当的度量下，流线是测地线</li>
                <li><strong>能量最优</strong>：最小化传输成本</li>
                <li><strong>保持结构</strong>：相邻点保持相邻</li>
            </ul>
        </div>
        
        <h4>4. 连续性与正则性</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">光滑演化</div>
            <p>如果分数函数 $\nabla\log p_t(x)$ 满足适当的正则性条件，则：</p>
            <ol>
                <li><strong>解的存在唯一性</strong>：给定初值，ODE有唯一解</li>
                <li><strong>连续依赖性</strong>：解连续依赖于初始条件</li>
                <li><strong>时间可逆性</strong>：可以精确地前向和后向求解</li>
            </ol>
        </div>
        
        <h4>5. 与Wasserstein梯度流的关系</h4>
        
        <div class="note-box">
            <h4>能量泛函的梯度流</h4>
            <p>概率流ODE可以理解为某个能量泛函的Wasserstein梯度流：</p>
            <div class="formula">
                $$\frac{\partial p_t}{\partial t} = \nabla \cdot \left(p_t \nabla \frac{\delta \mathcal{F}[p_t]}{\delta p_t}\right)$$
            </div>
            <p>其中 $\mathcal{F}[p]$ 是适当选择的能量泛函。</p>
        </div>
        
        <h4>6. 信息几何性质</h4>
        
        <div class="example-box">
            <div class="example-title">Fisher信息的演化</div>
            <p>沿着概率流，Fisher信息矩阵的演化遵循特定规律：</p>
            <ul>
                <li><strong>信息损失</strong>：前向流中Fisher信息单调递减</li>
                <li><strong>度量保持</strong>：某些几何结构得以保持</li>
                <li><strong>自然梯度</strong>：流动方向与自然梯度相关</li>
            </ul>
        </div>
        
        <h4>7. 数值性质</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">计算优势</div>
            <table style="width: 100%; margin-top: 15px;">
                <tr>
                    <th style="width: 50%; text-align: left;">性质</th>
                    <th style="width: 50%; text-align: left;">含义</th>
                </tr>
                <tr>
                    <td>Lipschitz连续性</td>
                    <td>数值稳定，可用标准ODE求解器</td>
                </tr>
                <tr>
                    <td>自适应步长</td>
                    <td>可根据局部误差调整步长</td>
                </tr>
                <tr>
                    <td>高阶方法适用</td>
                    <td>Runge-Kutta等方法有效</td>
                </tr>
                <tr>
                    <td>并行化友好</td>
                    <td>批量样本可并行处理</td>
                </tr>
            </table>
        </div>
        
        <h4>8. 语义插值性质</h4>
        
        <div class="note-box">
            <h4>平滑的语义过渡</h4>
            <p>概率流ODE的轨迹提供了自然的插值路径：</p>
            <ul>
                <li>两个数据点之间的插值通过其噪声表示的线性插值实现</li>
                <li>插值路径反映了数据流形的几何结构</li>
                <li>中间状态保持语义连贯性</li>
            </ul>
        </div>
        
        <h4>应用价值</h4>
        
        <div class="example-box">
            <div class="example-title">实际应用中的重要性</div>
            <ol>
                <li><strong>精确反演</strong>：可以精确重构原始数据</li>
                <li><strong>潜在空间操作</strong>：在噪声空间进行语义编辑</li>
                <li><strong>概率估计</strong>：通过变换公式计算似然</li>
                <li><strong>轨迹分析</strong>：研究生成过程的动力学</li>
            </ol>
        </div>
        
        <h3>5.4.3 ODE vs SDE：权衡与选择</h3>
        
        <p>在实际应用中，选择使用SDE还是概率流ODE需要考虑多个因素。每种方法都有其优势和局限性。</p>
        
        <h4>生成质量对比</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">质量-多样性权衡</div>
            <table style="width: 100%; margin-top: 15px;">
                <tr>
                    <th style="width: 25%; text-align: left;">方面</th>
                    <th style="width: 37.5%; text-align: left;">SDE</th>
                    <th style="width: 37.5%; text-align: left;">ODE</th>
                </tr>
                <tr>
                    <td><strong>样本质量</strong></td>
                    <td>通常更高，随机性有助于避免局部缺陷</td>
                    <td>可能陷入次优路径</td>
                </tr>
                <tr>
                    <td><strong>多样性</strong></td>
                    <td>自然产生多样化样本</td>
                    <td>确定性导致多样性受限</td>
                </tr>
                <tr>
                    <td><strong>模式覆盖</strong></td>
                    <td>更好地覆盖所有模式</td>
                    <td>可能错过某些模式</td>
                </tr>
                <tr>
                    <td><strong>细节保真度</strong></td>
                    <td>随机噪声可能模糊细节</td>
                    <td>精确轨迹保持细节</td>
                </tr>
            </table>
        </div>
        
        <h4>计算效率分析</h4>
        
        <div class="note-box">
            <h4>速度与精度的平衡</h4>
            <p><strong>SDE的计算特点：</strong></p>
            <ul>
                <li>需要固定的小步长（通常1000步）</li>
                <li>每步需要生成随机噪声</li>
                <li>难以使用自适应步长</li>
                <li>并行化效率高</li>
            </ul>
            <p><strong>ODE的计算特点：</strong></p>
            <ul>
                <li>可使用高阶求解器（如RK45）</li>
                <li>自适应步长大幅减少NFE</li>
                <li>通常只需100-200次函数评估</li>
                <li>数值误差可控</li>
            </ul>
        </div>
        
        <h4>应用场景适配</h4>
        
        <div class="example-box">
            <div class="example-title">选择指南</div>
            <p><strong>适合使用SDE的场景：</strong></p>
            <ol>
                <li><strong>纯生成任务</strong>：需要高质量、多样化的样本</li>
                <li><strong>数据增强</strong>：随机性带来的变化是优势</li>
                <li><strong>对抗鲁棒性</strong>：随机性增强模型鲁棒性</li>
                <li><strong>探索性应用</strong>：需要发现新的样本模式</li>
            </ol>
            <p><strong>适合使用ODE的场景：</strong></p>
            <ol>
                <li><strong>图像编辑</strong>：需要精确的编码-解码</li>
                <li><strong>插值任务</strong>：生成中间过渡状态</li>
                <li><strong>反演重构</strong>：从噪声恢复原始输入</li>
                <li><strong>可解释性研究</strong>：分析生成轨迹</li>
            </ol>
        </div>
        
        <h4>混合策略</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">结合两者优势</div>
            <p>实践中常用的混合策略：</p>
            <ol>
                <li><strong>分段切换</strong>：
                    <ul>
                        <li>早期阶段（高噪声）使用ODE快速去噪</li>
                        <li>后期阶段（低噪声）使用SDE精细化</li>
                    </ul>
                </li>
                <li><strong>温度调节</strong>：
                    <ul>
                        <li>引入温度参数 $\tau$ 控制随机性</li>
                        <li>$dx = f dt + \tau \cdot g dw$</li>
                        <li>$\tau=0$ 退化为ODE，$\tau=1$ 为标准SDE</li>
                    </ul>
                </li>
                <li><strong>条件切换</strong>：
                    <ul>
                        <li>根据当前状态的置信度动态选择</li>
                        <li>高置信区域用ODE，低置信区域用SDE</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>数值稳定性考虑</h4>
        
        <div class="note-box">
            <h4>数值挑战与解决方案</h4>
            <p><strong>SDE的数值挑战：</strong></p>
            <ul>
                <li>步长过大导致数值爆炸</li>
                <li>累积误差难以控制</li>
                <li>需要仔细选择离散化方案</li>
            </ul>
            <p><strong>ODE的数值挑战：</strong></p>
            <ul>
                <li>刚性问题需要隐式求解器</li>
                <li>分数函数的数值误差会累积</li>
                <li>需要监控局部截断误差</li>
            </ul>
        </div>
        
        <h4>理论保证对比</h4>
        
        <div class="example-box">
            <div class="example-title">收敛性分析</div>
            <table style="width: 100%; margin-top: 15px;">
                <tr>
                    <th style="width: 33%; text-align: left;">理论性质</th>
                    <th style="width: 33%; text-align: left;">SDE</th>
                    <th style="width: 34%; text-align: left;">ODE</th>
                </tr>
                <tr>
                    <td>收敛阶</td>
                    <td>弱收敛 O(√dt)</td>
                    <td>可达高阶 O(dt^p)</td>
                </tr>
                <tr>
                    <td>误差界</td>
                    <td>概率意义上的界</td>
                    <td>确定性误差界</td>
                </tr>
                <tr>
                    <td>长时间行为</td>
                    <td>遍历性保证</td>
                    <td>轨迹稳定性</td>
                </tr>
            </table>
        </div>
        
        <h4>实践建议</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">最佳实践总结</div>
            <ol>
                <li><strong>默认选择</strong>：对于大多数生成任务，SDE仍是首选</li>
                <li><strong>速度优先</strong>：当推理速度关键时，考虑ODE</li>
                <li><strong>精度要求</strong>：需要精确控制时使用ODE</li>
                <li><strong>实验验证</strong>：具体选择应基于实际效果</li>
                <li><strong>混合使用</strong>：不同阶段可以使用不同方法</li>
            </ol>
        </div>

        <h2>5.5 Fokker-Planck方程：密度视角</h2>
        
        <h3>5.5.1 从粒子到密度</h3>
        
        <p>Fokker-Planck方程提供了扩散过程的另一个视角：从跟踪单个粒子转向描述整体概率密度的演化。这是理解扩散模型的关键数学工具。</p>
        
        <h4>两种描述方式的对偶性</h4>
        
        <div class="note-box">
            <h4>微观 vs 宏观</h4>
            <table style="width: 100%; margin-top: 15px;">
                <tr>
                    <th style="width: 50%; text-align: left;">SDE（微观）</th>
                    <th style="width: 50%; text-align: left;">Fokker-Planck（宏观）</th>
                </tr>
                <tr>
                    <td>描述单个粒子的随机轨迹</td>
                    <td>描述概率密度的确定性演化</td>
                </tr>
                <tr>
                    <td>$dx_t = f(x_t,t)dt + g(t)dw_t$</td>
                    <td>$\frac{\partial p}{\partial t} = -\nabla \cdot (fp) + \frac{g^2}{2}\Delta p$</td>
                </tr>
                <tr>
                    <td>随机微分方程</td>
                    <td>偏微分方程</td>
                </tr>
            </table>
        </div>
        
        <h4>Fokker-Planck方程的推导直觉</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">守恒律视角</div>
            <p>Fokker-Planck方程本质上是概率的守恒律：</p>
            <div class="formula">
                $$\frac{\partial p}{\partial t} + \nabla \cdot J = 0$$
            </div>
            <p>其中概率流 $J$ 包含两部分：</p>
            <ul>
                <li><strong>漂移流</strong>：$J_{drift} = f(x,t)p(x,t)$</li>
                <li><strong>扩散流</strong>：$J_{diff} = -\frac{g(t)^2}{2}\nabla p(x,t)$</li>
            </ul>
        </div>
        
        <h4>标准形式与物理意义</h4>
        
        <p>对于一般的SDE，Fokker-Planck方程为：</p>
        
        <div class="formula">
            $$\frac{\partial p(x,t)}{\partial t} = -\sum_i \frac{\partial}{\partial x_i}[f_i(x,t)p(x,t)] + \frac{1}{2}\sum_{i,j}\frac{\partial^2}{\partial x_i \partial x_j}[g_{ij}(t)p(x,t)]$$
        </div>
        
        <div class="example-box">
            <div class="example-title">各项的物理解释</div>
            <ul>
                <li><strong>时间导数项</strong> $\frac{\partial p}{\partial t}$：密度的局部变化率</li>
                <li><strong>对流项</strong> $-\nabla \cdot (fp)$：由确定性漂移引起的概率流动</li>
                <li><strong>扩散项</strong> $\frac{g^2}{2}\Delta p$：由随机涨落引起的概率扩散</li>
            </ul>
        </div>
        
        <h4>特殊情况：线性Fokker-Planck方程</h4>
        
        <p>对于扩散模型中常见的线性SDE：</p>
        <div class="formula">
            $$dx = -\frac{\beta(t)}{2}x dt + \sqrt{\beta(t)}dw$$
        </div>
        
        <p>对应的Fokker-Planck方程是：</p>
        <div class="formula">
            $$\frac{\partial p}{\partial t} = \frac{\beta(t)}{2}\nabla \cdot (xp) + \frac{\beta(t)}{2}\Delta p$$
        </div>
        
        <div class="note-box">
            <h4>解的高斯性</h4>
            <p>线性Fokker-Planck方程的一个重要性质是：如果初始分布是高斯的，那么任意时刻的分布都保持高斯形式。这解释了为什么扩散模型的前向过程最终收敛到高斯分布。</p>
        </div>
        
        <h4>与热方程的联系</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">扩散作为热传导</div>
            <p>在纯扩散情况下（$f=0$），Fokker-Planck方程退化为热方程：</p>
            <div class="formula">
                $$\frac{\partial p}{\partial t} = D\Delta p$$
            </div>
            <p>这建立了以下类比：</p>
            <ul>
                <li>概率密度 ↔ 温度分布</li>
                <li>扩散系数 ↔ 热导率</li>
                <li>概率流 ↔ 热流</li>
            </ul>
        </div>
        
        <h4>稳态与平衡分布</h4>
        
        <div class="example-box">
            <div class="example-title">长时间行为</div>
            <p>当 $t \to \infty$ 时，系统趋向稳态：$\frac{\partial p}{\partial t} = 0$</p>
            <p>稳态分布 $p_\infty(x)$ 满足：</p>
            <div class="formula">
                $$\nabla \cdot (f p_\infty) = \frac{g^2}{2}\Delta p_\infty$$
            </div>
            <p>对于扩散模型，这通常是标准高斯分布 $\mathcal{N}(0,I)$。</p>
        </div>
        
        <h4>边界条件的重要性</h4>
        
        <div class="note-box">
            <h4>自然边界条件</h4>
            <p>在 $\mathbb{R}^d$ 上，通常采用自然边界条件：</p>
            <ul>
                <li>$p(x,t) \to 0$ 当 $|x| \to \infty$</li>
                <li>$\int_{\mathbb{R}^d} p(x,t)dx = 1$（概率守恒）</li>
            </ul>
            <p>这些条件确保了物理意义和数学良定性。</p>
        </div>
        
        <h4>数值求解的挑战</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">维数灾难</div>
            <p>直接求解Fokker-Planck方程面临严重的维数灾难：</p>
            <ul>
                <li>对于 $d$ 维问题，计算复杂度为 $O(N^d)$</li>
                <li>存储需求随维数指数增长</li>
                <li>高维空间中的数值格式不稳定</li>
            </ul>
            <p>这就是为什么扩散模型选择通过学习分数函数来间接求解。</p>
        </div>
        
        <h3>5.5.2 Fokker-Planck方程的推导</h3>
        
        <p>Fokker-Planck方程的推导展示了随机过程与偏微分方程之间的深刻联系。这里我们从直观到严格，逐步推导这个方程。</p>
        
        <h4>方法一：从Chapman-Kolmogorov方程出发</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">基本思路</div>
            <p>考虑转移概率密度 $p(x,t|x_0,t_0)$，它满足Chapman-Kolmogorov方程：</p>
            <div class="formula">
                $$p(x,t+\Delta t|x_0,t_0) = \int p(x,t+\Delta t|y,t)p(y,t|x_0,t_0)dy$$
            </div>
            <p>对小时间步 $\Delta t$，展开转移核并取极限即可得到Fokker-Planck方程。</p>
        </div>
        
        <h4>方法二：Itô公式方法（更直观）</h4>
        
        <p>这是理解Fokker-Planck方程的现代方法：</p>
        
        <div class="note-box">
            <h4>核心步骤</h4>
            <ol>
                <li><strong>考虑测试函数</strong>：对任意光滑函数 $\phi(x)$，计算期望值的演化</li>
                <li><strong>应用Itô公式</strong>：
                    <div class="formula">
                        $$d\phi(x_t) = \nabla\phi \cdot dx_t + \frac{1}{2}\text{Tr}(\nabla^2\phi \cdot d\langle x\rangle_t)$$
                    </div>
                </li>
                <li><strong>取期望</strong>：利用 $\mathbb{E}[dw_t] = 0$</li>
                <li><strong>分部积分</strong>：将作用在 $\phi$ 上的算子转移到 $p$ 上</li>
            </ol>
        </div>
        
        <h4>详细推导：一维情况</h4>
        
        <div class="example-box">
            <div class="example-title">从SDE到Fokker-Planck</div>
            <p>设一维SDE为：$dx_t = f(x_t,t)dt + g(t)dw_t$</p>
            
            <p><strong>步骤1</strong>：对测试函数 $\phi(x)$ 应用Itô公式</p>
            <div class="formula">
                $$d\phi(x_t) = \phi'(x_t)dx_t + \frac{1}{2}\phi''(x_t)(dx_t)^2$$
            </div>
            
            <p><strong>步骤2</strong>：计算二次变分 $(dx_t)^2 = g(t)^2dt$</p>
            
            <p><strong>步骤3</strong>：代入并取期望</p>
            <div class="formula">
                $$\frac{d}{dt}\mathbb{E}[\phi(x_t)] = \mathbb{E}[f(x_t,t)\phi'(x_t) + \frac{g(t)^2}{2}\phi''(x_t)]$$
            </div>
            
            <p><strong>步骤4</strong>：用密度函数表示期望</p>
            <div class="formula">
                $$\frac{d}{dt}\int \phi(x)p(x,t)dx = \int \left[f(x,t)\phi'(x) + \frac{g(t)^2}{2}\phi''(x)\right]p(x,t)dx$$
            </div>
            
            <p><strong>步骤5</strong>：分部积分</p>
            <div class="formula">
                $$\int \phi(x)\frac{\partial p}{\partial t}dx = \int \phi(x)\left[-\frac{\partial}{\partial x}(f p) + \frac{g^2}{2}\frac{\partial^2 p}{\partial x^2}\right]dx$$
            </div>
            
            <p>由于 $\phi$ 任意，得到Fokker-Planck方程。</p>
        </div>
        
        <h4>高维推广</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">多维Fokker-Planck方程</div>
            <p>对于 $d$ 维SDE：$dx_i = f_i(x,t)dt + \sum_j g_{ij}(t)dw_j$</p>
            <p>Fokker-Planck方程为：</p>
            <div class="formula">
                $$\frac{\partial p}{\partial t} = -\sum_i \frac{\partial}{\partial x_i}(f_i p) + \frac{1}{2}\sum_{i,j}\frac{\partial^2}{\partial x_i \partial x_j}(D_{ij}p)$$
            </div>
            <p>其中扩散矩阵 $D_{ij} = \sum_k g_{ik}g_{jk}$。</p>
        </div>
        
        <h4>反向Fokker-Planck方程</h4>
        
        <div class="note-box">
            <h4>时间反演</h4>
            <p>对于反向SDE，对应的Fokker-Planck方程（也称为Kolmogorov反向方程）是：</p>
            <div class="formula">
                $$-\frac{\partial p}{\partial t} = f \cdot \nabla p + \frac{g^2}{2}\Delta p$$
            </div>
            <p>注意时间导数的符号变化，这反映了时间反演的本质。</p>
        </div>
        
        <h4>与分数函数的关系</h4>
        
        <div class="example-box">
            <div class="example-title">分数函数的出现</div>
            <p>Fokker-Planck方程可以重写为：</p>
            <div class="formula">
                $$\frac{\partial p}{\partial t} = -\nabla \cdot \left[p\left(f - \frac{g^2}{2}\nabla \log p\right)\right] - \frac{g^2}{2}\Delta p$$
            </div>
            <p>这里自然出现了分数函数 $\nabla \log p$，暗示了它在扩散过程中的核心作用。</p>
        </div>
        
        <h4>物理解释：概率流的分解</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">流的物理图像</div>
            <p>Fokker-Planck方程描述了两种概率流的竞争：</p>
            <ul>
                <li><strong>确定性流</strong>：由漂移 $f(x,t)$ 驱动，可以聚集或分散概率</li>
                <li><strong>扩散流</strong>：总是使概率分散，趋向均匀分布</li>
            </ul>
            <p>扩散模型巧妙地平衡这两种流，实现数据与噪声之间的可逆转换。</p>
        </div>
        
        <h4>数学性质</h4>
        
        <div class="note-box">
            <h4>重要性质</h4>
            <ol>
                <li><strong>线性性</strong>：Fokker-Planck方程对 $p$ 是线性的</li>
                <li><strong>保正性</strong>：如果初值 $p_0 \geq 0$，则 $p_t \geq 0$ 对所有 $t$ 成立</li>
                <li><strong>质量守恒</strong>：$\int p(x,t)dx = 1$ 对所有 $t$ 成立</li>
                <li><strong>最大值原理</strong>：密度的最大值不会增加（纯扩散情况）</li>
            </ol>
        </div>
        
        <h3>5.5.3 与分数函数的联系</h3>
        
        <p>Fokker-Planck方程与分数函数之间存在深刻的联系。这种联系不仅是数学上的巧合，更揭示了扩散模型的核心机制。</p>
        
        <h4>分数函数在Fokker-Planck方程中的出现</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">概率流的分解</div>
            <p>Fokker-Planck方程可以写成流的形式：</p>
            <div class="formula">
                $$\frac{\partial p}{\partial t} = -\nabla \cdot J$$
            </div>
            <p>其中总概率流 $J$ 可以分解为：</p>
            <div class="formula">
                $$J = \underbrace{fp}_{\text{漂移流}} - \underbrace{\frac{g^2}{2}\nabla p}_{\text{扩散流}} = p\left(f - \frac{g^2}{2}\nabla \log p\right)$$
            </div>
            <p>这里自然出现了分数函数 $\nabla \log p$。</p>
        </div>
        
        <h4>分数函数的物理意义</h4>
        
        <div class="note-box">
            <h4>三种解释</h4>
            <ol>
                <li><strong>热力学力</strong>：分数函数代表将系统推向平衡态的"力"</li>
                <li><strong>信息梯度</strong>：指向信息含量增加的方向</li>
                <li><strong>最可能路径</strong>：在给定约束下的最可能演化方向</li>
            </ol>
        </div>
        
        <h4>稳态条件与分数函数</h4>
        
        <div class="example-box">
            <div class="example-title">平衡态的特征</div>
            <p>在稳态（$\frac{\partial p}{\partial t} = 0$）时，概率流必须为零：</p>
            <div class="formula">
                $$J = p\left(f - \frac{g^2}{2}\nabla \log p\right) = 0$$
            </div>
            <p>这给出稳态条件：</p>
            <div class="formula">
                $$f(x) = \frac{g^2}{2}\nabla \log p_{\infty}(x)$$
            </div>
            <p>即漂移必须恰好平衡扩散引起的概率流出。</p>
        </div>
        
        <h4>分数函数与熵产生</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">熵的演化</div>
            <p>相对熵（KL散度）的时间导数为：</p>
            <div class="formula">
                $$\frac{d}{dt}D_{KL}(p_t \| p_{\infty}) = -\int p_t |\nabla \log p_t - \nabla \log p_{\infty}|^2 dx \leq 0$$
            </div>
            <p>这表明：</p>
            <ul>
                <li>分数函数的差异驱动系统向平衡态演化</li>
                <li>演化速率正比于分数函数差的平方</li>
                <li>当且仅当 $p_t = p_{\infty}$ 时演化停止</li>
            </ul>
        </div>
        
        <h4>反向过程中分数函数的作用</h4>
        
        <div class="note-box">
            <h4>时间反演的关键</h4>
            <p>考虑前向Fokker-Planck方程：</p>
            <div class="formula">
                $$\frac{\partial p}{\partial t} = -\nabla \cdot (fp) + \frac{g^2}{2}\Delta p$$
            </div>
            <p>对应的反向Fokker-Planck方程需要额外的分数项：</p>
            <div class="formula">
                $$\frac{\partial p}{\partial \tau} = -\nabla \cdot \left[\left(-f + g^2\nabla \log p\right)p\right] + \frac{g^2}{2}\Delta p$$
            </div>
            <p>分数函数 $\nabla \log p$ 提供了反向演化所需的"信息"。</p>
        </div>
        
        <h4>分数匹配与Fokker-Planck方程</h4>
        
        <div class="example-box">
            <div class="example-title">学习目标的等价性</div>
            <p>扩散模型的训练可以从两个角度理解：</p>
            <ol>
                <li><strong>分数匹配</strong>：最小化 $\mathbb{E}_{p_t}[|\nabla \log p_t - s_\theta|^2]$</li>
                <li><strong>密度演化</strong>：使神经网络参数化的流满足Fokker-Planck方程</li>
            </ol>
            <p>这两个目标在数学上是等价的。</p>
        </div>
        
        <h4>变分视角：最小作用量原理</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">Onsager-Machlup泛函</div>
            <p>扩散过程的路径概率可以用作用量表示：</p>
            <div class="formula">
                $$S[x] = \int_0^T \left[\frac{|\dot{x} - f|^2}{2g^2} - \frac{1}{2}\nabla \cdot f\right]dt$$
            </div>
            <p>分数函数通过Fokker-Planck方程进入这个作用量，决定了最可能的演化路径。</p>
        </div>
        
        <h4>计算优势</h4>
        
        <div class="note-box">
            <h4>为什么学习分数而非密度</h4>
            <ol>
                <li><strong>局部性</strong>：分数函数只需要局部信息，而密度需要全局归一化</li>
                <li><strong>维数可扩展</strong>：分数匹配避免了高维空间的积分</li>
                <li><strong>数值稳定</strong>：梯度估计比密度估计更稳定</li>
                <li><strong>训练简单</strong>：去噪任务提供了自然的训练信号</li>
            </ol>
        </div>
        
        <h4>总结：分数函数的中心地位</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">统一视角</div>
            <p>分数函数 $\nabla \log p$ 是连接多个概念的桥梁：</p>
            <ul>
                <li><strong>SDE视角</strong>：使反向过程成为可能</li>
                <li><strong>PDE视角</strong>：出现在Fokker-Planck方程中</li>
                <li><strong>ODE视角</strong>：定义概率流的速度场</li>
                <li><strong>优化视角</strong>：提供了可学习的参数化</li>
                <li><strong>几何视角</strong>：是概率流形上的切向量</li>
            </ul>
            <p>理解这些联系是掌握连续时间扩散模型的关键。</p>
        </div>

        <h2>5.6 统一框架：Score SDE</h2>
        
        <h3>5.6.1 VP-SDE、VE-SDE和sub-VP-SDE</h3>
        
        <p>Score SDE框架统一了各种扩散模型，将它们表示为不同的SDE选择。这里介绍三种主要的SDE类型及其特点。</p>
        
        <h4>VP-SDE（Variance Preserving）</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">方差保持SDE</div>
            <p>VP-SDE对应于DDPM，其形式为：</p>
            <div class="formula">
                $$dx = -\frac{1}{2}\beta(t)x dt + \sqrt{\beta(t)}dw$$
            </div>
            <p>其中 $\beta(t)$ 是噪声调度函数。</p>
            <p><strong>关键性质</strong>：</p>
            <ul>
                <li>保持信号和噪声的总方差近似为1</li>
                <li>边缘分布：$p(x_t|x_0) = \mathcal{N}(\sqrt{\bar{\alpha}_t}x_0, (1-\bar{\alpha}_t)I)$</li>
                <li>终态分布：$p(x_T) \approx \mathcal{N}(0, I)$</li>
            </ul>
        </div>
        
        <h4>VE-SDE（Variance Exploding）</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">方差爆炸SDE</div>
            <p>VE-SDE对应于NCSN/SMLD，其形式为：</p>
            <div class="formula">
                $$dx = \sqrt{\frac{d[\sigma^2(t)]}{dt}}dw$$
            </div>
            <p>其中 $\sigma(t)$ 是递增的噪声水平函数。</p>
            <p><strong>关键性质</strong>：</p>
            <ul>
                <li>没有漂移项，纯扩散过程</li>
                <li>边缘分布：$p(x_t|x_0) = \mathcal{N}(x_0, \sigma^2(t)I)$</li>
                <li>方差随时间单调增加至无穷</li>
            </ul>
        </div>
        
        <h4>sub-VP-SDE</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">次方差保持SDE</div>
            <p>sub-VP-SDE是VP-SDE的连续时间极限：</p>
            <div class="formula">
                $$dx = -\frac{1}{2}\beta(t)x dt + \sqrt{\beta(t)(1-e^{-2\int_0^t \beta(s)ds})}dw$$
            </div>
            <p><strong>关键性质</strong>：</p>
            <ul>
                <li>更精确地保持离散DDPM的边缘分布</li>
                <li>扩散系数依赖于历史</li>
                <li>数值稳定性更好</li>
            </ul>
        </div>
        
        <h4>三种SDE的比较</h4>
        
        <div class="example-box">
            <div class="example-title">特性对比</div>
            <table style="width: 100%; margin-top: 15px;">
                <tr>
                    <th style="width: 25%; text-align: left;">特性</th>
                    <th style="width: 25%; text-align: left;">VP-SDE</th>
                    <th style="width: 25%; text-align: left;">VE-SDE</th>
                    <th style="width: 25%; text-align: left;">sub-VP-SDE</th>
                </tr>
                <tr>
                    <td>漂移项</td>
                    <td>线性</td>
                    <td>无</td>
                    <td>线性</td>
                </tr>
                <tr>
                    <td>扩散系数</td>
                    <td>$\sqrt{\beta(t)}$</td>
                    <td>$\sqrt{\dot{\sigma}^2(t)}$</td>
                    <td>状态依赖</td>
                </tr>
                <tr>
                    <td>终态分布</td>
                    <td>$\mathcal{N}(0,I)$</td>
                    <td>$\mathcal{N}(0,\sigma_T^2 I)$</td>
                    <td>$\mathcal{N}(0,I)$</td>
                </tr>
                <tr>
                    <td>计算效率</td>
                    <td>高</td>
                    <td>最高</td>
                    <td>中等</td>
                </tr>
            </table>
        </div>
        
        <h4>噪声调度的选择</h4>
        
        <div class="note-box">
            <h4>常用的噪声调度</h4>
            <p><strong>VP-SDE的β调度</strong>：</p>
            <ul>
                <li>线性：$\beta(t) = \beta_{min} + t(\beta_{max} - \beta_{min})$</li>
                <li>余弦：$\beta(t) = \beta_{max} \cdot \sin^2(\frac{\pi t}{2T})$</li>
                <li>改进线性：考虑信噪比的平滑变化</li>
            </ul>
            <p><strong>VE-SDE的σ调度</strong>：</p>
            <ul>
                <li>几何级数：$\sigma_i = \sigma_{min} \cdot (\sigma_{max}/\sigma_{min})^{i/N}$</li>
                <li>多项式：$\sigma(t) = \sigma_{min} + t^p(\sigma_{max} - \sigma_{min})$</li>
            </ul>
        </div>
        
        <h4>选择指南</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">何时使用哪种SDE</div>
            <ol>
                <li><strong>VP-SDE</strong>：
                    <ul>
                        <li>标准选择，适合大多数任务</li>
                        <li>训练稳定，理论完善</li>
                        <li>与DDPM兼容</li>
                    </ul>
                </li>
                <li><strong>VE-SDE</strong>：
                    <ul>
                        <li>需要精确控制噪声水平</li>
                        <li>多尺度建模</li>
                        <li>计算效率要求高</li>
                    </ul>
                </li>
                <li><strong>sub-VP-SDE</strong>：
                    <ul>
                        <li>需要精确匹配离散模型</li>
                        <li>理论研究</li>
                        <li>高精度要求</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>统一视角的优势</h4>
        
        <div class="example-box">
            <div class="example-title">Score SDE框架的贡献</div>
            <ul>
                <li><strong>理论统一</strong>：不同方法只是SDE的不同选择</li>
                <li><strong>灵活设计</strong>：可以设计新的SDE形式</li>
                <li><strong>统一训练</strong>：相同的分数匹配目标</li>
                <li><strong>统一采样</strong>：通用的求解器（如PC采样器）</li>
            </ul>
        </div>
        
        <h3>5.6.2 离散模型作为SDE的特例</h3>
        
        <p>一个深刻的洞察是：所有离散时间的扩散模型都可以看作连续SDE的数值离散化。这个视角不仅统一了理论，还指导了算法改进。</p>
        
        <h4>DDPM与VP-SDE的对应关系</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">从离散到连续</div>
            <p>DDPM的前向过程：</p>
            <div class="formula">
                $$x_t = \sqrt{\alpha_t}x_{t-1} + \sqrt{1-\alpha_t}\epsilon_t$$
            </div>
            <p>当时间步 $\Delta t \to 0$ 时，设 $\alpha_t = 1 - \beta_t\Delta t$，可得：</p>
            <div class="formula">
                $$\frac{x_t - x_{t-1}}{\Delta t} \approx -\frac{\beta_t}{2}x_t + \frac{\sqrt{\beta_t}}{\sqrt{\Delta t}}\epsilon_t$$
            </div>
            <p>这正是VP-SDE的Euler-Maruyama离散化。</p>
        </div>
        
        <h4>NCSN与VE-SDE的对应关系</h4>
        
        <div class="note-box">
            <h4>多尺度噪声的连续化</h4>
            <p>NCSN使用离散的噪声水平 $\{\sigma_i\}_{i=1}^L$，每个水平对应一个加噪分布：</p>
            <div class="formula">
                $$p_{\sigma_i}(x|x_0) = \mathcal{N}(x_0, \sigma_i^2 I)$$
            </div>
            <p>当 $L \to \infty$ 且噪声水平连续化时，得到VE-SDE：</p>
            <div class="formula">
                $$dx = \sqrt{\frac{d\sigma^2(t)}{dt}}dw$$
            </div>
        </div>
        
        <h4>离散化误差分析</h4>
        
        <div class="example-box">
            <div class="example-title">数值格式的影响</div>
            <table style="width: 100%; margin-top: 15px;">
                <tr>
                    <th style="width: 33%; text-align: left;">离散化方法</th>
                    <th style="width: 33%; text-align: left;">局部误差</th>
                    <th style="width: 34%; text-align: left;">特点</th>
                </tr>
                <tr>
                    <td>Euler-Maruyama</td>
                    <td>$O(\Delta t)$</td>
                    <td>简单但精度低</td>
                </tr>
                <tr>
                    <td>Heun方法</td>
                    <td>$O(\Delta t^2)$</td>
                    <td>需要两次函数评估</td>
                </tr>
                <tr>
                    <td>随机Runge-Kutta</td>
                    <td>$O(\Delta t^{3/2})$</td>
                    <td>高精度但复杂</td>
                </tr>
            </table>
        </div>
        
        <h4>时间步的选择</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">离散步数与连续时间</div>
            <p>离散模型的步数 $T$ 与连续时间的关系：</p>
            <ul>
                <li><strong>DDPM</strong>：通常 $T=1000$，对应连续时间 $[0,1]$</li>
                <li><strong>改进DDPM</strong>：$T=4000$，更好地逼近连续极限</li>
                <li><strong>连续模型</strong>：$T \to \infty$，完全连续</li>
            </ul>
            <p>步数越多，离散模型越接近连续SDE，但计算成本也越高。</p>
        </div>
        
        <h4>训练目标的统一</h4>
        
        <div class="note-box">
            <h4>分数匹配的一致性</h4>
            <p>无论是离散还是连续模型，训练目标都是分数匹配：</p>
            <ul>
                <li><strong>DDPM</strong>：$\mathcal{L} = \mathbb{E}_{t,x_0,\epsilon}[\|\epsilon - \epsilon_\theta(x_t, t)\|^2]$</li>
                <li><strong>Score SDE</strong>：$\mathcal{L} = \mathbb{E}_{t,x_0,x_t}[\|s_\theta(x_t, t) - \nabla \log p_{t|0}(x_t|x_0)\|^2]$</li>
            </ul>
            <p>两者通过关系 $\epsilon = -\sigma_t \nabla \log p_{t|0}$ 联系起来。</p>
        </div>
        
        <h4>采样算法的继承</h4>
        
        <div class="example-box">
            <div class="example-title">从离散到连续的算法迁移</div>
            <ol>
                <li><strong>DDPM采样</strong> → <strong>SDE求解器</strong>：
                    <ul>
                        <li>祖先采样 → Euler-Maruyama方法</li>
                        <li>DDIM → 概率流ODE</li>
                    </ul>
                </li>
                <li><strong>加速技巧</strong>：
                    <ul>
                        <li>步长调整在连续框架下更自然</li>
                        <li>自适应求解器可以自动选择步长</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>连续视角的优势</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">为什么采用连续框架？</div>
            <ol>
                <li><strong>理论优势</strong>：
                    <ul>
                        <li>更清晰的数学结构</li>
                        <li>丰富的SDE/PDE理论可用</li>
                        <li>更容易分析收敛性</li>
                    </ul>
                </li>
                <li><strong>算法优势</strong>：
                    <ul>
                        <li>可以使用成熟的ODE/SDE求解器</li>
                        <li>自适应时间步长</li>
                        <li>高阶数值方法</li>
                    </ul>
                </li>
                <li><strong>灵活性</strong>：
                    <ul>
                        <li>容易设计新的SDE</li>
                        <li>可以在不同SDE之间转换</li>
                        <li>统一的训练和采样框架</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>实践指南</h4>
        
        <div class="note-box">
            <h4>何时使用离散vs连续</h4>
            <ul>
                <li><strong>使用离散模型</strong>：
                    <ul>
                        <li>已有成熟的离散实现</li>
                        <li>固定步数的应用场景</li>
                        <li>需要与现有DDPM代码兼容</li>
                    </ul>
                </li>
                <li><strong>使用连续模型</strong>：
                    <ul>
                        <li>需要灵活的时间步长</li>
                        <li>追求理论优雅性</li>
                        <li>探索新的模型设计</li>
                    </ul>
                </li>
            </ul>
        </div>
        
        <h3>5.6.3 新的可能性</h3>
        
        <p>Score SDE框架不仅统一了现有方法，更重要的是开启了设计新型扩散模型的大门。这里探讨一些令人兴奋的新方向。</p>
        
        <h4>设计新的SDE</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">超越标准选择</div>
            <p>除了VP-SDE和VE-SDE，我们可以设计具有特殊性质的新SDE：</p>
            <ol>
                <li><strong>自适应SDE</strong>：
                    <div class="formula">
                        $$dx = f(x,t,\text{SNR}(x))dt + g(t,\text{SNR}(x))dw$$
                    </div>
                    <p>根据局部信噪比调整扩散速率</p>
                </li>
                <li><strong>各向异性SDE</strong>：
                    <div class="formula">
                        $$dx = f(x,t)dt + G(x,t)dw$$
                    </div>
                    <p>$G$是状态依赖的扩散矩阵，不同方向扩散速率不同</p>
                </li>
                <li><strong>非线性SDE</strong>：
                    <div class="formula">
                        $$dx = -\nabla V(x)dt + \sqrt{2T(t)}dw$$
                    </div>
                    <p>引入势能函数$V(x)$，实现特定的稳态分布</p>
                </li>
            </ol>
        </div>
        
        <h4>混合采样策略</h4>
        
        <div class="note-box">
            <h4>SDE-ODE混合</h4>
            <p>在生成过程的不同阶段使用不同的动力学：</p>
            <ul>
                <li><strong>初始阶段（高噪声）</strong>：使用ODE快速确定大致结构</li>
                <li><strong>中间阶段</strong>：使用SDE增加多样性</li>
                <li><strong>最终阶段（低噪声）</strong>：再次使用ODE精确细节</li>
            </ul>
            <p>这种策略结合了两者的优势：速度、质量和多样性。</p>
        </div>
        
        <h4>条件生成的新方法</h4>
        
        <div class="example-box">
            <div class="example-title">通过修改SDE实现条件生成</div>
            <ol>
                <li><strong>引导漂移</strong>：
                    <div class="formula">
                        $$dx = [f(x,t) + \lambda\nabla\log p(y|x)]dt + g(t)dw$$
                    </div>
                    <p>在漂移项中加入条件信息</p>
                </li>
                <li><strong>条件扩散</strong>：
                    <div class="formula">
                        $$dx = f(x,t)dt + g(t,y)dw$$
                    </div>
                    <p>扩散系数依赖于条件$y$</p>
                </li>
                <li><strong>约束SDE</strong>：
                    <p>在流形上定义SDE，自动满足某些约束</p>
                </li>
            </ol>
        </div>
        
        <h4>加速采样的创新</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">新型求解器设计</div>
            <ul>
                <li><strong>预测-校正方法</strong>：
                    <ol>
                        <li>预测步：使用高阶ODE求解器</li>
                        <li>校正步：使用少量Langevin动力学步骤</li>
                    </ol>
                </li>
                <li><strong>自适应时间重参数化</strong>：
                    <p>在关键区域（如$t \approx 0$）使用更密集的时间步</p>
                </li>
                <li><strong>学习型求解器</strong>：
                    <p>使用神经网络学习最优的离散化方案</p>
                </li>
            </ul>
        </div>
        
        <h4>多模态扩散</h4>
        
        <div class="note-box">
            <h4>不同模态的联合建模</h4>
            <p>设计处理多种数据类型的统一SDE：</p>
            <ul>
                <li><strong>图像-文本联合SDE</strong>：不同模态使用不同的扩散速率</li>
                <li><strong>层次化SDE</strong>：粗粒度和细粒度特征的分层扩散</li>
                <li><strong>图结构SDE</strong>：在图上定义的扩散过程</li>
            </ul>
        </div>
        
        <h4>理论创新方向</h4>
        
        <div class="example-box">
            <div class="example-title">推动理论边界</div>
            <ol>
                <li><strong>最优传输视角</strong>：
                    <ul>
                        <li>设计最小化传输成本的SDE</li>
                        <li>学习数据流形间的最优映射</li>
                    </ul>
                </li>
                <li><strong>信息几何</strong>：
                    <ul>
                        <li>在概率流形上设计测地线SDE</li>
                        <li>利用Fisher信息优化扩散路径</li>
                    </ul>
                </li>
                <li><strong>控制论方法</strong>：
                    <ul>
                        <li>将生成过程视为最优控制问题</li>
                        <li>学习最优的控制策略</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>实际应用的新可能</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">突破性应用</div>
            <ol>
                <li><strong>科学计算</strong>：
                    <ul>
                        <li>分子动力学模拟</li>
                        <li>量子系统建模</li>
                        <li>气候模型</li>
                    </ul>
                </li>
                <li><strong>逆问题求解</strong>：
                    <ul>
                        <li>医学成像重建</li>
                        <li>地震波反演</li>
                        <li>超分辨率</li>
                    </ul>
                </li>
                <li><strong>生成式设计</strong>：
                    <ul>
                        <li>材料设计</li>
                        <li>药物发现</li>
                        <li>建筑设计</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>未来展望</h4>
        
        <div class="note-box">
            <h4>连续时间框架的潜力</h4>
            <p>Score SDE框架为扩散模型开辟了广阔的研究空间：</p>
            <ul>
                <li><strong>理论深度</strong>：与数学物理的深度连接还有待挖掘</li>
                <li><strong>算法创新</strong>：新的数值方法和优化技术</li>
                <li><strong>应用广度</strong>：从图像生成到科学计算的全方位应用</li>
                <li><strong>硬件协同</strong>：为专用硬件设计的SDE</li>
            </ul>
            <p>这个框架不仅是技术工具，更是理解生成模型的新范式。</p>
        </div>

        <h2>5.7 数值方法与实现</h2>
        
        <h3>5.7.1 SDE的数值解法</h3>
        
        <p>准确高效地求解SDE是实现扩散模型的关键。这里介绍主要的数值方法及其在扩散模型中的应用。</p>
        
        <h4>Euler-Maruyama方法</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">最基本的SDE求解器</div>
            <p>对于SDE：$dx = f(x,t)dt + g(t)dw$</p>
            <p>Euler-Maruyama离散化为：</p>
            <div class="formula">
                $$x_{n+1} = x_n + f(x_n, t_n)\Delta t + g(t_n)\sqrt{\Delta t}\cdot z_n$$
            </div>
            <p>其中 $z_n \sim \mathcal{N}(0, I)$。</p>
            <p><strong>特点</strong>：</p>
            <ul>
                <li>实现简单，计算效率高</li>
                <li>强收敛阶：$O(\sqrt{\Delta t})$</li>
                <li>弱收敛阶：$O(\Delta t)$</li>
                <li>对于线性SDE是精确的</li>
            </ul>
        </div>
        
        <h4>Heun方法（改进Euler）</h4>
        
        <div class="note-box">
            <h4>预测-校正方法</h4>
            <p>Heun方法通过两步提高精度：</p>
            <ol>
                <li><strong>预测步</strong>：
                    <div class="formula">
                        $$\tilde{x}_{n+1} = x_n + f(x_n, t_n)\Delta t + g(t_n)\sqrt{\Delta t}\cdot z_n$$
                    </div>
                </li>
                <li><strong>校正步</strong>：
                    <div class="formula">
                        $$x_{n+1} = x_n + \frac{1}{2}[f(x_n, t_n) + f(\tilde{x}_{n+1}, t_{n+1})]\Delta t + g(t_n)\sqrt{\Delta t}\cdot z_n$$
                    </div>
                </li>
            </ol>
            <p>弱收敛阶提高到 $O(\Delta t^2)$。</p>
        </div>
        
        <h4>随机Runge-Kutta方法</h4>
        
        <div class="example-box">
            <div class="example-title">高阶方法</div>
            <p>类似于确定性ODE的Runge-Kutta方法，但需要考虑随机积分：</p>
            <ul>
                <li><strong>阶数选择</strong>：通常使用1.5阶或2.5阶方法</li>
                <li><strong>计算成本</strong>：每步需要多次函数评估</li>
                <li><strong>稳定性</strong>：对刚性问题更稳定</li>
            </ul>
            <p>适用于需要高精度的场景，但计算成本较高。</p>
        </div>
        
        <h4>指数积分器</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">利用线性结构</div>
            <p>对于具有线性漂移的SDE（如VP-SDE）：</p>
            <div class="formula">
                $$dx = -\frac{\beta(t)}{2}x dt + \sqrt{\beta(t)}dw$$
            </div>
            <p>可以精确积分线性部分：</p>
            <div class="formula">
                $$x_{n+1} = e^{-\frac{1}{2}\int_{t_n}^{t_{n+1}}\beta(s)ds} x_n + \text{随机项}$$
            </div>
            <p><strong>优势</strong>：</p>
            <ul>
                <li>对线性部分是精确的</li>
                <li>数值稳定性好</li>
                <li>适合大步长</li>
            </ul>
        </div>
        
        <h4>自适应步长方法</h4>
        
        <div class="note-box">
            <h4>动态调整时间步</h4>
            <p>根据局部误差估计自动调整步长：</p>
            <ol>
                <li><strong>误差估计</strong>：比较不同阶数方法的结果</li>
                <li><strong>步长控制</strong>：
                    <div class="formula">
                        $$\Delta t_{new} = \Delta t_{old} \cdot \left(\frac{\text{容差}}{\text{误差估计}}\right)^{1/p}$$
                    </div>
                </li>
                <li><strong>拒绝机制</strong>：误差过大时重新计算</li>
            </ol>
            <p>在扩散模型中，通常在 $t \approx 0$ 附近需要更小的步长。</p>
        </div>
        
        <h4>反向SDE的特殊处理</h4>
        
        <div class="example-box">
            <div class="example-title">数值挑战与解决方案</div>
            <p><strong>挑战</strong>：</p>
            <ul>
                <li>分数函数在 $t \approx 0$ 附近可能很大</li>
                <li>数值误差累积</li>
                <li>需要处理边界条件</li>
            </ul>
            <p><strong>解决方案</strong>：</p>
            <ul>
                <li><strong>时间重缩放</strong>：使用 $\tau = \log(t)$ 等变换</li>
                <li><strong>截断技巧</strong>：在很小的 $t_{min}$ 停止</li>
                <li><strong>方差缩放</strong>：调整最后几步的噪声强度</li>
            </ul>
        </div>
        
        <h4>并行化策略</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">提高计算效率</div>
            <ol>
                <li><strong>批量并行</strong>：
                    <ul>
                        <li>同时处理多个样本</li>
                        <li>共享分数函数计算</li>
                    </ul>
                </li>
                <li><strong>时间并行</strong>：
                    <ul>
                        <li>Parareal算法</li>
                        <li>多重打靶法</li>
                    </ul>
                </li>
                <li><strong>GPU优化</strong>：
                    <ul>
                        <li>向量化随机数生成</li>
                        <li>融合核函数</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>实践建议</h4>
        
        <div class="note-box">
            <h4>选择合适的求解器</h4>
            <table style="width: 100%; margin-top: 15px;">
                <tr>
                    <th style="width: 30%; text-align: left;">场景</th>
                    <th style="width: 35%; text-align: left;">推荐方法</th>
                    <th style="width: 35%; text-align: left;">原因</th>
                </tr>
                <tr>
                    <td>快速原型</td>
                    <td>Euler-Maruyama</td>
                    <td>简单易实现</td>
                </tr>
                <tr>
                    <td>生产部署</td>
                    <td>自适应Heun</td>
                    <td>精度与效率平衡</td>
                </tr>
                <tr>
                    <td>高质量生成</td>
                    <td>高阶RK + 自适应</td>
                    <td>最高精度</td>
                </tr>
                <tr>
                    <td>线性SDE</td>
                    <td>指数积分器</td>
                    <td>利用特殊结构</td>
                </tr>
            </table>
        </div>
        
        <h3>5.7.2 ODE求解器的应用</h3>
        
        <p>概率流ODE为扩散模型带来了确定性采样的可能。这里介绍如何有效地使用ODE求解器，以及相关的技巧和挑战。</p>
        
        <h4>标准ODE求解器</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">经典方法在扩散模型中的应用</div>
            <p>概率流ODE的一般形式：</p>
            <div class="formula">
                $$\frac{dx}{dt} = f(x,t) - \frac{1}{2}g(t)^2 s_\theta(x,t)$$
            </div>
            <p><strong>常用求解器</strong>：</p>
            <ul>
                <li><strong>RK45</strong>：自适应步长的4/5阶Runge-Kutta</li>
                <li><strong>DOP853</strong>：8阶Dormand-Prince方法</li>
                <li><strong>LSODA</strong>：自动刚性检测</li>
                <li><strong>Radau</strong>：隐式方法，适合刚性问题</li>
            </ul>
        </div>
        
        <h4>DDIM作为ODE求解器</h4>
        
        <div class="note-box">
            <h4>从离散到连续的视角</h4>
            <p>DDIM可以理解为概率流ODE的特殊离散化：</p>
            <ol>
                <li><strong>DDIM更新规则</strong>：
                    <div class="formula">
                        $$x_{t-1} = \sqrt{\bar{\alpha}_{t-1}}\left(\frac{x_t - \sqrt{1-\bar{\alpha}_t}\epsilon_\theta(x_t,t)}{\sqrt{\bar{\alpha}_t}}\right) + \sqrt{1-\bar{\alpha}_{t-1}}\epsilon_\theta(x_t,t)$$
                    </div>
                </li>
                <li><strong>对应的ODE</strong>：VP-SDE的概率流ODE</li>
                <li><strong>优势</strong>：专门为扩散模型设计，数值性质好</li>
            </ol>
        </div>
        
        <h4>DPM-Solver系列</h4>
        
        <div class="example-box">
            <div class="example-title">专用高阶求解器</div>
            <p>DPM-Solver利用扩散ODE的特殊结构：</p>
            <ul>
                <li><strong>指数积分</strong>：精确处理线性部分</li>
                <li><strong>多步方法</strong>：利用历史信息提高精度</li>
                <li><strong>阶数</strong>：1阶到3阶版本</li>
            </ul>
            <p><strong>关键创新</strong>：</p>
            <ol>
                <li>变量变换：$\lambda_t = \log(\alpha_t/\sigma_t)$</li>
                <li>线性多步公式</li>
                <li>解析系数计算</li>
            </ol>
        </div>
        
        <h4>自适应步长策略</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">智能时间步选择</div>
            <p><strong>误差控制</strong>：</p>
            <ul>
                <li>局部截断误差估计</li>
                <li>嵌入式Runge-Kutta对</li>
                <li>Richardson外推</li>
            </ul>
            <p><strong>步长调整</strong>：</p>
            <div class="formula">
                $$h_{new} = h_{old} \cdot \min\left(f_{max}, \max\left(f_{min}, f_{safe}\left(\frac{\epsilon_{tol}}{\epsilon_{est}}\right)^{1/(p+1)}\right)\right)$$
            </div>
            <p>其中 $f_{safe} \approx 0.9$ 是安全因子。</p>
        </div>
        
        <h4>时间重参数化技巧</h4>
        
        <div class="note-box">
            <h4>改善数值性质</h4>
            <p>通过时间变换改善ODE的条件数：</p>
            <ol>
                <li><strong>对数时间</strong>：$\tau = \log(t)$
                    <ul>
                        <li>在 $t \approx 0$ 附近展开时间</li>
                        <li>避免奇异性</li>
                    </ul>
                </li>
                <li><strong>信噪比参数化</strong>：$\tau = \log(\text{SNR}(t))$
                    <ul>
                        <li>均匀化不同时刻的重要性</li>
                        <li>改善收敛性</li>
                    </ul>
                </li>
                <li><strong>学习的时间表</strong>：
                    <ul>
                        <li>神经网络学习最优时间映射</li>
                        <li>适应具体任务</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>刚性问题的处理</h4>
        
        <div class="example-box">
            <div class="example-title">数值稳定性挑战</div>
            <p><strong>刚性的来源</strong>：</p>
            <ul>
                <li>分数函数的大梯度</li>
                <li>多尺度动力学</li>
                <li>接近数据流形时的快速变化</li>
            </ul>
            <p><strong>解决方法</strong>：</p>
            <ul>
                <li><strong>隐式方法</strong>：向后Euler、Radau</li>
                <li><strong>半隐式方法</strong>：IMEX方案</li>
                <li><strong>预条件技术</strong>：改善条件数</li>
            </ul>
        </div>
        
        <h4>快速ODE采样技巧</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">加速策略</div>
            <ol>
                <li><strong>渐进式采样</strong>：
                    <ul>
                        <li>先用大步长生成粗略结果</li>
                        <li>在关键区域细化</li>
                    </ul>
                </li>
                <li><strong>并行ODE求解</strong>：
                    <ul>
                        <li>多重打靶法</li>
                        <li>时间分解</li>
                    </ul>
                </li>
                <li><strong>知识蒸馏</strong>：
                    <ul>
                        <li>学习少步求解器</li>
                        <li>直接预测跳跃</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>质量评估指标</h4>
        
        <div class="note-box">
            <h4>如何评价ODE求解质量</h4>
            <ul>
                <li><strong>轨迹误差</strong>：与高精度参考解比较</li>
                <li><strong>不变量保持</strong>：检查概率守恒</li>
                <li><strong>生成质量</strong>：FID、IS等感知指标</li>
                <li><strong>计算效率</strong>：NFE（函数评估次数）</li>
            </ul>
        </div>
        
        <h4>实用建议</h4>
        
        <div class="example-box">
            <div class="example-title">最佳实践</div>
            <ol>
                <li><strong>初始实验</strong>：从DDIM或DPM-Solver开始</li>
                <li><strong>精度需求高</strong>：使用自适应RK45</li>
                <li><strong>速度优先</strong>：固定步长的专用求解器</li>
                <li><strong>调试技巧</strong>：
                    <ul>
                        <li>可视化ODE轨迹</li>
                        <li>监控局部误差</li>
                        <li>检查数值稳定性</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h3>5.7.3 实现细节与技巧</h3>
        
        <p>成功实现连续时间扩散模型需要注意许多细节。这里分享一些实践中的关键技巧和常见陷阱。</p>
        
        <h4>时间编码的实现</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">连续时间的神经网络输入</div>
            <p><strong>时间嵌入方法</strong>：</p>
            <ol>
                <li><strong>正弦编码</strong>：
                    <div class="formula">
                        $$\text{emb}(t) = [\sin(2^0 \pi t), \cos(2^0 \pi t), ..., \sin(2^{L-1} \pi t), \cos(2^{L-1} \pi t)]$$
                    </div>
                </li>
                <li><strong>学习的嵌入</strong>：
                    <ul>
                        <li>MLP将标量 $t$ 映射到高维向量</li>
                        <li>更灵活但需要更多参数</li>
                    </ul>
                </li>
                <li><strong>傅里叶特征</strong>：
                    <ul>
                        <li>随机频率的正弦基函数</li>
                        <li>理论保证的表达能力</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>分数参数化选择</h4>
        
        <div class="note-box">
            <h4>不同参数化的权衡</h4>
            <p>分数函数可以通过不同方式参数化：</p>
            <ul>
                <li><strong>直接预测分数</strong>：$s_\theta(x,t) = \nabla \log p_t(x)$</li>
                <li><strong>预测噪声</strong>：$\epsilon_\theta(x,t)$，然后 $s_\theta = -\epsilon_\theta/\sigma_t$</li>
                <li><strong>预测速度</strong>：$v_\theta(x,t) = \dot{x}_t$</li>
                <li><strong>预测去噪数据</strong>：$\hat{x}_0 = f_\theta(x_t, t)$</li>
            </ul>
            <p>选择影响训练稳定性和生成质量。</p>
        </div>
        
        <h4>数值稳定性技巧</h4>
        
        <div class="example-box">
            <div class="example-title">避免数值问题</div>
            <ol>
                <li><strong>对数域计算</strong>：
                    <ul>
                        <li>使用 $\log \bar{\alpha}_t$ 而非 $\bar{\alpha}_t$</li>
                        <li>避免下溢问题</li>
                    </ul>
                </li>
                <li><strong>方差裁剪</strong>：
                    <ul>
                        <li>限制 $\beta(t)$ 的范围</li>
                        <li>防止数值爆炸</li>
                    </ul>
                </li>
                <li><strong>安全除法</strong>：
                    <div class="formula">
                        $$\frac{a}{b + \epsilon} \text{ 而非 } \frac{a}{b}$$
                    </div>
                </li>
            </ol>
        </div>
        
        <h4>边界条件处理</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">$t \approx 0$ 和 $t \approx T$ 的特殊处理</div>
            <p><strong>起始时刻 ($t \approx 0$)</strong>：</p>
            <ul>
                <li>分数函数可能发散</li>
                <li>使用最小时间 $t_{min} = 10^{-5}$</li>
                <li>特殊的方差缩放</li>
            </ul>
            <p><strong>终止时刻 ($t \approx T$)</strong>：</p>
            <ul>
                <li>确保收敛到先验分布</li>
                <li>可能需要额外的噪声</li>
            </ul>
        </div>
        
        <h4>训练技巧</h4>
        
        <div class="note-box">
            <h4>提高训练效果</h4>
            <ol>
                <li><strong>重要性采样</strong>：
                    <ul>
                        <li>根据信噪比调整时间采样</li>
                        <li>在困难区域采样更多</li>
                    </ul>
                </li>
                <li><strong>损失加权</strong>：
                    <ul>
                        <li>不同时刻使用不同权重</li>
                        <li>平衡各尺度的贡献</li>
                    </ul>
                </li>
                <li><strong>预条件技巧</strong>：
                    <ul>
                        <li>输入和输出缩放</li>
                        <li>改善梯度流</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>内存优化</h4>
        
        <div class="example-box">
            <div class="example-title">大规模模型的实现</div>
            <ul>
                <li><strong>梯度检查点</strong>：
                    <ul>
                        <li>时间换空间</li>
                        <li>在UNet的特定层使用</li>
                    </ul>
                </li>
                <li><strong>混合精度训练</strong>：
                    <ul>
                        <li>FP16计算，FP32累积</li>
                        <li>注意数值稳定性</li>
                    </ul>
                </li>
                <li><strong>分布式策略</strong>：
                    <ul>
                        <li>数据并行</li>
                        <li>模型并行（大模型）</li>
                    </ul>
                </li>
            </ul>
        </div>
        
        <h4>调试和验证</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">确保正确实现</div>
            <ol>
                <li><strong>单元测试</strong>：
                    <ul>
                        <li>测试时间离散化的一致性</li>
                        <li>验证概率守恒</li>
                        <li>检查可逆性</li>
                    </ul>
                </li>
                <li><strong>渐进测试</strong>：
                    <ul>
                        <li>从简单分布开始</li>
                        <li>逐步增加复杂度</li>
                    </ul>
                </li>
                <li><strong>可视化工具</strong>：
                    <ul>
                        <li>轨迹可视化</li>
                        <li>分数场可视化</li>
                        <li>中间状态检查</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>性能优化清单</h4>
        
        <div class="note-box">
            <h4>实现检查列表</h4>
            <table style="width: 100%; margin-top: 15px;">
                <tr>
                    <th style="width: 40%; text-align: left;">优化项</th>
                    <th style="width: 30%; text-align: left;">影响</th>
                    <th style="width: 30%; text-align: left;">难度</th>
                </tr>
                <tr>
                    <td>使用编译优化（torch.compile）</td>
                    <td>2-3x加速</td>
                    <td>简单</td>
                </tr>
                <tr>
                    <td>融合自定义CUDA核</td>
                    <td>10-20%加速</td>
                    <td>困难</td>
                </tr>
                <tr>
                    <td>优化注意力计算</td>
                    <td>显著内存节省</td>
                    <td>中等</td>
                </tr>
                <tr>
                    <td>缓存中间结果</td>
                    <td>避免重复计算</td>
                    <td>简单</td>
                </tr>
            </table>
        </div>
        
        <h4>常见错误和解决方案</h4>
        
        <div class="example-box">
            <div class="example-title">避免常见陷阱</div>
            <ol>
                <li><strong>时间方向错误</strong>：
                    <ul>
                        <li>确保前向是 $0 \to T$</li>
                        <li>反向是 $T \to 0$</li>
                    </ul>
                </li>
                <li><strong>方差参数化不一致</strong>：
                    <ul>
                        <li>统一使用 $\beta$ 或 $\alpha$</li>
                        <li>注意累积乘积</li>
                    </ul>
                </li>
                <li><strong>随机种子问题</strong>：
                    <ul>
                        <li>训练和采样使用不同种子</li>
                        <li>确保可重现性</li>
                    </ul>
                </li>
            </ol>
        </div>

        <h2>5.8 理论深入</h2>
        
        <h3>5.8.1 存在性与唯一性</h3>
        
        <p>SDE解的存在性与唯一性是扩散模型理论基础的重要组成部分。这些结果保证了模型的数学良定性。</p>
        
        <h4>基本存在唯一性定理</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">Itô SDE的存在唯一性</div>
            <p>考虑SDE：$dx_t = f(x_t, t)dt + g(t)dw_t$</p>
            <p>如果满足以下条件：</p>
            <ol>
                <li><strong>Lipschitz条件</strong>：存在常数 $K$ 使得
                    <div class="formula">
                        $$|f(x,t) - f(y,t)| \leq K|x-y|$$
                    </div>
                </li>
                <li><strong>线性增长条件</strong>：存在常数 $C$ 使得
                    <div class="formula">
                        $$|f(x,t)|^2 + |g(t)|^2 \leq C(1 + |x|^2)$$
                    </div>
                </li>
            </ol>
            <p>则对任意初值 $x_0$，SDE存在唯一的强解。</p>
        </div>
        
        <h4>扩散模型中的验证</h4>
        
        <div class="note-box">
            <h4>常见SDE的性质检验</h4>
            <p><strong>VP-SDE</strong>：$dx = -\frac{\beta(t)}{2}x dt + \sqrt{\beta(t)}dw$</p>
            <ul>
                <li>漂移项线性：自动满足Lipschitz条件</li>
                <li>有界的 $\beta(t)$ 保证线性增长</li>
                <li>结论：存在唯一解</li>
            </ul>
            <p><strong>VE-SDE</strong>：$dx = \sqrt{\frac{d\sigma^2(t)}{dt}}dw$</p>
            <ul>
                <li>无漂移项，条件自动满足</li>
                <li>只需 $\sigma(t)$ 连续可微</li>
            </ul>
        </div>
        
        <h4>反向SDE的存在性</h4>
        
        <div class="example-box">
            <div class="example-title">分数函数的正则性要求</div>
            <p>反向SDE：$dx = [f(x,t) - g(t)^2\nabla\log p_t(x)]dt + g(t)d\bar{w}$</p>
            <p>存在性需要分数函数满足：</p>
            <ul>
                <li><strong>局部Lipschitz</strong>：在紧集上Lipschitz连续</li>
                <li><strong>多项式增长</strong>：$|\nabla\log p_t(x)| \leq C(1 + |x|^k)$</li>
            </ul>
            <p>神经网络通常满足这些条件。</p>
        </div>
        
        <h4>弱解与强解</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">解的概念</div>
            <ul>
                <li><strong>强解</strong>：给定布朗运动 $w_t$，解 $x_t$ 是 $w_t$ 的函数</li>
                <li><strong>弱解</strong>：存在某个概率空间和布朗运动使得SDE成立</li>
            </ul>
            <p>对于扩散模型：</p>
            <ul>
                <li>训练时只需要弱解（分布匹配）</li>
                <li>确定性采样需要强解</li>
            </ul>
        </div>
        
        <h4>爆炸时间与全局解</h4>
        
        <div class="note-box">
            <h4>解的长时间行为</h4>
            <p>即使局部解存在，也可能在有限时间爆炸。避免爆炸的充分条件：</p>
            <ol>
                <li><strong>耗散性</strong>：$\langle x, f(x,t) \rangle \leq -\alpha|x|^2 + \beta$</li>
                <li><strong>有界扩散</strong>：$|g(t)| \leq M$</li>
            </ol>
            <p>VP-SDE的耗散性保证了全局解的存在。</p>
        </div>
        
        <h4>路径正则性</h4>
        
        <div class="example-box">
            <div class="example-title">解的连续性和可微性</div>
            <ul>
                <li><strong>连续性</strong>：SDE的解几乎必然连续</li>
                <li><strong>Hölder连续性</strong>：指数 $< 1/2$</li>
                <li><strong>不可微性</strong>：几乎处处不可微</li>
            </ul>
            <p>这解释了为什么需要用SDE而非ODE描述噪声驱动的过程。</p>
        </div>
        
        <h4>概率流ODE的存在性</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">从SDE到ODE</div>
            <p>概率流ODE：$\frac{dx}{dt} = f(x,t) - \frac{1}{2}g(t)^2\nabla\log p_t(x)$</p>
            <p>存在性比SDE更强，因为：</p>
            <ul>
                <li>确定性系统，无随机项</li>
                <li>标准ODE理论适用</li>
                <li>可以使用高阶数值方法</li>
            </ul>
            <p>关键：分数函数的光滑性决定了ODE解的正则性。</p>
        </div>
        
        <h4>实践意义</h4>
        
        <div class="note-box">
            <h4>理论对实现的指导</h4>
            <ol>
                <li><strong>网络架构设计</strong>：
                    <ul>
                        <li>确保输出Lipschitz连续</li>
                        <li>使用谱归一化等技术</li>
                    </ul>
                </li>
                <li><strong>训练稳定性</strong>：
                    <ul>
                        <li>正则化保证解的存在性</li>
                        <li>梯度裁剪防止爆炸</li>
                    </ul>
                </li>
                <li><strong>数值方法选择</strong>：
                    <ul>
                        <li>强解理论支持显式方法</li>
                        <li>刚性问题可能需要隐式方法</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h3>5.8.2 收敛性分析</h3>
        
        <p>收敛性分析是理解扩散模型长时间行为和采样质量的关键。这里探讨不同层面的收敛性质。</p>
        
        <h4>分布收敛性</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">前向过程的收敛</div>
            <p>对于前向SDE，我们关心 $p_t$ 是否收敛到目标分布 $p_\infty$：</p>
            <ul>
                <li><strong>VP-SDE</strong>：$p_t \to \mathcal{N}(0, I)$ 当 $t \to \infty$</li>
                <li><strong>VE-SDE</strong>：$p_t$ 的方差趋于无穷，但标准化后收敛</li>
            </ul>
            <p><strong>收敛速率</strong>：通常是指数收敛
            <div class="formula">
                $$W_2(p_t, p_\infty) \leq Ce^{-\lambda t}$$
            </div>
            其中 $W_2$ 是Wasserstein-2距离。</p>
        </div>
        
        <h4>反向过程的收敛性</h4>
        
        <div class="note-box">
            <h4>生成质量的理论保证</h4>
            <p>反向SDE的收敛性依赖于：</p>
            <ol>
                <li><strong>分数估计误差</strong>：$\mathbb{E}[|s_\theta - \nabla\log p_t|^2]$</li>
                <li><strong>离散化误差</strong>：时间步长 $\Delta t$ 的影响</li>
                <li><strong>有限时间截断</strong>：在 $t_{min}$ 停止的影响</li>
            </ol>
            <p>总误差界：
            <div class="formula">
                $$W_2(p_{gen}, p_{data}) \leq C_1\sqrt{\epsilon_{score}} + C_2\sqrt{\Delta t} + C_3 t_{min}$$
            </div></p>
        </div>
        
        <h4>数值方法的收敛阶</h4>
        
        <div class="example-box">
            <div class="example-title">不同离散化的收敛性</div>
            <table style="width: 100%; margin-top: 15px;">
                <tr>
                    <th style="width: 30%; text-align: left;">方法</th>
                    <th style="width: 35%; text-align: left;">强收敛阶</th>
                    <th style="width: 35%; text-align: left;">弱收敛阶</th>
                </tr>
                <tr>
                    <td>Euler-Maruyama</td>
                    <td>$O(\sqrt{\Delta t})$</td>
                    <td>$O(\Delta t)$</td>
                </tr>
                <tr>
                    <td>Milstein方法</td>
                    <td>$O(\Delta t)$</td>
                    <td>$O(\Delta t)$</td>
                </tr>
                <tr>
                    <td>高阶Runge-Kutta</td>
                    <td>$O(\Delta t)$</td>
                    <td>$O(\Delta t^2)$</td>
                </tr>
            </table>
            <p>注：扩散模型主要关心弱收敛（分布层面）。</p>
        </div>
        
        <h4>遍历性与混合时间</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">长时间行为</div>
            <p>SDE的遍历性保证了时间平均等于空间平均：</p>
            <div class="formula">
                $$\lim_{T \to \infty} \frac{1}{T}\int_0^T f(x_t)dt = \int f(x)p_\infty(x)dx$$
            </div>
            <p><strong>混合时间</strong>：达到平衡分布所需时间</p>
            <ul>
                <li>VP-SDE：$T_{mix} = O(\frac{1}{\beta_{min}}\log\frac{1}{\epsilon})$</li>
                <li>影响因素：噪声强度、初始分布、目标精度</li>
            </ul>
        </div>
        
        <h4>分数匹配的收敛性</h4>
        
        <div class="note-box">
            <h4>训练目标的渐近性质</h4>
            <p>分数匹配损失的最小值：</p>
            <div class="formula">
                $$\mathcal{L}^* = \inf_{s_\theta} \mathbb{E}_{t,x}[|s_\theta(x,t) - \nabla\log p_t(x)|^2]$$
            </div>
            <p><strong>收敛保证</strong>：</p>
            <ul>
                <li>神经网络的通用逼近性</li>
                <li>样本复杂度：$O(\frac{d}{\epsilon^2})$</li>
                <li>优化收敛：依赖于损失函数的凸性</li>
            </ul>
        </div>
        
        <h4>KL散度的演化</h4>
        
        <div class="example-box">
            <div class="example-title">信息论视角</div>
            <p>前向过程中KL散度的演化：</p>
            <div class="formula">
                $$\frac{d}{dt}D_{KL}(p_t \| p_\infty) = -\mathcal{I}(p_t)$$
            </div>
            <p>其中 $\mathcal{I}$ 是Fisher信息。这表明：</p>
            <ul>
                <li>KL散度单调递减</li>
                <li>收敛速率由Fisher信息决定</li>
                <li>几何解释：沿信息几何的测地线移动</li>
            </ul>
        </div>
        
        <h4>有限样本的影响</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">统计误差分析</div>
            <p>使用有限样本训练的影响：</p>
            <ol>
                <li><strong>估计偏差</strong>：$O(1/n)$</li>
                <li><strong>估计方差</strong>：$O(1/\sqrt{n})$</li>
                <li><strong>泛化误差</strong>：依赖于模型复杂度</li>
            </ol>
            <p>实践建议：样本量 $n$ 应满足 $n \gg d^2/\epsilon^2$。</p>
        </div>
        
        <h4>加速收敛的技术</h4>
        
        <div class="note-box">
            <h4>改善收敛性的方法</h4>
            <ol>
                <li><strong>方差缩减</strong>：
                    <ul>
                        <li>控制变量法</li>
                        <li>重要性采样</li>
                    </ul>
                </li>
                <li><strong>预条件技术</strong>：
                    <ul>
                        <li>改变度量使问题更易求解</li>
                        <li>自适应步长</li>
                    </ul>
                </li>
                <li><strong>多尺度方法</strong>：
                    <ul>
                        <li>不同时间尺度的耦合</li>
                        <li>由粗到细的策略</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h3>5.8.3 与最优传输的联系</h3>
        
        <p>扩散模型与最优传输理论有着深刻的联系。这种联系不仅提供了新的理论视角，还启发了新的算法设计。</p>
        
        <h4>最优传输问题回顾</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">Monge-Kantorovich问题</div>
            <p>给定两个概率分布 $p_0$ 和 $p_T$，最优传输问题是找到成本最小的传输方案：</p>
            <div class="formula">
                $$\inf_{\pi \in \Pi(p_0, p_T)} \int c(x,y) d\pi(x,y)$$
            </div>
            <p>其中：</p>
            <ul>
                <li>$\pi$ 是联合分布，边缘为 $p_0$ 和 $p_T$</li>
                <li>$c(x,y)$ 是传输成本（通常是 $|x-y|^2$）</li>
                <li>$\Pi(p_0, p_T)$ 是所有可行传输方案</li>
            </ul>
        </div>
        
        <h4>动态最优传输</h4>
        
        <div class="note-box">
            <h4>Benamou-Brenier公式</h4>
            <p>最优传输可以表示为动态问题：</p>
            <div class="formula">
                $$W_2^2(p_0, p_T) = \inf_{(p_t, v_t)} \int_0^T \int |v_t(x)|^2 p_t(x) dx dt$$
            </div>
            <p>约束条件：</p>
            <div class="formula">
                $$\frac{\partial p_t}{\partial t} + \nabla \cdot (p_t v_t) = 0$$
            </div>
            <p>这将离散传输转化为连续时间的流问题。</p>
        </div>
        
        <h4>扩散模型作为正则化最优传输</h4>
        
        <div class="example-box">
            <div class="example-title">熵正则化的视角</div>
            <p>扩散过程可以看作带熵正则化的最优传输：</p>
            <ol>
                <li><strong>Schrödinger桥问题</strong>：
                    <div class="formula">
                        $$\inf_{\mathbb{P}} D_{KL}(\mathbb{P} \| \mathbb{Q}) \text{ s.t. } \mathbb{P}_0 = p_0, \mathbb{P}_T = p_T$$
                    </div>
                    其中 $\mathbb{Q}$ 是参考过程（如布朗运动）
                </li>
                <li><strong>与扩散的联系</strong>：
                    <ul>
                        <li>解是一个扩散过程</li>
                        <li>漂移由分数函数决定</li>
                        <li>正则化参数对应扩散强度</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>概率流ODE与位移插值</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">McCann插值</div>
            <p>在最优传输中，两个分布之间的测地线由位移插值给出：</p>
            <div class="formula">
                $$p_t = ((1-t)\text{Id} + tT)_\# p_0$$
            </div>
            <p>其中 $T$ 是最优传输映射。</p>
            <p><strong>与概率流ODE的关系</strong>：</p>
            <ul>
                <li>概率流ODE定义了一种特殊的插值</li>
                <li>当扩散趋于0时，收敛到最优传输</li>
                <li>提供了计算测地线的实用方法</li>
            </ul>
        </div>
        
        <h4>Wasserstein梯度流</h4>
        
        <div class="note-box">
            <h4>能量泛函的梯度流</h4>
            <p>许多PDE可以写成Wasserstein空间上的梯度流：</p>
            <div class="formula">
                $$\frac{\partial p}{\partial t} = \nabla \cdot \left(p \nabla \frac{\delta \mathcal{F}[p]}{\delta p}\right)$$
            </div>
            <p>扩散模型的联系：</p>
            <ul>
                <li>前向过程：相对熵的梯度流</li>
                <li>反向过程：可以设计为某个能量的梯度流</li>
                <li>提供了变分原理的解释</li>
            </ul>
        </div>
        
        <h4>计算优势</h4>
        
        <div class="example-box">
            <div class="example-title">为什么这个联系重要？</div>
            <ol>
                <li><strong>新的算法</strong>：
                    <ul>
                        <li>基于OT的采样方法</li>
                        <li>更好的插值路径</li>
                        <li>加速技术</li>
                    </ul>
                </li>
                <li><strong>理论保证</strong>：
                    <ul>
                        <li>收敛性分析</li>
                        <li>最优性条件</li>
                        <li>稳定性结果</li>
                    </ul>
                </li>
                <li><strong>应用扩展</strong>：
                    <ul>
                        <li>不同度量空间</li>
                        <li>约束传输问题</li>
                        <li>多边际问题</li>
                    </ul>
                </li>
            </ol>
        </div>
        
        <h4>流匹配与最优传输</h4>
        
        <div class="theorem-box">
            <div class="theorem-title">统一框架</div>
            <p>流匹配方法直接学习传输速度场：</p>
            <ul>
                <li><strong>目标</strong>：学习 $v_t$ 使得 $(p_t, v_t)$ 解决传输问题</li>
                <li><strong>优势</strong>：避免学习分数函数</li>
                <li><strong>联系</strong>：$v_t = f(x,t) - \frac{g^2}{2}\nabla\log p_t$</li>
            </ul>
            <p>这提供了扩散模型的另一种参数化。</p>
        </div>
        
        <h4>未来方向</h4>
        
        <div class="note-box">
            <h4>开放问题</h4>
            <ol>
                <li><strong>非欧几里得空间</strong>：
                    <ul>
                        <li>流形上的扩散</li>
                        <li>图上的最优传输</li>
                    </ul>
                </li>
                <li><strong>多模态传输</strong>：
                    <ul>
                        <li>不同空间之间的映射</li>
                        <li>Gromov-Wasserstein距离</li>
                    </ul>
                </li>
                <li><strong>计算效率</strong>：
                    <ul>
                        <li>利用OT结构加速</li>
                        <li>稀疏传输方案</li>
                    </ul>
                </li>
            </ol>
        </div>

        <h2>5.9 本章小结</h2>
        
        <div class="summary-box">
            <h3>核心概念回顾</h3>
            
            <h4>1. 从离散到连续的演进</h4>
            <ul>
                <li>离散时间扩散模型（DDPM）的局限性</li>
                <li>连续时间极限的自然性和优势</li>
                <li>SDE作为描述扩散过程的统一框架</li>
            </ul>
            
            <h4>2. 三大支柱</h4>
            <ul>
                <li><strong>SDE（随机微分方程）</strong>：描述单个粒子的随机演化</li>
                <li><strong>ODE（概率流）</strong>：提供确定性的替代方案</li>
                <li><strong>PDE（Fokker-Planck）</strong>：刻画概率密度的演化</li>
            </ul>
            
            <h4>3. 关键数学对象</h4>
            <ul>
                <li><strong>分数函数</strong> $\nabla \log p_t(x)$：连接所有视角的核心</li>
                <li><strong>Anderson定理</strong>：时间反演的理论基础</li>
                <li><strong>Score SDE框架</strong>：统一不同扩散模型</li>
            </ul>
            
            <h4>4. 实践要点</h4>
            <ul>
                <li>数值求解器的选择：SDE vs ODE</li>
                <li>时间编码和边界处理</li>
                <li>训练稳定性和收敛性保证</li>
            </ul>
            
            <h4>5. 理论深度</h4>
            <ul>
                <li>存在唯一性定理保证数学良定性</li>
                <li>收敛性分析指导算法设计</li>
                <li>与最优传输的联系开启新方向</li>
            </ul>
        </div>
        
        <h2>5.10 练习题</h2>
        
        <div class="exercise">
            <div class="exercise-title">练习 5.1：从离散到连续</div>
            <p>考虑DDPM的前向过程：$x_t = \sqrt{\alpha_t}x_{t-1} + \sqrt{1-\alpha_t}\epsilon_t$</p>
            <p>设 $\alpha_t = 1 - \beta \Delta t$，其中 $\Delta t = 1/T$，$T$ 是总步数。</p>
            <ol>
                <li>推导当 $T \to \infty$ 时的连续时间SDE</li>
                <li>计算对应的边缘分布 $p(x_t|x_0)$</li>
                <li>验证该SDE是VP-SDE的特例</li>
            </ol>
            <button class="toggle-answer">显示答案</button>
            <div class="answer" style="display: none;">
                <p><strong>解答：</strong></p>
                <ol>
                    <li>将离散递推展开：
                        $$x_t - x_{t-1} = (\sqrt{1-\beta\Delta t} - 1)x_{t-1} + \sqrt{\beta\Delta t}\cdot\frac{\epsilon_t}{\sqrt{\Delta t}}\sqrt{\Delta t}$$
                        利用 $\sqrt{1-\beta\Delta t} \approx 1 - \frac{\beta\Delta t}{2}$，得到：
                        $$\frac{x_t - x_{t-1}}{\Delta t} \approx -\frac{\beta}{2}x_{t-1} + \sqrt{\beta}\cdot\frac{\epsilon_t}{\sqrt{\Delta t}}$$
                        取极限得到SDE：$dx = -\frac{\beta}{2}x dt + \sqrt{\beta}dw$
                    </li>
                    <li>这是线性SDE，解为：$x_t = e^{-\frac{\beta t}{2}}x_0 + \int_0^t e^{-\frac{\beta(t-s)}{2}}\sqrt{\beta}dw_s$
                        因此：$p(x_t|x_0) = \mathcal{N}(e^{-\frac{\beta t}{2}}x_0, 1-e^{-\beta t})$
                    </li>
                    <li>这正是VP-SDE在常数 $\beta(t) = \beta$ 情况下的形式。</li>
                </ol>
            </div>
        </div>
        
        <div class="exercise">
            <div class="exercise-title">练习 5.2：反向SDE推导</div>
            <p>给定前向SDE：$dx = f(x,t)dt + g(t)dw$</p>
            <ol>
                <li>使用Bayes定理说明为什么反向过程需要分数函数</li>
                <li>推导反向SDE的漂移项</li>
                <li>解释分数函数项 $-g(t)^2\nabla\log p_t(x)$ 的物理意义</li>
            </ol>
            <button class="toggle-answer">显示答案</button>
            <div class="answer" style="display: none;">
                <p><strong>解答：</strong></p>
                <ol>
                    <li>反向转移核需要：$p(x_{t-dt}|x_t) = \frac{p(x_t|x_{t-dt})p(x_{t-dt})}{p(x_t)}$
                        对数形式：$\log p(x_{t-dt}|x_t) = \log p(x_t|x_{t-dt}) + \log p(x_{t-dt}) - \log p(x_t)$
                        这解释了为什么需要 $\nabla \log p_t$。
                    </li>
                    <li>使用Girsanov定理或直接计算，可得反向漂移：
                        $\tilde{f}(x,t) = f(x,t) - g(t)^2\nabla\log p_t(x)$
                    </li>
                    <li>物理意义：
                        <ul>
                            <li>$f(x,t)$：原始的确定性漂移</li>
                            <li>$-g(t)^2\nabla\log p_t(x)$：补偿扩散造成的概率流失</li>
                            <li>总效果：将概率"拉回"高密度区域</li>
                        </ul>
                    </li>
                </ol>
            </div>
        </div>
        
        <div class="exercise">
            <div class="exercise-title">练习 5.3：概率流ODE</div>
            <p>考虑VP-SDE：$dx = -\frac{\beta(t)}{2}x dt + \sqrt{\beta(t)}dw$</p>
            <ol>
                <li>写出对应的概率流ODE</li>
                <li>证明ODE和SDE产生相同的边缘分布</li>
                <li>讨论何时使用ODE vs SDE进行采样</li>
            </ol>
            <button class="toggle-answer">显示答案</button>
            <div class="answer" style="display: none;">
                <p><strong>解答：</strong></p>
                <ol>
                    <li>概率流ODE：$\frac{dx}{dt} = -\frac{\beta(t)}{2}x - \frac{\beta(t)}{2}\nabla\log p_t(x)$
                        对于高斯分布，$\nabla\log p_t(x) = -\frac{x-\mu_t}{\sigma_t^2}$
                    </li>
                    <li>证明：两者对应相同的Fokker-Planck方程
                        $$\frac{\partial p}{\partial t} = \frac{\beta(t)}{2}\nabla\cdot(xp) + \frac{\beta(t)}{2}\Delta p$$
                    </li>
                    <li>使用建议：
                        <ul>
                            <li>ODE：需要精确编码/解码、插值、编辑</li>
                            <li>SDE：需要多样性、避免模式坍塌、纯生成任务</li>
                        </ul>
                    </li>
                </ol>
            </div>
        </div>
        
        <div class="exercise">
            <div class="exercise-title">练习 5.4：Fokker-Planck方程</div>
            <p>对于SDE：$dx = -x dt + \sqrt{2}dw$</p>
            <ol>
                <li>写出对应的Fokker-Planck方程</li>
                <li>求解稳态分布</li>
                <li>计算从任意初始分布到稳态的收敛时间</li>
            </ol>
            <button class="toggle-answer">显示答案</button>
            <div class="answer" style="display: none;">
                <p><strong>解答：</strong></p>
                <ol>
                    <li>Fokker-Planck方程：
                        $$\frac{\partial p}{\partial t} = \frac{\partial}{\partial x}(xp) + \frac{\partial^2 p}{\partial x^2}$$
                    </li>
                    <li>稳态条件 $\frac{\partial p}{\partial t} = 0$ 给出：
                        $$\frac{d}{dx}(xp) + \frac{dp}{dx} = 0$$
                        解得：$p_\infty(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2}$（标准正态分布）
                    </li>
                    <li>收敛速率由最小特征值决定，这里是指数收敛：
                        $$\|p_t - p_\infty\|_{L^2} \leq e^{-t}\|p_0 - p_\infty\|_{L^2}$$
                    </li>
                </ol>
            </div>
        </div>
        
        <div class="exercise">
            <div class="exercise-title">练习 5.5：数值方法比较</div>
            <p>实现并比较不同的SDE数值解法：</p>
            <ol>
                <li>实现Euler-Maruyama和Heun方法</li>
                <li>在VP-SDE上测试收敛阶</li>
                <li>分析计算成本vs精度的权衡</li>
            </ol>
            <button class="toggle-answer">显示答案</button>
            <div class="answer" style="display: none;">
                <p><strong>提示：</strong></p>
                <ul>
                    <li>Euler-Maruyama：$x_{n+1} = x_n + f(x_n,t_n)\Delta t + g(t_n)\sqrt{\Delta t}z_n$</li>
                    <li>Heun：先预测再校正，提高确定性部分的精度</li>
                    <li>使用已知解析解的SDE（如OU过程）验证收敛阶</li>
                    <li>绘制误差vs步长的对数图，斜率即为收敛阶</li>
                </ul>
            </div>
        </div>
        
        <div class="exercise">
            <div class="exercise-title">练习 5.6：Score SDE框架</div>
            <p>证明以下等价关系：</p>
            <ol>
                <li>DDPM的噪声预测 $\epsilon_\theta$ 与分数函数的关系</li>
                <li>NCSN的多尺度训练与VE-SDE的联系</li>
                <li>设计一个新的SDE并分析其性质</li>
            </ol>
            <button class="toggle-answer">显示答案</button>
            <div class="answer" style="display: none;">
                <p><strong>解答要点：</strong></p>
                <ol>
                    <li>关系：$\epsilon_\theta(x_t, t) = -\sigma_t s_\theta(x_t, t)$
                        其中 $\sigma_t = \sqrt{1-\bar{\alpha}_t}$
                    </li>
                    <li>NCSN的噪声水平 $\{\sigma_i\}$ 对应VE-SDE在离散时刻的值</li>
                    <li>新SDE示例：非线性漂移 $dx = -x^3 dt + \sqrt{2}dw$
                        <ul>
                            <li>多模态稳态分布</li>
                            <li>局部稳定性分析</li>
                            <li>数值挑战：刚性问题</li>
                        </ul>
                    </li>
                </ol>
            </div>
        </div>
        
        <div class="exercise">
            <div class="exercise-title">挑战题：最优传输视角</div>
            <p>探索扩散模型与最优传输的联系：</p>
            <ol>
                <li>证明当 $g(t) \to 0$ 时，概率流ODE收敛到最优传输的位移插值</li>
                <li>实现基于最优传输的采样加速方法</li>
                <li>讨论Schrödinger桥与扩散模型的关系</li>
            </ol>
            <button class="toggle-answer">显示答案</button>
            <div class="answer" style="display: none;">
                <p><strong>研究方向：</strong></p>
                <ul>
                    <li>参考Benamou-Brenier公式和动态最优传输理论</li>
                    <li>考虑熵正则化的作用</li>
                    <li>流匹配方法提供了实际的算法思路</li>
                    <li>这是当前研究的活跃领域，有很多开放问题</li>
                </ul>
            </div>
        </div>
        
        <div class="navigation">
            <a href="chapter4.html" class="prev-link">← 第4章：基于分数的生成模型</a>
            <a href="index.html" class="home-link">返回首页</a>
            <a href="chapter6.html" class="next-link">第6章：流匹配 →</a>
        </div>
    </div>
    
    <script src="common.js"></script>
</body>
</html>