[â† è¿”å›ç›®å½•](index.md) | ç¬¬9ç«  / å…±14ç«  | [ä¸‹ä¸€ç«  â†’](chapter10.md)

# ç¬¬9ç« ï¼šæ¡ä»¶ç”Ÿæˆä¸å¼•å¯¼æŠ€æœ¯

æ¡ä»¶ç”Ÿæˆæ˜¯æ‰©æ•£æ¨¡å‹æœ€é‡è¦çš„åº”ç”¨ä¹‹ä¸€ï¼Œå®ƒä½¿æˆ‘ä»¬èƒ½å¤Ÿæ§åˆ¶ç”Ÿæˆè¿‡ç¨‹ï¼Œäº§ç”Ÿç¬¦åˆç‰¹å®šè¦æ±‚çš„æ ·æœ¬ã€‚æœ¬ç« æ·±å…¥æ¢è®¨å„ç§æ¡ä»¶ç”ŸæˆæŠ€æœ¯ï¼Œä»åŸºäºåˆ†ç±»å™¨çš„å¼•å¯¼åˆ°æ— åˆ†ç±»å™¨å¼•å¯¼ï¼Œå†åˆ°æœ€æ–°çš„æ§åˆ¶æ–¹æ³•ã€‚æ‚¨å°†å­¦ä¹ å¦‚ä½•åœ¨æ•°å­¦ä¸Šç†è§£è¿™äº›å¼•å¯¼æœºåˆ¶ï¼ŒæŒæ¡åœ¨ä¸åŒåœºæ™¯ä¸‹é€‰æ‹©å’Œå®ç°æ¡ä»¶ç”Ÿæˆçš„æŠ€å·§ï¼Œå¹¶äº†è§£å¦‚ä½•å¹³è¡¡ç”Ÿæˆè´¨é‡ä¸æ¡ä»¶éµå¾ªåº¦ã€‚é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œæ‚¨å°†èƒ½å¤Ÿæ„å»ºå¼ºå¤§çš„å¯æ§ç”Ÿæˆç³»ç»Ÿã€‚

## ç« èŠ‚å¤§çº²

### 9.1 æ¡ä»¶æ‰©æ•£æ¨¡å‹çš„åŸºç¡€
- æ¡ä»¶åˆ†å¸ƒçš„å»ºæ¨¡
- æ¡ä»¶ä¿¡æ¯çš„æ³¨å…¥æ–¹å¼
- æ¶æ„è®¾è®¡è€ƒè™‘
- è®­ç»ƒç­–ç•¥

### 9.2 åˆ†ç±»å™¨å¼•å¯¼ï¼ˆClassifier Guidanceï¼‰
- ç†è®ºæ¨å¯¼ä¸ç›´è§‰
- æ¢¯åº¦è®¡ç®—ä¸å®ç°
- å¼•å¯¼å¼ºåº¦çš„å½±å“
- å±€é™æ€§åˆ†æ

### 9.3 æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆClassifier-Free Guidanceï¼‰
- åŠ¨æœºä¸æ ¸å¿ƒæ€æƒ³
- æ¡ä»¶ä¸æ— æ¡ä»¶æ¨¡å‹çš„è”åˆè®­ç»ƒ
- å¼•å¯¼å…¬å¼æ¨å¯¼
- å®è·µä¸­çš„æŠ€å·§

### 9.4 é«˜çº§å¼•å¯¼æŠ€æœ¯
- å¤šæ¡ä»¶ç»„åˆ
- è´Ÿå‘æç¤ºï¼ˆNegative Promptingï¼‰
- åŠ¨æ€å¼•å¯¼å¼ºåº¦
- ControlNetä¸é€‚é…å™¨æ–¹æ³•

### 9.5 è¯„ä¼°ä¸ä¼˜åŒ–
- æ¡ä»¶ä¸€è‡´æ€§åº¦é‡
- å¤šæ ·æ€§ä¸è´¨é‡æƒè¡¡
- å¼•å¯¼å¤±æ•ˆçš„è¯Šæ–­
- å®é™…åº”ç”¨æ¡ˆä¾‹

## 9.1 æ¡ä»¶æ‰©æ•£æ¨¡å‹çš„åŸºç¡€

### 9.1.1 æ¡ä»¶åˆ†å¸ƒçš„æ•°å­¦æ¡†æ¶

åœ¨æ¡ä»¶æ‰©æ•£æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å»ºæ¨¡æ¡ä»¶åˆ†å¸ƒ $p(\mathbf{x}|\mathbf{c})$ï¼Œå…¶ä¸­ $\mathbf{x}$ æ˜¯æ•°æ®ï¼ˆå¦‚å›¾åƒï¼‰ï¼Œ$\mathbf{c}$ æ˜¯æ¡ä»¶ä¿¡æ¯ï¼ˆå¦‚ç±»åˆ«æ ‡ç­¾ã€æ–‡æœ¬æè¿°ç­‰ï¼‰ã€‚

æ¡ä»¶æ‰©æ•£è¿‡ç¨‹å®šä¹‰ä¸ºï¼š
- **å‰å‘è¿‡ç¨‹**ï¼š$q(\mathbf{x}_t|\mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1-\beta_t}\mathbf{x}_{t-1}, \beta_t\mathbf{I})$ï¼ˆä¸æ¡ä»¶æ— å…³ï¼‰
- **åå‘è¿‡ç¨‹**ï¼š$p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{c}) = \mathcal{N}(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t, \mathbf{c}), \sigma_t^2\mathbf{I})$

å…³é”®åœ¨äºå¦‚ä½•è®¾è®¡å’Œè®­ç»ƒæ¡ä»¶å»å™ªç½‘ç»œ $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \mathbf{c})$ã€‚

### 9.1.2 æ¡ä»¶ä¿¡æ¯çš„æ³¨å…¥æ–¹å¼

**1. æ‹¼æ¥ï¼ˆConcatenationï¼‰**

æœ€ç›´æ¥çš„æ–¹å¼æ˜¯å°†æ¡ä»¶ä¿¡æ¯ä¸è¾“å…¥æ‹¼æ¥ï¼š
```python
# å¯¹äºå›¾åƒæ¡ä»¶
x_with_cond = torch.cat([x_t, c_image], dim=1)
# å¯¹äºå‘é‡æ¡ä»¶
c_embed = condition_encoder(c)
x_with_cond = torch.cat([x_t, c_embed.unsqueeze(-1).unsqueeze(-1).expand(...)])
```

**2. è‡ªé€‚åº”å½’ä¸€åŒ–ï¼ˆAdaptive Normalizationï¼‰**

é€šè¿‡æ¡ä»¶ä¿¡æ¯è°ƒåˆ¶å½’ä¸€åŒ–å‚æ•°ï¼š
```python
# AdaIN, AdaGN, AdaLNç­‰
gamma, beta = mlp(c_embed)
h = normalize(h)
h = gamma * h + beta
```

**3. äº¤å‰æ³¨æ„åŠ›ï¼ˆCross-Attentionï¼‰**

ç‰¹åˆ«é€‚åˆåºåˆ—æ¡ä»¶ï¼ˆå¦‚æ–‡æœ¬ï¼‰ï¼š
```python
# Qæ¥è‡ªå›¾åƒç‰¹å¾ï¼ŒK,Væ¥è‡ªæ–‡æœ¬ç¼–ç 
attn_output = CrossAttention(
    query=image_features,
    key=text_features,
    value=text_features
)
```

**4. ç‰¹å¾è°ƒåˆ¶ï¼ˆFeature-wise Modulationï¼‰**

FiLMå±‚é€šè¿‡æ¡ä»¶ä¿¡æ¯ç¼©æ”¾å’Œåç§»ç‰¹å¾ï¼š
```python
gamma, beta = film_generator(c)
h = gamma * h + beta
```

ğŸ”¬ **ç ”ç©¶çº¿ç´¢ï¼šæœ€ä¼˜æ³¨å…¥ä½ç½®**  
åº”è¯¥åœ¨ç½‘ç»œçš„å“ªäº›å±‚æ³¨å…¥æ¡ä»¶ä¿¡æ¯ï¼Ÿæ—©æœŸå±‚vsåæœŸå±‚ï¼Ÿæ‰€æœ‰å±‚vsç‰¹å®šå±‚ï¼Ÿè¿™å¯èƒ½ä¾èµ–äºæ¡ä»¶ç±»å‹å’Œä»»åŠ¡ã€‚

### 9.1.3 æ¶æ„è®¾è®¡åŸåˆ™

**1. æ¡ä»¶ç¼–ç å™¨è®¾è®¡**

ä¸åŒç±»å‹çš„æ¡ä»¶éœ€è¦ä¸åŒçš„ç¼–ç å™¨ï¼š
- **ç±»åˆ«æ ‡ç­¾**ï¼šåµŒå…¥å±‚ + MLP
- **æ–‡æœ¬**ï¼šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆCLIP, T5ç­‰ï¼‰
- **å›¾åƒ**ï¼šé¢„è®­ç»ƒè§†è§‰æ¨¡å‹æˆ–ä¸“ç”¨CNN
- **éŸ³é¢‘**ï¼šé¢‘è°±å›¾ç¼–ç å™¨

**2. å¤šå°ºåº¦æ¡ä»¶æ³¨å…¥**

åœ¨U-Netçš„ä¸åŒåˆ†è¾¨ç‡æ³¨å…¥æ¡ä»¶ï¼š
```python
class ConditionalUNet(nn.Module):
    def forward(self, x, t, c):
        # ç¼–ç è·¯å¾„
        h1 = self.down1(x, t, c)  # é«˜åˆ†è¾¨ç‡æ¡ä»¶
        h2 = self.down2(h1, t, c)  # ä¸­åˆ†è¾¨ç‡æ¡ä»¶
        h3 = self.down3(h2, t, c)  # ä½åˆ†è¾¨ç‡æ¡ä»¶
        
        # è§£ç è·¯å¾„ä¹Ÿæ³¨å…¥æ¡ä»¶
        ...
```

**3. æ—¶é—´-æ¡ä»¶äº¤äº’**

æ—¶é—´æ­¥å’Œæ¡ä»¶ä¿¡æ¯å¯èƒ½éœ€è¦äº¤äº’ï¼š
```python
# è”åˆç¼–ç 
t_embed = self.time_embed(t)
c_embed = self.cond_embed(c)
joint_embed = self.joint_mlp(t_embed + c_embed)
```

### 9.1.4 è®­ç»ƒç­–ç•¥

**1. æ¡ä»¶dropout**

éšæœºä¸¢å¼ƒæ¡ä»¶ä¿¡æ¯ï¼Œè®­ç»ƒæ¨¡å‹åŒæ—¶å¤„ç†æ¡ä»¶å’Œæ— æ¡ä»¶ç”Ÿæˆï¼š
```python
def training_step(x, c):
    # ä»¥æ¦‚ç‡p_uncondä¸¢å¼ƒæ¡ä»¶
    if random.random() < p_uncond:
        c = null_condition
    
    # æ­£å¸¸è®­ç»ƒ
    noise = torch.randn_like(x)
    x_t = add_noise(x, noise, t)
    pred_noise = model(x_t, t, c)
    loss = F.mse_loss(pred_noise, noise)
```

è¿™æ˜¯æ— åˆ†ç±»å™¨å¼•å¯¼çš„åŸºç¡€ã€‚

**2. æ¡ä»¶å¢å¼º**

å¯¹æ¡ä»¶ä¿¡æ¯è¿›è¡Œæ•°æ®å¢å¼ºï¼š
- æ–‡æœ¬ï¼šåŒä¹‰è¯æ›¿æ¢ã€æ”¹å†™
- å›¾åƒï¼šå‡ ä½•å˜æ¢ã€é¢œè‰²æ‰°åŠ¨
- ç±»åˆ«ï¼šæ ‡ç­¾å¹³æ»‘ã€æ··åˆ

**3. å¤šä»»åŠ¡å­¦ä¹ **

åŒæ—¶è®­ç»ƒå¤šç§æ¡ä»¶ï¼š
```python
loss = loss_uncond + Î»1*loss_class + Î»2*loss_text + Î»3*loss_image
```

ğŸ’¡ **å®è·µæŠ€å·§ï¼šæ¡ä»¶ç¼©æ”¾**  
ä¸åŒæ¡ä»¶çš„å¼ºåº¦å¯èƒ½éœ€è¦ä¸åŒçš„ç¼©æ”¾ã€‚ä½¿ç”¨å¯å­¦ä¹ çš„ç¼©æ”¾å› å­ï¼š`c_scaled = c * self.condition_scale`

<details>
<summary>**ç»ƒä¹  9.1ï¼šå®ç°å¤šæ¨¡æ€æ¡ä»¶æ‰©æ•£æ¨¡å‹**</summary>

è®¾è®¡ä¸€ä¸ªæ”¯æŒå¤šç§æ¡ä»¶ç±»å‹çš„æ‰©æ•£æ¨¡å‹ã€‚

1. **åŸºç¡€æ¶æ„**ï¼š
   - å®ç°æ”¯æŒç±»åˆ«ã€æ–‡æœ¬ã€å›¾åƒæ¡ä»¶çš„U-Net
   - è®¾è®¡çµæ´»çš„æ¡ä»¶æ³¨å…¥æœºåˆ¶
   - å¤„ç†æ¡ä»¶ç¼ºå¤±çš„æƒ…å†µ

2. **æ¡ä»¶ç¼–ç å™¨**ï¼š
   - ç±»åˆ«ï¼šå¯å­¦ä¹ åµŒå…¥
   - æ–‡æœ¬ï¼šä½¿ç”¨é¢„è®­ç»ƒCLIP
   - å›¾åƒï¼šè½»é‡çº§CNNç¼–ç å™¨

3. **è®­ç»ƒå®éªŒ**ï¼š
   - æ¯”è¾ƒä¸åŒæ³¨å…¥æ–¹å¼çš„æ•ˆæœ
   - ç ”ç©¶æ¡ä»¶dropoutç‡çš„å½±å“
   - æµ‹è¯•å¤šæ¡ä»¶ç»„åˆ

4. **æ‰©å±•ç ”ç©¶**ï¼š
   - è®¾è®¡æ¡ä»¶å¼ºåº¦çš„è‡ªé€‚åº”è°ƒæ•´
   - å®ç°æ¡ä»¶æ’å€¼
   - æ¢ç´¢æ–°çš„æ¡ä»¶ç±»å‹ï¼ˆå¦‚è‰å›¾ã€æ·±åº¦å›¾ï¼‰

</details>

### 9.1.5 æ¡ä»¶ä¸€è‡´æ€§çš„ç†è®ºä¿è¯

**å˜åˆ†ä¸‹ç•Œçš„æ¡ä»¶ç‰ˆæœ¬**ï¼š

$$\log p_\theta(\mathbf{x}_0|\mathbf{c}) \geq \mathbb{E}_q\left[\log p_\theta(\mathbf{x}_0|\mathbf{x}_1, \mathbf{c}) - \sum_{t=2}^T D_{KL}(q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{c}))\right]$$

è¿™ä¿è¯äº†æ¨¡å‹å­¦ä¹ çš„æ˜¯çœŸå®çš„æ¡ä»¶åˆ†å¸ƒã€‚

**æ¡ä»¶ç‹¬ç«‹æ€§å‡è®¾**ï¼š

åœ¨è®¸å¤šå®ç°ä¸­ï¼Œæˆ‘ä»¬å‡è®¾ï¼š
$$q(\mathbf{x}_t|\mathbf{x}_0, \mathbf{c}) = q(\mathbf{x}_t|\mathbf{x}_0)$$

å³å‰å‘è¿‡ç¨‹ä¸æ¡ä»¶æ— å…³ã€‚è¿™ç®€åŒ–äº†è®­ç»ƒä½†å¯èƒ½é™åˆ¶äº†æ¨¡å‹èƒ½åŠ›ã€‚

ğŸŒŸ **å¼€æ”¾é—®é¢˜ï¼šæ¡ä»¶ç›¸å…³çš„å‰å‘è¿‡ç¨‹**  
æ˜¯å¦å¯ä»¥è®¾è®¡ä¾èµ–äºæ¡ä»¶çš„å‰å‘è¿‡ç¨‹ï¼Ÿä¾‹å¦‚ï¼Œå¯¹ä¸åŒç±»åˆ«ä½¿ç”¨ä¸åŒçš„å™ªå£°è°ƒåº¦ï¼Ÿè¿™å¯èƒ½æä¾›æ›´å¥½çš„å½’çº³åç½®ã€‚

### 9.1.6 å®ç°ç»†èŠ‚ä¸ä¼˜åŒ–

**å†…å­˜ä¼˜åŒ–**ï¼š
```python
# ä½¿ç”¨gradient checkpointingèŠ‚çœå†…å­˜
class ConditionalBlock(nn.Module):
    @torch.utils.checkpoint.checkpoint
    def forward(self, x, c):
        # è®¡ç®—å¯†é›†çš„æ“ä½œ
        ...
```

**è®¡ç®—ä¼˜åŒ–**ï¼š
```python
# ç¼“å­˜æ¡ä»¶ç¼–ç 
class CachedConditionEncoder:
    def __init__(self):
        self.cache = {}
    
    def encode(self, c):
        if c not in self.cache:
            self.cache[c] = self.encoder(c)
        return self.cache[c]
```

**æ•°å€¼ç¨³å®šæ€§**ï¼š
```python
# é˜²æ­¢æ¡ä»¶ç¼–ç çš„æ•°å€¼é—®é¢˜
c_encoded = F.normalize(c_encoded, dim=-1) * self.scale
```

## 9.2 åˆ†ç±»å™¨å¼•å¯¼ï¼ˆClassifier Guidanceï¼‰

### 9.2.1 ç†è®ºæ¨å¯¼

åˆ†ç±»å™¨å¼•å¯¼çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä½¿ç”¨å¤–éƒ¨åˆ†ç±»å™¨çš„æ¢¯åº¦æ¥å¼•å¯¼æ‰©æ•£æ¨¡å‹çš„é‡‡æ ·è¿‡ç¨‹ã€‚æˆ‘ä»¬ä»è´å¶æ–¯è§„åˆ™å¼€å§‹ï¼š

$$\nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t|\mathbf{c}) = \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t) + \nabla_{\mathbf{x}_t} \log p(\mathbf{c}|\mathbf{x}_t)$$

ç¬¬ä¸€é¡¹æ˜¯æ— æ¡ä»¶åˆ†æ•°ï¼Œç¬¬äºŒé¡¹æ˜¯åˆ†ç±»å™¨çš„æ¢¯åº¦ã€‚è¿™ç»™å‡ºäº†æ¡ä»¶é‡‡æ ·çš„æ›´æ–°è§„åˆ™ï¼š

$$\tilde{\boldsymbol{\epsilon}}_\theta(\mathbf{x}_t, t, \mathbf{c}) = \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) - \sqrt{1 - \bar{\alpha}_t} \nabla_{\mathbf{x}_t} \log p_\phi(\mathbf{c}|\mathbf{x}_t)$$

å…¶ä¸­ $p_\phi(\mathbf{c}|\mathbf{x}_t)$ æ˜¯åœ¨å™ªå£°æ•°æ®ä¸Šè®­ç»ƒçš„åˆ†ç±»å™¨ã€‚

### 9.2.2 å™ªå£°æ¡ä»¶åˆ†ç±»å™¨

å…³é”®æŒ‘æˆ˜æ˜¯è®­ç»ƒä¸€ä¸ªèƒ½åœ¨æ‰€æœ‰å™ªå£°æ°´å¹³ $t$ ä¸Šå·¥ä½œçš„åˆ†ç±»å™¨ã€‚è®­ç»ƒè¿‡ç¨‹ï¼š

```python
def train_noise_conditional_classifier(classifier, diffusion, dataloader):
    for x, c in dataloader:
        # éšæœºé‡‡æ ·æ—¶é—´æ­¥
        t = torch.randint(0, diffusion.num_timesteps, (x.shape[0],))
        
        # æ·»åŠ ç›¸åº”çš„å™ªå£°
        noise = torch.randn_like(x)
        x_t = diffusion.q_sample(x, t, noise)
        
        # åˆ†ç±»å™¨é¢„æµ‹
        logits = classifier(x_t, t)
        loss = F.cross_entropy(logits, c)
        
        loss.backward()
```

åˆ†ç±»å™¨æ¶æ„éœ€è¦ï¼š
1. æ—¶é—´æ¡ä»¶ï¼šäº†è§£å½“å‰å™ªå£°æ°´å¹³
2. é²æ£’æ€§ï¼šåœ¨é«˜å™ªå£°ä¸‹ä»èƒ½æå–æœ‰ç”¨ç‰¹å¾
3. æ¢¯åº¦è´¨é‡ï¼šæä¾›æœ‰æ„ä¹‰çš„å¼•å¯¼ä¿¡å·

### 9.2.3 å¼•å¯¼å¼ºåº¦ä¸é‡‡æ ·

å¼•å¯¼å¼ºåº¦ $s$ æ§åˆ¶æ¡ä»¶çš„å½±å“ç¨‹åº¦ï¼š

$$\tilde{\boldsymbol{\epsilon}}_\theta(\mathbf{x}_t, t, \mathbf{c}) = \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t) - s\sqrt{1 - \bar{\alpha}_t} \nabla_{\mathbf{x}_t} \log p_\phi(\mathbf{c}|\mathbf{x}_t)$$

- $s = 0$ï¼šæ— æ¡ä»¶ç”Ÿæˆ
- $s = 1$ï¼šæ ‡å‡†æ¡ä»¶ç”Ÿæˆ
- $s > 1$ï¼šå¼ºåŒ–æ¡ä»¶ï¼Œå¯èƒ½é™ä½å¤šæ ·æ€§
- $s < 0$ï¼šè´Ÿå‘å¼•å¯¼ï¼Œè¿œç¦»æ¡ä»¶

**é‡‡æ ·ç®—æ³•**ï¼š
```python
def classifier_guided_sampling(x_T, model, classifier, c, s=1.0):
    x = x_T
    for t in reversed(range(T)):
        # æ— æ¡ä»¶é¢„æµ‹
        epsilon = model(x, t)
        
        # è®¡ç®—åˆ†ç±»å™¨æ¢¯åº¦
        x.requires_grad_(True)
        logits = classifier(x, t)
        log_prob = F.log_softmax(logits, dim=-1)[range(len(c)), c]
        grad = torch.autograd.grad(log_prob.sum(), x)[0]
        x.requires_grad_(False)
        
        # ç»„åˆé¢„æµ‹
        epsilon_tilde = epsilon - s * sqrt(1 - alphas_cumprod[t]) * grad
        
        # é‡‡æ ·æ­¥éª¤
        x = sampling_step(x, epsilon_tilde, t)
    
    return x
```

### 9.2.4 æ¢¯åº¦è®¡ç®—çš„å®è·µè€ƒè™‘

**1. æ¢¯åº¦ç¼©æ”¾**

ä¸åŒæ—¶é—´æ­¥çš„æ¢¯åº¦é‡çº§å·®å¼‚å¾ˆå¤§ï¼Œéœ€è¦è‡ªé€‚åº”ç¼©æ”¾ï¼š
```python
# æ ¹æ®å™ªå£°æ°´å¹³è°ƒæ•´æ¢¯åº¦
grad_scale = 1.0 / (1 - alphas_cumprod[t]).sqrt()
scaled_grad = grad * grad_scale
```

**2. æ¢¯åº¦è£å‰ª**

é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼š
```python
grad_norm = grad.flatten(1).norm(dim=1, keepdim=True)
grad = grad / grad_norm.clamp(min=1e-8)
```

**3. å¤šæ­¥æ¢¯åº¦**

ä½¿ç”¨å¤šæ­¥æ¢¯åº¦ç´¯ç§¯è·å¾—æ›´ç¨³å®šçš„æ–¹å‘ï¼š
```python
grad_accum = 0
for _ in range(n_grad_steps):
    grad = compute_classifier_grad(x + noise_scale * torch.randn_like(x))
    grad_accum += grad
grad = grad_accum / n_grad_steps
```

ğŸ’¡ **å®è·µæŠ€å·§ï¼šæ¸©åº¦è°ƒèŠ‚**  
å¯¹åˆ†ç±»å™¨è¾“å‡ºä½¿ç”¨æ¸©åº¦ç¼©æ”¾å¯ä»¥æ§åˆ¶å¼•å¯¼çš„é”åº¦ï¼š`logits = classifier(x, t) / temperature`

### 9.2.5 å±€é™æ€§åˆ†æ

**1. éœ€è¦é¢å¤–çš„åˆ†ç±»å™¨**
- å¢åŠ è®­ç»ƒæˆæœ¬
- åˆ†ç±»å™¨è´¨é‡å½±å“ç”Ÿæˆè´¨é‡
- éœ€è¦ä¸ºæ¯ä¸ªæ¡ä»¶ç±»å‹è®­ç»ƒåˆ†ç±»å™¨

**2. æ¢¯åº¦è´¨é‡é—®é¢˜**
- é«˜å™ªå£°ä¸‹æ¢¯åº¦å¯èƒ½æ— æ„ä¹‰
- å¯¹æŠ—æ ·æœ¬é—®é¢˜
- æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸

**3. æ¨¡å¼å´©æºƒé£é™©**
- è¿‡å¼ºçš„å¼•å¯¼å¯¼è‡´å¤šæ ·æ€§ä¸§å¤±
- ç”Ÿæˆåˆ†å¸ƒåç¦»çœŸå®åˆ†å¸ƒ
- éš¾ä»¥å¹³è¡¡è´¨é‡å’Œå¤šæ ·æ€§

**4. è®¡ç®—å¼€é”€**
- æ¯æ­¥éœ€è¦é¢å¤–çš„å‰å‘å’Œåå‘ä¼ æ’­
- å†…å­˜å ç”¨å¢åŠ 
- é‡‡æ ·é€Ÿåº¦æ˜¾è‘—é™ä½

<details>
<summary>**ç»ƒä¹  9.2ï¼šåˆ†æåˆ†ç±»å™¨å¼•å¯¼çš„è¡Œä¸º**</summary>

æ·±å…¥ç ”ç©¶åˆ†ç±»å™¨å¼•å¯¼åœ¨ä¸åŒè®¾ç½®ä¸‹çš„è¡¨ç°ã€‚

1. **å¼•å¯¼å¼ºåº¦å®éªŒ**ï¼š
   - åœ¨MNISTä¸Šè®­ç»ƒæ‰©æ•£æ¨¡å‹å’Œåˆ†ç±»å™¨
   - æµ‹è¯•ä¸åŒå¼•å¯¼å¼ºåº¦ s âˆˆ [0, 0.5, 1, 2, 5, 10]
   - ç»˜åˆ¶ç”Ÿæˆè´¨é‡vså¤šæ ·æ€§æ›²çº¿

2. **æ¢¯åº¦å¯è§†åŒ–**ï¼š
   - å¯è§†åŒ–ä¸åŒæ—¶é—´æ­¥çš„åˆ†ç±»å™¨æ¢¯åº¦
   - åˆ†ææ¢¯åº¦æ–¹å‘çš„è¯­ä¹‰å«ä¹‰
   - ç ”ç©¶æ¢¯åº¦èŒƒæ•°çš„å˜åŒ–

3. **å¤±æ•ˆæ¨¡å¼åˆ†æ**ï¼š
   - è¯†åˆ«åˆ†ç±»å™¨å¼•å¯¼å¤±è´¥çš„æ¡ˆä¾‹
   - åˆ†æè¿‡åº¦å¼•å¯¼çš„è¡¨ç°
   - è®¾è®¡æ”¹è¿›ç­–ç•¥

4. **ç†è®ºæ‹“å±•**ï¼š
   - æ¨å¯¼æœ€ä¼˜å¼•å¯¼å¼ºåº¦çš„ç†è®º
   - ç ”ç©¶å¼•å¯¼å¯¹ç”Ÿæˆåˆ†å¸ƒçš„å½±å“
   - æ¢ç´¢è‡ªé€‚åº”å¼•å¯¼å¼ºåº¦

</details>

### 9.2.6 æ”¹è¿›ä¸å˜ä½“

**1. æˆªæ–­å¼•å¯¼**

åªåœ¨ç‰¹å®šæ—¶é—´èŒƒå›´å†…åº”ç”¨å¼•å¯¼ï¼š
```python
if t > T_start and t < T_end:
    epsilon = epsilon - s * grad
```

**2. å±€éƒ¨å¼•å¯¼**

åªå¯¹å›¾åƒçš„ç‰¹å®šåŒºåŸŸåº”ç”¨å¼•å¯¼ï¼š
```python
mask = compute_attention_mask(x, c)
epsilon = epsilon - s * grad * mask
```

**3. å¤šåˆ†ç±»å™¨é›†æˆ**

ä½¿ç”¨å¤šä¸ªåˆ†ç±»å™¨çš„ç»„åˆï¼š
```python
grad_ensemble = 0
for classifier in classifiers:
    grad_ensemble += compute_grad(classifier, x, t, c)
grad = grad_ensemble / len(classifiers)
```

ğŸ”¬ **ç ”ç©¶æ–¹å‘ï¼šéšå¼åˆ†ç±»å™¨**  
èƒ½å¦ä»æ‰©æ•£æ¨¡å‹æœ¬èº«æå–åˆ†ç±»å™¨ï¼Œé¿å…è®­ç»ƒé¢å¤–æ¨¡å‹ï¼Ÿè¿™æ¶‰åŠåˆ°å¯¹æ‰©æ•£æ¨¡å‹å†…éƒ¨è¡¨ç¤ºçš„æ·±å…¥ç†è§£ã€‚

### 9.2.7 ä¸å…¶ä»–æ–¹æ³•çš„è”ç³»

åˆ†ç±»å™¨å¼•å¯¼ä¸å…¶ä»–ç”Ÿæˆæ¨¡å‹æŠ€æœ¯æœ‰æ·±åˆ»è”ç³»ï¼š

**1. ä¸GANçš„åˆ¤åˆ«å™¨å¼•å¯¼ç±»ä¼¼**
- éƒ½ä½¿ç”¨å¤–éƒ¨æ¨¡å‹æä¾›æ¢¯åº¦ä¿¡å·
- éƒ½é¢ä¸´è®­ç»ƒä¸ç¨³å®šçš„é—®é¢˜

**2. ä¸èƒ½é‡æ¨¡å‹çš„å…³ç³»**
- åˆ†ç±»å™¨å®šä¹‰äº†èƒ½é‡æ™¯è§‚
- å¼•å¯¼ç›¸å½“äºåœ¨èƒ½é‡æ™¯è§‚ä¸Šçš„æ¢¯åº¦ä¸‹é™

**3. ä¸å¼ºåŒ–å­¦ä¹ çš„å¥–åŠ±å¼•å¯¼**
- åˆ†ç±»å™¨æ¦‚ç‡ç±»ä¼¼å¥–åŠ±ä¿¡å·
- å¯ä»¥å€Ÿé‰´RLä¸­çš„æŠ€æœ¯ï¼ˆå¦‚PPOï¼‰

ğŸŒŸ **æœªæ¥å±•æœ›ï¼šç»Ÿä¸€çš„å¼•å¯¼æ¡†æ¶**  
æ˜¯å¦å­˜åœ¨ä¸€ä¸ªç»Ÿä¸€çš„ç†è®ºæ¡†æ¶ï¼Œæ¶µç›–æ‰€æœ‰ç±»å‹çš„å¼•å¯¼ï¼Ÿè¿™å¯èƒ½éœ€è¦ä»æœ€ä¼˜æ§åˆ¶æˆ–å˜åˆ†æ¨æ–­çš„è§’åº¦é‡æ–°æ€è€ƒã€‚

## 9.3 æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆClassifier-Free Guidanceï¼‰

### 9.3.1 åŠ¨æœºä¸æ ¸å¿ƒæ´å¯Ÿ

æ— åˆ†ç±»å™¨å¼•å¯¼ï¼ˆCFGï¼‰è§£å†³äº†åˆ†ç±»å™¨å¼•å¯¼çš„ä¸»è¦é™åˆ¶ï¼šä¸éœ€è¦è®­ç»ƒé¢å¤–çš„åˆ†ç±»å™¨ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯åŒæ—¶è®­ç»ƒæ¡ä»¶å’Œæ— æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼Œç„¶ååœ¨é‡‡æ ·æ—¶ç»„åˆå®ƒä»¬çš„é¢„æµ‹ã€‚

åŸºæœ¬åŸç†åŸºäºï¼š
$$\nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t|\mathbf{c}) = \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t) + \nabla_{\mathbf{x}_t} \log p(\mathbf{c}|\mathbf{x}_t)$$

CFGé€šè¿‡éšå¼ä¼°è®¡ $\nabla_{\mathbf{x}_t} \log p(\mathbf{c}|\mathbf{x}_t)$ï¼š
$$\nabla_{\mathbf{x}_t} \log p(\mathbf{c}|\mathbf{x}_t) \approx \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t|\mathbf{c}) - \nabla_{\mathbf{x}_t} \log p(\mathbf{x}_t)$$

### 9.3.2 è®­ç»ƒç­–ç•¥ï¼šæ¡ä»¶Dropout

å…³é”®åˆ›æ–°æ˜¯åœ¨è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒæ¡ä»¶ï¼š

```python
def train_classifier_free(model, x, c, p_uncond=0.1):
    # éšæœºå†³å®šæ˜¯å¦ä½¿ç”¨æ¡ä»¶
    if torch.rand(1).item() < p_uncond:
        # æ— æ¡ä»¶è®­ç»ƒ
        c = null_token  # ç‰¹æ®Šçš„ç©ºæ¡ä»¶æ ‡è®°
    
    # æ ‡å‡†æ‰©æ•£æ¨¡å‹è®­ç»ƒ
    t = torch.randint(0, num_timesteps, (x.shape[0],))
    noise = torch.randn_like(x)
    x_t = add_noise(x, noise, t)
    
    # é¢„æµ‹å™ªå£°
    pred_noise = model(x_t, t, c)
    loss = F.mse_loss(pred_noise, noise)
    
    return loss
```

è¿™ä½¿å¾—å•ä¸ªæ¨¡å‹èƒ½å¤Ÿå¤„ç†æ¡ä»¶å’Œæ— æ¡ä»¶ç”Ÿæˆã€‚

### 9.3.3 é‡‡æ ·å…¬å¼

CFGçš„é‡‡æ ·å…¬å¼ï¼š
$$\tilde{\boldsymbol{\epsilon}}_\theta(\mathbf{x}_t, t, \mathbf{c}) = (1 + w)\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \mathbf{c}) - w\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \varnothing)$$

å…¶ä¸­ï¼š
- $w$ï¼šå¼•å¯¼æƒé‡ï¼ˆguidance weightï¼‰
- $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \mathbf{c})$ï¼šæ¡ä»¶é¢„æµ‹
- $\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \varnothing)$ï¼šæ— æ¡ä»¶é¢„æµ‹

è¿™å¯ä»¥é‡å†™ä¸ºï¼š
$$\tilde{\boldsymbol{\epsilon}}_\theta = \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \varnothing) + w[\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \mathbf{c}) - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t, \varnothing)]$$

æ˜¾ç¤ºäº†ä»æ— æ¡ä»¶é¢„æµ‹å‡ºå‘ï¼Œæœæ¡ä»¶æ–¹å‘ç§»åŠ¨çš„è§£é‡Šã€‚

### 9.3.4 å®ç°ç»†èŠ‚

**é«˜æ•ˆé‡‡æ ·å®ç°**ï¼š
```python
def cfg_sampling(model, shape, c, w=7.5, eta=0):
    # åˆå§‹å™ªå£°
    x = torch.randn(shape)
    
    # å‡†å¤‡æ¡ä»¶å’Œæ— æ¡ä»¶è¾“å…¥
    c_in = torch.cat([c, null_token])  # æ‰¹é‡å¤„ç†
    
    for t in tqdm(reversed(range(num_timesteps))):
        # å•æ¬¡å‰å‘ä¼ æ’­è·å¾—ä¸¤ä¸ªé¢„æµ‹
        x_in = torch.cat([x, x])
        t_in = torch.cat([t, t])
        noise_pred = model(x_in, t_in, c_in)
        
        # åˆ†ç¦»æ¡ä»¶å’Œæ— æ¡ä»¶é¢„æµ‹
        noise_c, noise_u = noise_pred.chunk(2)
        
        # CFGç»„åˆ
        noise_pred = noise_u + w * (noise_c - noise_u)
        
        # DDIM/DDPMé‡‡æ ·æ­¥éª¤
        x = sampling_step(x, noise_pred, t, eta)
    
    return x
```

**å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬**ï¼š
```python
def memory_efficient_cfg(model, x, t, c, w):
    # ä½¿ç”¨gradient checkpointing
    with torch.no_grad():
        # æ— æ¡ä»¶é¢„æµ‹
        noise_u = model(x, t, null_token)
    
    # åªå¯¹æ¡ä»¶é¢„æµ‹è®¡ç®—æ¢¯åº¦ï¼ˆå¦‚æœéœ€è¦ï¼‰
    noise_c = model(x, t, c)
    
    return noise_u + w * (noise_c - noise_u)
```

### 9.3.5 å¼•å¯¼æƒé‡çš„é€‰æ‹©

ä¸åŒçš„ $w$ å€¼äº§ç”Ÿä¸åŒæ•ˆæœï¼š

| $w$ å€¼ | æ•ˆæœ | å…¸å‹åº”ç”¨ |
|--------|------|----------|
| 0 | æ— æ¡ä»¶ç”Ÿæˆ | æµ‹è¯•åŸºçº¿ |
| 1 | æ ‡å‡†æ¡ä»¶ç”Ÿæˆ | ä¿å®ˆç”Ÿæˆ |
| 3-5 | è½»åº¦å¼•å¯¼ | å¹³è¡¡è´¨é‡ |
| 7.5 | æ ‡å‡†å¼•å¯¼ | é»˜è®¤è®¾ç½® |
| 10-20 | å¼ºå¼•å¯¼ | é«˜ä¿çœŸåº¦ |
| >20 | æç«¯å¼•å¯¼ | å¯èƒ½è¿‡é¥±å’Œ |

**åŠ¨æ€å¼•å¯¼è°ƒåº¦**ï¼š
```python
def dynamic_guidance_weight(t, T):
    # æ—©æœŸä½¿ç”¨å¼ºå¼•å¯¼ï¼ŒåæœŸå‡å¼±
    progress = t / T
    w = w_start * (1 - progress) + w_end * progress
    return w
```

ğŸ’¡ **å®è·µæ´å¯Ÿï¼šå¼•å¯¼æƒé‡ä¸æ¡ä»¶ç±»å‹**  
ä¸åŒæ¡ä»¶ç±»å‹éœ€è¦ä¸åŒçš„å¼•å¯¼å¼ºåº¦ã€‚æ–‡æœ¬æ¡ä»¶é€šå¸¸éœ€è¦ w=7.5ï¼Œè€Œç±»åˆ«æ¡ä»¶å¯èƒ½åªéœ€è¦ w=3ã€‚

### 9.3.6 ç†è®ºåˆ†æ

**1. ä¸ºä»€ä¹ˆCFGæœ‰æ•ˆï¼Ÿ**

CFGéšå¼åœ°å¢å¼ºäº†æ¡ä»¶çš„å¯¹æ•°ä¼¼ç„¶ï¼š
$$\log \tilde{p}(\mathbf{x}|\mathbf{c}) = \log p(\mathbf{x}|\mathbf{c}) + w\log p(\mathbf{c}|\mathbf{x})$$

è¿™ç›¸å½“äºåœ¨é‡‡æ ·æ—¶é‡æ–°åŠ æƒæ¡ä»¶çš„é‡è¦æ€§ã€‚

**2. ä¸å˜åˆ†æ¨æ–­çš„è”ç³»**

CFGå¯ä»¥è§†ä¸ºå˜åˆ†æ¨æ–­ä¸­çš„é‡è¦æ€§åŠ æƒï¼š
- æé«˜é«˜æ¡ä»¶ä¼¼ç„¶åŒºåŸŸçš„é‡‡æ ·æ¦‚ç‡
- å‡å°‘ä½æ¡ä»¶ä¼¼ç„¶åŒºåŸŸçš„é‡‡æ ·æ¦‚ç‡

**3. å‡ ä½•è§£é‡Š**

åœ¨å™ªå£°é¢„æµ‹ç©ºé—´ä¸­ï¼ŒCFGæ‰§è¡Œå¤–æ¨ï¼š
- ä»æ— æ¡ä»¶é¢„æµ‹å‡ºå‘
- æ²¿ç€æŒ‡å‘æ¡ä»¶é¢„æµ‹çš„æ–¹å‘ç§»åŠ¨
- å¯èƒ½è¶…è¶Šæ¡ä»¶é¢„æµ‹ï¼ˆå½“ $w > 1$ï¼‰

<details>
<summary>**ç»ƒä¹  9.3ï¼šCFGçš„æ·±å…¥åˆ†æ**</summary>

æ¢ç´¢CFGçš„å„ç§ç‰¹æ€§å’Œæ”¹è¿›æ–¹æ³•ã€‚

1. **å¼•å¯¼æƒé‡è°ƒåº¦**ï¼š
   - å®ç°çº¿æ€§ã€ä½™å¼¦ã€æŒ‡æ•°è°ƒåº¦
   - æ¯”è¾ƒä¸åŒè°ƒåº¦å¯¹ç”Ÿæˆè´¨é‡çš„å½±å“
   - æ‰¾å‡ºæœ€ä¼˜çš„è°ƒåº¦ç­–ç•¥

2. **æ¡ä»¶dropoutç‡ç ”ç©¶**ï¼š
   - æµ‹è¯• p_uncond âˆˆ [0.05, 0.1, 0.2, 0.5]
   - åˆ†æå¯¹æ¨¡å‹æ³›åŒ–çš„å½±å“
   - ç ”ç©¶ä¸å¼•å¯¼æƒé‡çš„äº¤äº’

3. **å¤šæ¡ä»¶CFG**ï¼š
   - å®ç°æ”¯æŒå¤šä¸ªæ¡ä»¶çš„CFG
   - è®¾è®¡æ¡ä»¶æƒé‡åˆ†é…ç­–ç•¥
   - å¤„ç†æ¡ä»¶å†²çª

4. **ç†è®ºæ‰©å±•**ï¼š
   - æ¨å¯¼CFGçš„æœ€ä¼˜å¼•å¯¼æƒé‡
   - åˆ†æCFGå¯¹ç”Ÿæˆåˆ†å¸ƒçš„å½±å“
   - ç ”ç©¶CFGä¸å…¶ä»–é‡‡æ ·æ–¹æ³•çš„ç»„åˆ

</details>

### 9.3.7 é«˜çº§æŠ€å·§

**1. è´Ÿå‘æç¤ºï¼ˆNegative Promptingï¼‰**

ä½¿ç”¨è´Ÿæ¡ä»¶æ¥é¿å…ç‰¹å®šå†…å®¹ï¼š
```python
def cfg_with_negative(x_t, t, c_pos, c_neg, w_pos=7.5, w_neg=7.5):
    noise_uncond = model(x_t, t, null_token)
    noise_pos = model(x_t, t, c_pos)
    noise_neg = model(x_t, t, c_neg)
    
    # ç»„åˆå…¬å¼
    noise = noise_uncond + w_pos * (noise_pos - noise_uncond) - w_neg * (noise_neg - noise_uncond)
    return noise
```

**2. å¤šå°ºåº¦å¼•å¯¼**

åœ¨ä¸åŒæ—¶é—´æ­¥ä½¿ç”¨ä¸åŒçš„å¼•å¯¼ç­–ç•¥ï¼š
```python
def multiscale_cfg(t, T):
    if t > 0.8 * T:  # æ—©æœŸï¼šå¼ºè¯­ä¹‰å¼•å¯¼
        return cfg_semantic(w=10)
    elif t > 0.3 * T:  # ä¸­æœŸï¼šå¹³è¡¡å¼•å¯¼
        return cfg_balanced(w=7.5)
    else:  # åæœŸï¼šç»†èŠ‚å¼•å¯¼
        return cfg_detail(w=3)
```

**3. è‡ªé€‚åº”CFG**

æ ¹æ®é¢„æµ‹çš„ä¸ç¡®å®šæ€§è°ƒæ•´å¼•å¯¼ï¼š
```python
def adaptive_cfg(noise_c, noise_u):
    # è®¡ç®—é¢„æµ‹å·®å¼‚
    diff = (noise_c - noise_u).abs().mean()
    
    # å·®å¼‚å¤§æ—¶å‡å°å¼•å¯¼æƒé‡
    w = base_weight * torch.exp(-alpha * diff)
    
    return noise_u + w * (noise_c - noise_u)
```

ğŸ”¬ **ç ”ç©¶æ–¹å‘ï¼šç†è®ºæœ€ä¼˜çš„å¼•å¯¼**  
å½“å‰çš„çº¿æ€§ç»„åˆæ˜¯å¦æ˜¯æœ€ä¼˜çš„ï¼Ÿæ˜¯å¦å­˜åœ¨éçº¿æ€§çš„ç»„åˆæ–¹å¼èƒ½äº§ç”Ÿæ›´å¥½çš„ç»“æœï¼Ÿè¿™éœ€è¦ä»ä¿¡æ¯è®ºè§’åº¦æ·±å…¥åˆ†æã€‚

### 9.3.8 CFGçš„ä¼˜åŠ¿ä¸å±€é™

**ä¼˜åŠ¿**ï¼š
1. **ç®€æ´æ€§**ï¼šä¸éœ€è¦é¢å¤–æ¨¡å‹
2. **çµæ´»æ€§**ï¼šæ˜“äºè°ƒæ•´å¼•å¯¼å¼ºåº¦
3. **é€šç”¨æ€§**ï¼šé€‚ç”¨äºä»»ä½•æ¡ä»¶ç±»å‹
4. **æ•ˆæœå¥½**ï¼šå®è·µä¸­è¡¨ç°ä¼˜å¼‚

**å±€é™**ï¼š
1. **è®¡ç®—å¼€é”€**ï¼šéœ€è¦ä¸¤æ¬¡å‰å‘ä¼ æ’­
2. **è®­ç»ƒè¦æ±‚**ï¼šéœ€è¦æ¡ä»¶dropout
3. **åˆ†å¸ƒåç§»**ï¼šå¼ºå¼•å¯¼å¯èƒ½å¯¼è‡´åˆ†å¸ƒåç¦»
4. **æ¨¡å¼ä¸¢å¤±**ï¼šå¯èƒ½é™ä½å¤šæ ·æ€§

### 9.3.9 ä¸å…¶ä»–æ–¹æ³•çš„æ¯”è¾ƒ

| æ–¹æ³• | é¢å¤–æ¨¡å‹ | è®¡ç®—æˆæœ¬ | çµæ´»æ€§ | æ•ˆæœ |
|------|----------|----------|---------|------|
| åˆ†ç±»å™¨å¼•å¯¼ | éœ€è¦ | é«˜ï¼ˆæ¢¯åº¦ï¼‰ | ä¸­ | å¥½ |
| CFG | ä¸éœ€è¦ | ä¸­ï¼ˆ2xå‰å‘ï¼‰ | é«˜ | å¾ˆå¥½ |
| åŸå§‹æ¡ä»¶ | ä¸éœ€è¦ | ä½ | ä½ | ä¸€èˆ¬ |

ğŸŒŸ **æœªæ¥è¶‹åŠ¿ï¼šç»Ÿä¸€å¼•å¯¼ç†è®º**  
CFGçš„æˆåŠŸå¯å‘äº†è®¸å¤šåç»­å·¥ä½œã€‚æœªæ¥å¯èƒ½å‡ºç°ç»Ÿä¸€çš„å¼•å¯¼ç†è®ºï¼Œæ¶µç›–æ‰€æœ‰æ¡ä»¶ç”Ÿæˆæ–¹æ³•ï¼Œå¹¶æä¾›æœ€ä¼˜å¼•å¯¼ç­–ç•¥çš„ç†è®ºä¿è¯ã€‚

## 9.4 é«˜çº§å¼•å¯¼æŠ€æœ¯

### 9.4.1 å¤šæ¡ä»¶ç»„åˆ

ç°å®åº”ç”¨ä¸­å¸¸éœ€è¦åŒæ—¶æ»¡è¶³å¤šä¸ªæ¡ä»¶ã€‚å¤šæ¡ä»¶ç»„åˆçš„å…³é”®æ˜¯å¦‚ä½•å¹³è¡¡ä¸åŒæ¡ä»¶çš„å½±å“ã€‚

**1. çº¿æ€§ç»„åˆ**

æœ€ç®€å•çš„æ–¹æ³•æ˜¯çº¿æ€§åŠ æƒï¼š
```python
def multi_condition_cfg(x_t, t, conditions, weights):
    # æ— æ¡ä»¶é¢„æµ‹
    noise_uncond = model(x_t, t, null_token)
    
    # ç»„åˆå¤šä¸ªæ¡ä»¶
    combined_direction = 0
    for c, w in zip(conditions, weights):
        noise_c = model(x_t, t, c)
        combined_direction += w * (noise_c - noise_uncond)
    
    return noise_uncond + combined_direction
```

**2. å±‚æ¬¡åŒ–æ¡ä»¶**

ä¸åŒæ¡ä»¶åœ¨ä¸åŒå°ºåº¦èµ·ä½œç”¨ï¼š
```python
class HierarchicalConditioning:
    def __init__(self):
        self.global_conditions = []  # å½±å“æ•´ä½“
        self.local_conditions = []   # å½±å“ç»†èŠ‚
    
    def apply(self, x_t, t, T):
        if t > 0.5 * T:  # æ—©æœŸï¼šå…¨å±€æ¡ä»¶
            return apply_conditions(self.global_conditions)
        else:  # åæœŸï¼šå±€éƒ¨æ¡ä»¶
            return apply_conditions(self.local_conditions)
```

**3. æ¡ä»¶å›¾ç»“æ„**

ä½¿ç”¨å›¾å®šä¹‰æ¡ä»¶ä¹‹é—´çš„å…³ç³»ï¼š
```python
class ConditionalGraph:
    def __init__(self):
        self.nodes = {}  # æ¡ä»¶èŠ‚ç‚¹
        self.edges = {}  # æ¡ä»¶å…³ç³»
    
    def propagate(self, x_t, t):
        # æ ¹æ®å›¾ç»“æ„ä¼ æ’­æ¡ä»¶å½±å“
        for node in topological_sort(self.nodes):
            parents = self.get_parents(node)
            node.update(parents, x_t, t)
```

### 9.4.2 è´Ÿå‘æç¤ºæŠ€æœ¯

è´Ÿå‘æç¤ºï¼ˆNegative Promptingï¼‰æ˜¯é¿å…ç‰¹å®šå†…å®¹çš„å¼ºå¤§å·¥å…·ã€‚

**1. åŸºç¡€è´Ÿå‘æç¤º**
```python
def negative_prompting(x_t, t, pos_prompt, neg_prompt, w_pos=7.5, w_neg=3.0):
    noise_uncond = model(x_t, t, null_token)
    noise_pos = model(x_t, t, pos_prompt)
    noise_neg = model(x_t, t, neg_prompt)
    
    # æœæ­£å‘ç§»åŠ¨ï¼Œè¿œç¦»è´Ÿå‘
    direction = w_pos * (noise_pos - noise_uncond) - w_neg * (noise_neg - noise_uncond)
    return noise_uncond + direction
```

**2. å¤šè´Ÿå‘æç¤º**
```python
def multi_negative_prompting(x_t, t, pos, neg_list, w_pos, w_neg_list):
    noise_uncond = model(x_t, t, null_token)
    noise_pos = model(x_t, t, pos)
    
    # æ­£å‘
    direction = w_pos * (noise_pos - noise_uncond)
    
    # å¤šä¸ªè´Ÿå‘
    for neg, w_neg in zip(neg_list, w_neg_list):
        noise_neg = model(x_t, t, neg)
        direction -= w_neg * (noise_neg - noise_uncond)
    
    return noise_uncond + direction
```

**3. è‡ªé€‚åº”è´Ÿå‘å¼ºåº¦**
```python
def adaptive_negative(x_t, t, pos, neg):
    # è®¡ç®—æ­£è´Ÿå‘çš„ç›¸ä¼¼åº¦
    sim = cosine_similarity(encode(pos), encode(neg))
    
    # ç›¸ä¼¼åº¦é«˜æ—¶å¢å¼ºè´Ÿå‘å¼ºåº¦
    w_neg = base_w_neg * (1 + alpha * sim)
    
    return negative_prompting(x_t, t, pos, neg, w_pos, w_neg)
```

ğŸ’¡ **å®è·µæŠ€å·§ï¼šè´Ÿå‘æç¤ºçš„è‰ºæœ¯**  
å¥½çš„è´Ÿå‘æç¤ºåº”è¯¥å…·ä½“ä½†ä¸è¿‡äºé™åˆ¶ã€‚ä¾‹å¦‚ï¼Œ"ä½è´¨é‡"æ¯”"æ¨¡ç³Š"æ›´é€šç”¨ï¼Œ"è¿‡åº¦é¥±å’Œ"æ¯”"å¤ªäº®"æ›´ç²¾ç¡®ã€‚

### 9.4.3 åŠ¨æ€å¼•å¯¼å¼ºåº¦

å›ºå®šçš„å¼•å¯¼å¼ºåº¦å¯èƒ½ä¸æ˜¯æœ€ä¼˜çš„ã€‚åŠ¨æ€è°ƒæ•´å¯ä»¥è·å¾—æ›´å¥½çš„ç»“æœã€‚

**1. æ—¶é—´ç›¸å…³çš„å¼•å¯¼**
```python
def time_dependent_guidance(t, T):
    # ä½™å¼¦è°ƒåº¦
    progress = t / T
    w = w_min + (w_max - w_min) * (1 + np.cos(np.pi * progress)) / 2
    return w
```

**2. å†…å®¹ç›¸å…³çš„å¼•å¯¼**
```python
def content_aware_guidance(x_t, t, c):
    # åŸºäºå½“å‰ç”Ÿæˆå†…å®¹è°ƒæ•´
    content_features = extract_features(x_t)
    
    # æ£€æµ‹æ˜¯å¦éœ€è¦å¼ºå¼•å¯¼
    needs_strong_guidance = check_alignment(content_features, c)
    
    w = w_strong if needs_strong_guidance else w_normal
    return w
```

**3. ä¸ç¡®å®šæ€§ç›¸å…³çš„å¼•å¯¼**
```python
def uncertainty_based_guidance(model, x_t, t, c, n_samples=5):
    # å¤šæ¬¡é‡‡æ ·ä¼°è®¡ä¸ç¡®å®šæ€§
    predictions = []
    for _ in range(n_samples):
        noise = model(x_t + small_noise(), t, c)
        predictions.append(noise)
    
    # é«˜ä¸ç¡®å®šæ€§æ—¶å¢å¼ºå¼•å¯¼
    uncertainty = torch.stack(predictions).std(0).mean()
    w = w_base * (1 + beta * uncertainty)
    return w
```

### 9.4.4 ControlNetä¸é€‚é…å™¨æ–¹æ³•

ControlNetæä¾›äº†ç²¾ç¡®çš„ç©ºé—´æ§åˆ¶ï¼Œé€šè¿‡é¢å¤–çš„æ¡ä»¶è¾“å…¥ï¼ˆå¦‚è¾¹ç¼˜å›¾ã€æ·±åº¦å›¾ï¼‰å¼•å¯¼ç”Ÿæˆã€‚

**1. ControlNetåŸºç¡€æ¶æ„**
```python
class ControlNet(nn.Module):
    def __init__(self, base_model):
        super().__init__()
        # å¤åˆ¶åŸºç¡€æ¨¡å‹çš„ç¼–ç å™¨
        self.control_encoder = copy.deepcopy(base_model.encoder)
        # é›¶åˆå§‹åŒ–çš„æŠ•å½±å±‚
        self.zero_convs = nn.ModuleList([
            zero_module(nn.Conv2d(...)) for _ in range(n_layers)
        ])
    
    def forward(self, x, t, c, control):
        # å¤„ç†æ§åˆ¶ä¿¡å·
        control_feats = self.control_encoder(control, t)
        
        # æ³¨å…¥åˆ°åŸºç¡€æ¨¡å‹
        for i, feat in enumerate(control_feats):
            base_feats[i] += self.zero_convs[i](feat)
```

**2. å¤šæ§åˆ¶ç»„åˆ**
```python
def multi_control_generation(x_t, t, text, controls):
    # controls = {"depth": depth_map, "edge": edge_map, "pose": pose_map}
    
    # åŸºç¡€æ–‡æœ¬å¼•å¯¼
    noise_text = model(x_t, t, text)
    
    # æ·»åŠ å¤šä¸ªæ§åˆ¶
    noise_combined = noise_text
    for control_type, control_input in controls.items():
        control_noise = control_nets[control_type](x_t, t, text, control_input)
        noise_combined += control_weights[control_type] * control_noise
    
    return noise_combined
```

**3. é€‚é…å™¨æ–¹æ³•**

è½»é‡çº§çš„æ¡ä»¶æ³¨å…¥ï¼š
```python
class Adapter(nn.Module):
    def __init__(self, in_dim, hidden_dim, out_dim):
        super().__init__()
        self.down = nn.Linear(in_dim, hidden_dim)
        self.up = nn.Linear(hidden_dim, out_dim)
        self.act = nn.GELU()
        
        # é›¶åˆå§‹åŒ–
        nn.init.zeros_(self.up.weight)
        nn.init.zeros_(self.up.bias)
    
    def forward(self, x, condition):
        # ä¸‹æŠ•å½±
        h = self.down(condition)
        h = self.act(h)
        # ä¸ŠæŠ•å½±
        h = self.up(h)
        # æ®‹å·®è¿æ¥
        return x + h
```

<details>
<summary>**ç»ƒä¹  9.4ï¼šè®¾è®¡å¤æ‚çš„å¼•å¯¼ç³»ç»Ÿ**</summary>

æ„å»ºä¸€ä¸ªæ”¯æŒå¤šç§é«˜çº§å¼•å¯¼æŠ€æœ¯çš„ç³»ç»Ÿã€‚

1. **ç»„åˆå¼•å¯¼å™¨**ï¼š
   - å®ç°æ”¯æŒæ–‡æœ¬ã€å›¾åƒã€å¸ƒå±€çš„å¤šæ¨¡æ€å¼•å¯¼
   - è®¾è®¡æ¡ä»¶ä¼˜å…ˆçº§ç³»ç»Ÿ
   - å¤„ç†æ¡ä»¶å†²çª

2. **åŠ¨æ€è°ƒåº¦å™¨**ï¼š
   - å®ç°åŸºäºç”Ÿæˆè¿›åº¦çš„å¼•å¯¼è°ƒåº¦
   - æ ¹æ®ç”Ÿæˆè´¨é‡è‡ªé€‚åº”è°ƒæ•´
   - è®¾è®¡æ—©åœæœºåˆ¶

3. **æ§åˆ¶ç½‘ç»œé›†æˆ**ï¼š
   - å®ç°ç®€åŒ–ç‰ˆControlNet
   - æ”¯æŒè¾¹ç¼˜ã€æ·±åº¦ã€åˆ†å‰²å›¾æ§åˆ¶
   - è®¾è®¡æ§åˆ¶å¼ºåº¦çš„è‡ªåŠ¨è°ƒæ•´

4. **è¯„ä¼°ç³»ç»Ÿ**ï¼š
   - è®¾è®¡æ¡ä»¶ä¸€è‡´æ€§åº¦é‡
   - å®ç°å¤šæ ·æ€§è¯„ä¼°
   - æ„å»ºè‡ªåŠ¨åŒ–æµ‹è¯•æ¡†æ¶

</details>

### 9.4.5 å¼•å¯¼æŠ€æœ¯çš„ç»„åˆç­–ç•¥

**1. çº§è”å¼•å¯¼**
```python
def cascade_guidance(x_t, t, conditions):
    # é€æ­¥ç»†åŒ–
    x = x_t
    for i, (condition, strength) in enumerate(conditions):
        x = apply_guidance(x, t, condition, strength)
        # å¯é€‰ï¼šä¸­é—´å»å™ªæ­¥éª¤
        if i < len(conditions) - 1:
            x = denoise_step(x, t)
    return x
```

**2. æ³¨æ„åŠ›å¼•å¯¼çš„å¼•å¯¼**
```python
def attention_guided_cfg(x_t, t, c, attention_maps):
    # ä½¿ç”¨æ³¨æ„åŠ›å›¾è°ƒåˆ¶å¼•å¯¼å¼ºåº¦
    noise_c = model(x_t, t, c)
    noise_u = model(x_t, t, null_token)
    
    # ç©ºé—´å˜åŒ–çš„å¼•å¯¼æƒé‡
    w_spatial = compute_spatial_weights(attention_maps)
    
    return noise_u + w_spatial * (noise_c - noise_u)
```

**3. å…ƒå¼•å¯¼**
```python
class MetaGuidance:
    def __init__(self):
        self.guidance_predictor = nn.Module()  # é¢„æµ‹æœ€ä¼˜å¼•å¯¼ç­–ç•¥
    
    def apply(self, x_t, t, context):
        # é¢„æµ‹å½“å‰æœ€ä¼˜å¼•å¯¼å‚æ•°
        guidance_params = self.guidance_predictor(x_t, t, context)
        
        # åº”ç”¨é¢„æµ‹çš„å¼•å¯¼
        return apply_guidance_with_params(x_t, t, guidance_params)
```

ğŸ”¬ **ç ”ç©¶å‰æ²¿ï¼šå¯å­¦ä¹ çš„å¼•å¯¼**  
èƒ½å¦è®­ç»ƒä¸€ä¸ªç½‘ç»œæ¥å­¦ä¹ æœ€ä¼˜çš„å¼•å¯¼ç­–ç•¥ï¼Ÿè¿™å¯èƒ½éœ€è¦å…ƒå­¦ä¹ æˆ–å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚

### 9.4.6 å®é™…åº”ç”¨ä¸­çš„æƒè¡¡

**è´¨é‡ vs å¤šæ ·æ€§**ï¼š
- å¼ºå¼•å¯¼æé«˜è´¨é‡ä½†é™ä½å¤šæ ·æ€§
- éœ€è¦æ ¹æ®åº”ç”¨åœºæ™¯å¹³è¡¡

**è®¡ç®—æˆæœ¬**ï¼š
- å¤šæ¡ä»¶ç»„åˆå¢åŠ æ¨ç†æ—¶é—´
- ControlNetéœ€è¦é¢å¤–å†…å­˜
- éœ€è¦è€ƒè™‘éƒ¨ç½²é™åˆ¶

**ç”¨æˆ·ä½“éªŒ**ï¼š
- è¿‡å¤šçš„æ§åˆ¶é€‰é¡¹å¯èƒ½å›°æ‰°ç”¨æˆ·
- éœ€è¦åˆç†çš„é»˜è®¤å€¼
- æä¾›é¢„è®¾æ¨¡æ¿

ğŸŒŸ **æœ€ä½³å®è·µï¼šæ¸è¿›å¼å¤æ‚åº¦**  
ä¸ºç”¨æˆ·æä¾›åˆ†å±‚çš„æ§åˆ¶ï¼šåŸºç¡€ç”¨æˆ·ä½¿ç”¨ç®€å•æ–‡æœ¬ï¼Œé«˜çº§ç”¨æˆ·å¯ä»¥è®¿é—®æ‰€æœ‰æ§åˆ¶é€‰é¡¹ã€‚

## 9.5 è¯„ä¼°ä¸ä¼˜åŒ–

### 9.5.1 æ¡ä»¶ä¸€è‡´æ€§åº¦é‡

è¯„ä¼°ç”Ÿæˆå†…å®¹ä¸æ¡ä»¶çš„åŒ¹é…ç¨‹åº¦æ˜¯å…³é”®æŒ‘æˆ˜ã€‚

**1. åˆ†ç±»å‡†ç¡®ç‡**

å¯¹äºç±»åˆ«æ¡ä»¶ï¼š
```python
def classification_accuracy(generated_images, target_classes, classifier):
    predictions = classifier(generated_images)
    accuracy = (predictions.argmax(1) == target_classes).float().mean()
    return accuracy
```

**2. CLIP Score**

å¯¹äºæ–‡æœ¬æ¡ä»¶ï¼š
```python
def clip_score(images, texts, clip_model):
    # ç¼–ç å›¾åƒå’Œæ–‡æœ¬
    image_features = clip_model.encode_image(images)
    text_features = clip_model.encode_text(texts)
    
    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    similarity = F.cosine_similarity(image_features, text_features)
    return similarity.mean()
```

**3. ç»“æ„ç›¸ä¼¼åº¦**

å¯¹äºç©ºé—´æ§åˆ¶ï¼ˆå¦‚ControlNetï¼‰ï¼š
```python
def structural_similarity(generated, control_signal):
    # æå–ç»“æ„ç‰¹å¾
    gen_edges = edge_detector(generated)
    
    # è®¡ç®—ç›¸ä¼¼åº¦
    ssim = structural_similarity_index(gen_edges, control_signal)
    return ssim
```

**4. è¯­ä¹‰ä¸€è‡´æ€§**

ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¯„ä¼°è¯­ä¹‰å¯¹é½ï¼š
```python
def semantic_consistency(images, conditions, semantic_model):
    # æå–è¯­ä¹‰ç‰¹å¾
    image_semantics = semantic_model.extract_semantics(images)
    condition_semantics = semantic_model.encode_conditions(conditions)
    
    # è®¡ç®—è¯­ä¹‰è·ç¦»
    distance = semantic_distance(image_semantics, condition_semantics)
    return 1 / (1 + distance)  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
```

### 9.5.2 å¤šæ ·æ€§ä¸è´¨é‡æƒè¡¡

**1. å¤šæ ·æ€§åº¦é‡**

```python
def diversity_metrics(generated_samples):
    metrics = {}
    
    # ç‰¹å¾ç©ºé—´å¤šæ ·æ€§
    features = extract_features(generated_samples)
    metrics['feature_diversity'] = compute_variance(features)
    
    # æˆå¯¹è·ç¦»
    pairwise_dist = pdist(features)
    metrics['avg_distance'] = pairwise_dist.mean()
    
    # è¦†ç›–åº¦
    metrics['coverage'] = compute_coverage(features, reference_features)
    
    return metrics
```

**2. è´¨é‡-å¤šæ ·æ€§å‰æ²¿**

```python
def quality_diversity_frontier(model, conditions, guidance_weights):
    results = []
    
    for w in guidance_weights:
        # ç”Ÿæˆæ ·æœ¬
        samples = generate_with_guidance(model, conditions, w)
        
        # è¯„ä¼°
        quality = compute_quality(samples)
        diversity = compute_diversity(samples)
        
        results.append({
            'guidance_weight': w,
            'quality': quality,
            'diversity': diversity
        })
    
    return results
```

**3. è‡ªåŠ¨æƒè¡¡é€‰æ‹©**

```python
def auto_select_guidance(target_quality, target_diversity):
    # åŸºäºå†å²æ•°æ®æ‹Ÿåˆå…³ç³»
    quality_fn = fit_quality_curve(historical_data)
    diversity_fn = fit_diversity_curve(historical_data)
    
    # ä¼˜åŒ–ç›®æ ‡
    def objective(w):
        q = quality_fn(w)
        d = diversity_fn(w)
        return abs(q - target_quality) + abs(d - target_diversity)
    
    optimal_w = minimize(objective, x0=7.5)
    return optimal_w
```

### 9.5.3 å¼•å¯¼å¤±æ•ˆçš„è¯Šæ–­

**1. å¸¸è§å¤±æ•ˆæ¨¡å¼**

```python
class GuidanceFailureDetector:
    def __init__(self):
        self.failure_patterns = {
            'over_guidance': self.detect_over_guidance,
            'under_guidance': self.detect_under_guidance,
            'mode_collapse': self.detect_mode_collapse,
            'semantic_drift': self.detect_semantic_drift
        }
    
    def diagnose(self, samples, conditions):
        issues = []
        for name, detector in self.failure_patterns.items():
            if detector(samples, conditions):
                issues.append(name)
        return issues
```

**2. è¿‡åº¦å¼•å¯¼æ£€æµ‹**

```python
def detect_over_guidance(samples):
    # æ£€æŸ¥é¥±å’Œåº¦
    saturation = compute_saturation(samples)
    if saturation > threshold_high:
        return True
    
    # æ£€æŸ¥å¤šæ ·æ€§
    diversity = compute_diversity(samples)
    if diversity < threshold_low:
        return True
    
    return False
```

**3. è¯­ä¹‰æ¼‚ç§»æ£€æµ‹**

```python
def detect_semantic_drift(samples, conditions, steps=10):
    # è¿½è¸ªç”Ÿæˆè¿‡ç¨‹ä¸­çš„è¯­ä¹‰å˜åŒ–
    semantic_trajectory = []
    
    for step in range(steps):
        intermediate = get_intermediate_result(step)
        semantics = extract_semantics(intermediate)
        semantic_trajectory.append(semantics)
    
    # æ£€æµ‹å¼‚å¸¸æ¼‚ç§»
    drift = compute_trajectory_drift(semantic_trajectory)
    return drift > drift_threshold
```

ğŸ’¡ **è°ƒè¯•æŠ€å·§ï¼šå¯è§†åŒ–ä¸­é—´ç»“æœ**  
ä¿å­˜å¹¶å¯è§†åŒ–ä¸åŒæ—¶é—´æ­¥çš„ä¸­é—´ç»“æœï¼Œå¯ä»¥å¸®åŠ©è¯†åˆ«å¼•å¯¼åœ¨å“ªä¸ªé˜¶æ®µå¤±æ•ˆã€‚

### 9.5.4 å®é™…åº”ç”¨æ¡ˆä¾‹

**1. æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ**

```python
class Text2ImagePipeline:
    def __init__(self, model, cfg_scale=7.5):
        self.model = model
        self.cfg_scale = cfg_scale
        self.negative_prompts = [
            "low quality", "blurry", "distorted"
        ]
    
    def generate(self, prompt, **kwargs):
        # ç¼–ç æ–‡æœ¬
        text_emb = self.encode_text(prompt)
        neg_emb = self.encode_text(self.negative_prompts)
        
        # CFGé‡‡æ ·
        image = self.sample_with_cfg(
            text_emb, neg_emb, 
            self.cfg_scale, **kwargs
        )
        
        return image
```

**2. å›¾åƒç¼–è¾‘**

```python
class ImageEditingPipeline:
    def __init__(self, model, controlnet):
        self.model = model
        self.controlnet = controlnet
    
    def edit(self, image, edit_instruction, mask=None):
        # æå–æ§åˆ¶ä¿¡å·
        control = self.extract_control(image)
        
        # ç¼–ç ç¼–è¾‘æŒ‡ä»¤
        instruction_emb = self.encode_instruction(edit_instruction)
        
        # æ¡ä»¶ç”Ÿæˆ
        if mask is not None:
            # å±€éƒ¨ç¼–è¾‘
            edited = self.local_edit(image, mask, instruction_emb, control)
        else:
            # å…¨å±€ç¼–è¾‘
            edited = self.global_edit(image, instruction_emb, control)
        
        return edited
```

**3. å¤šæ¨¡æ€ç”Ÿæˆ**

```python
class MultiModalGenerator:
    def __init__(self, models):
        self.models = models
        self.fusion_module = CrossModalFusion()
    
    def generate(self, conditions):
        # conditions = {"text": ..., "audio": ..., "sketch": ...}
        
        # ç¼–ç å„æ¨¡æ€
        embeddings = {}
        for modality, condition in conditions.items():
            embeddings[modality] = self.models[modality].encode(condition)
        
        # è·¨æ¨¡æ€èåˆ
        fused_condition = self.fusion_module(embeddings)
        
        # ç”Ÿæˆ
        output = self.sample_with_fusion(fused_condition)
        return output
```

<details>
<summary>**ç»¼åˆç»ƒä¹ ï¼šæ„å»ºç”Ÿäº§çº§æ¡ä»¶ç”Ÿæˆç³»ç»Ÿ**</summary>

è®¾è®¡å¹¶å®ç°ä¸€ä¸ªå®Œæ•´çš„æ¡ä»¶ç”Ÿæˆç³»ç»Ÿã€‚

1. **ç³»ç»Ÿæ¶æ„**ï¼š
   - æ¨¡å—åŒ–è®¾è®¡ï¼Œæ”¯æŒæ’ä»¶å¼æ‰©å±•
   - ç»Ÿä¸€çš„APIæ¥å£
   - é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶

2. **åŠŸèƒ½å®ç°**ï¼š
   - æ”¯æŒå¤šç§æ¡ä»¶ç±»å‹
   - è‡ªåŠ¨å‚æ•°ä¼˜åŒ–
   - æ‰¹å¤„ç†å’Œæµå¼å¤„ç†

3. **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - æ¨¡å‹é‡åŒ–å’Œå‰ªæ
   - ç¼“å­˜æœºåˆ¶
   - å¹¶è¡ŒåŒ–ç­–ç•¥

4. **ç›‘æ§ä¸è¯„ä¼°**ï¼š
   - å®æ—¶è´¨é‡ç›‘æ§
   - A/Bæµ‹è¯•æ¡†æ¶
   - ç”¨æˆ·åé¦ˆé›†æˆ

5. **éƒ¨ç½²è€ƒè™‘**ï¼š
   - å®¹å™¨åŒ–éƒ¨ç½²
   - è´Ÿè½½å‡è¡¡
   - ç‰ˆæœ¬ç®¡ç†

</details>

### 9.5.5 ä¼˜åŒ–ç­–ç•¥æ€»ç»“

**è®­ç»ƒé˜¶æ®µä¼˜åŒ–**ï¼š
1. åˆç†çš„æ¡ä»¶dropoutç‡ï¼ˆé€šå¸¸0.1ï¼‰
2. å¤šä»»åŠ¡å­¦ä¹ å¹³è¡¡
3. æ•°æ®å¢å¼ºç­–ç•¥
4. è¯¾ç¨‹å­¦ä¹ ï¼ˆä»ç®€å•åˆ°å¤æ‚ï¼‰

**æ¨ç†é˜¶æ®µä¼˜åŒ–**ï¼š
1. å¼•å¯¼æƒé‡çš„è‡ªé€‚åº”è°ƒæ•´
2. æå‰åœæ­¢ç­–ç•¥
3. æ‰¹å¤„ç†ä¼˜åŒ–
4. ç»“æœç¼“å­˜

**ç³»ç»Ÿçº§ä¼˜åŒ–**ï¼š
1. æ¨¡å‹è’¸é¦
2. é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ
3. ç¡¬ä»¶åŠ é€Ÿï¼ˆGPU/TPUä¼˜åŒ–ï¼‰
4. åˆ†å¸ƒå¼æ¨ç†

### 9.5.6 æœªæ¥å‘å±•æ–¹å‘

**1. è‡ªé€‚åº”å¼•å¯¼**
- åŸºäºå†…å®¹çš„åŠ¨æ€è°ƒæ•´
- å­¦ä¹ å‹å¼•å¯¼ç­–ç•¥
- ç”¨æˆ·åå¥½å»ºæ¨¡

**2. ç»Ÿä¸€æ¡†æ¶**
- å¤šç§å¼•å¯¼æ–¹æ³•çš„ç»Ÿä¸€ç†è®º
- å¯ç»„åˆçš„å¼•å¯¼æ¨¡å—
- æ ‡å‡†åŒ–è¯„ä¼°ä½“ç³»

**3. æ•ˆç‡æå‡**
- ä¸€æ¬¡å‰å‘ä¼ æ’­çš„å¼•å¯¼
- è½»é‡çº§å¼•å¯¼ç½‘ç»œ
- è¾¹ç¼˜è®¾å¤‡éƒ¨ç½²

ğŸŒŸ **å±•æœ›ï¼šæ™ºèƒ½å¼•å¯¼ç³»ç»Ÿ**  
æœªæ¥çš„æ¡ä»¶ç”Ÿæˆç³»ç»Ÿå°†æ›´åŠ æ™ºèƒ½ï¼Œèƒ½å¤Ÿç†è§£ç”¨æˆ·æ„å›¾ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜å¼•å¯¼ç­–ç•¥ï¼Œå¹¶åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­åŠ¨æ€è°ƒæ•´ï¼Œå®ç°çœŸæ­£çš„"æ‰€æƒ³å³æ‰€å¾—"ã€‚

## æœ¬ç« å°ç»“

æœ¬ç« æ·±å…¥æ¢è®¨äº†æ‰©æ•£æ¨¡å‹çš„æ¡ä»¶ç”Ÿæˆä¸å¼•å¯¼æŠ€æœ¯ï¼Œä»åŸºç¡€çš„æ¡ä»¶ä¿¡æ¯æ³¨å…¥åˆ°é«˜çº§çš„ControlNetæ–¹æ³•ã€‚æˆ‘ä»¬å­¦ä¹ äº†ï¼š

- **æ¡ä»¶æ‰©æ•£æ¨¡å‹çš„åŸºç¡€**ï¼šå„ç§æ¡ä»¶æ³¨å…¥æ–¹å¼å’Œæ¶æ„è®¾è®¡
- **åˆ†ç±»å™¨å¼•å¯¼**ï¼šä½¿ç”¨å¤–éƒ¨åˆ†ç±»å™¨æ¢¯åº¦çš„ç»å…¸æ–¹æ³•
- **æ— åˆ†ç±»å™¨å¼•å¯¼**ï¼šç®€æ´é«˜æ•ˆçš„CFGæŠ€æœ¯
- **é«˜çº§å¼•å¯¼æŠ€æœ¯**ï¼šå¤šæ¡ä»¶ç»„åˆã€è´Ÿå‘æç¤ºã€åŠ¨æ€å¼•å¯¼ç­‰
- **è¯„ä¼°ä¸ä¼˜åŒ–**ï¼šå…¨é¢çš„è¯„ä¼°ä½“ç³»å’Œä¼˜åŒ–ç­–ç•¥

è¿™äº›æŠ€æœ¯ä½¿æ‰©æ•£æ¨¡å‹ä»éšæœºç”Ÿæˆå·¥å…·è½¬å˜ä¸ºç²¾ç¡®å¯æ§çš„åˆ›ä½œç³»ç»Ÿã€‚ä¸‹ä¸€ç« ï¼Œæˆ‘ä»¬å°†æ¢è®¨æ½œåœ¨æ‰©æ•£æ¨¡å‹ï¼Œå­¦ä¹ å¦‚ä½•åœ¨å‹ç¼©çš„æ½œåœ¨ç©ºé—´ä¸­é«˜æ•ˆåœ°è¿›è¡Œæ‰©æ•£å»ºæ¨¡ã€‚

[â† è¿”å›ç›®å½•](index.md) | ç¬¬9ç«  / å…±14ç«  | [ä¸‹ä¸€ç«  â†’](chapter10.md)