<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç¬¬3ç« ï¼šå»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ (DDPM) - Diffusion Models Tutorial</title>
    <link rel="stylesheet" href="common.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js" onload="renderMathInElement(document.body);"></script>
    <script src="common.js"></script>
</head>
<body>
    <div class="container">
        <div class="nav-bar">
            <a href="chapter2.html">â† ä¸Šä¸€ç« </a>
            <span>ç¬¬3ç«  / å…±14ç« </span>
            <a href="chapter4.html">ä¸‹ä¸€ç«  â†’</a>
        </div>
        
        <h1>ç¬¬3ç« ï¼šå»å™ªæ‰©æ•£æ¦‚ç‡æ¨¡å‹ (DDPM)</h1>
        
        <div class="chapter-intro">
            2020å¹´ï¼ŒHoç­‰äººçš„è®ºæ–‡"Denoising Diffusion Probabilistic Models"è®©æ‰©æ•£æ¨¡å‹çœŸæ­£è¿›å…¥äº†å®ç”¨é˜¶æ®µã€‚DDPMä¸ä»…ç®€åŒ–äº†è®­ç»ƒè¿‡ç¨‹ï¼Œè¿˜è¾¾åˆ°äº†ä¸GANç›¸åª²ç¾çš„ç”Ÿæˆè´¨é‡ã€‚æœ¬ç« å°†æ·±å…¥å‰–æDDPMçš„æ•°å­¦åŸç†ã€è®­ç»ƒç®—æ³•å’Œå®ç°ç»†èŠ‚ã€‚é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œä½ å°†æŒæ¡å¦‚ä½•ä»é›¶å®ç°ä¸€ä¸ªå®Œæ•´çš„DDPMï¼Œå¹¶ç†è§£å…¶èƒŒåçš„æ¦‚ç‡è®ºåŸºç¡€ã€‚
        </div>
        
        <h2>3.1 DDPMçš„æ ¸å¿ƒæ€æƒ³ï¼šç®€åŒ–ä¸ç»Ÿä¸€</h2>
        
        <p>åœ¨DDPMä¹‹å‰ï¼Œæ‰©æ•£æ¨¡å‹è™½ç„¶ç†è®ºä¼˜é›…ï¼Œä½†å®è·µå›°éš¾ã€‚2015å¹´Sohl-Dicksteinç­‰äººçš„å¼€åˆ›æ€§å·¥ä½œéœ€è¦ä¼°è®¡æ•´ä¸ªåå‘è¿‡ç¨‹çš„ç†µï¼Œè®­ç»ƒæå…¶å¤æ‚ã€‚DDPMçš„é©å‘½æ€§è´¡çŒ®åœ¨äºï¼š<strong>å°†å¤æ‚çš„å˜åˆ†æ¨æ–­ç®€åŒ–ä¸ºç®€å•çš„å»å™ªä»»åŠ¡</strong>ã€‚</p>
        
        <div class="definition">
            <div class="definition-title">DDPMçš„ä¸‰ä¸ªå…³é”®ç®€åŒ–</div>
            <ol>
                <li><strong>å›ºå®šæ–¹å·®è°ƒåº¦</strong>ï¼šå‰å‘è¿‡ç¨‹ä½¿ç”¨é¢„å®šä¹‰çš„ $\beta_t$ åºåˆ—ï¼Œæ— éœ€å­¦ä¹ </li>
                <li><strong>ç®€åŒ–åå‘è¿‡ç¨‹</strong>ï¼šå‡è®¾åå‘è¿‡ç¨‹ä¹Ÿæ˜¯é«˜æ–¯åˆ†å¸ƒï¼Œåªéœ€å­¦ä¹ å‡å€¼ï¼ˆå®é™…ä¸Šæ˜¯å­¦ä¹ å™ªå£°ï¼‰</li>
                <li><strong>é‡å‚æ•°åŒ–ç›®æ ‡</strong>ï¼šå°†é¢„æµ‹å‡å€¼è½¬æ¢ä¸ºé¢„æµ‹å™ªå£°ï¼Œå¤§å¹…æå‡è®­ç»ƒç¨³å®šæ€§</li>
            </ol>
        </div>
        
        <h3>3.1.1 ä»å¤æ‚åˆ°ç®€å•ï¼šDDPMçš„æ´å¯Ÿ</h3>
        
        <p>è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç±»æ¯”æ¥ç†è§£DDPMçš„æ ¸å¿ƒæ€æƒ³ï¼š</p>
        
        <div class="visualization" style="background-color: #f8f9fa; padding: 20px; margin: 20px 0; border-radius: 8px;">
            <h4>å¢¨æ°´æ‰©æ•£çš„ç±»æ¯”</h4>
            <p>æƒ³è±¡ä¸€æ»´å¢¨æ°´åœ¨æ°´ä¸­æ‰©æ•£ï¼š</p>
            <ul>
                <li><strong>å‰å‘è¿‡ç¨‹</strong>ï¼šå¢¨æ°´é€æ¸æ‰©æ•£ï¼Œæœ€ç»ˆå‡åŒ€åˆ†å¸ƒï¼ˆç‰©ç†è¿‡ç¨‹ï¼Œç¡®å®šçš„ï¼‰</li>
                <li><strong>åå‘è¿‡ç¨‹</strong>ï¼šå¦‚ä½•è®©æ‰©æ•£çš„å¢¨æ°´é‡æ–°èšé›†ï¼Ÿï¼ˆéœ€è¦å­¦ä¹ çš„ï¼‰</li>
            </ul>
            <p>DDPMçš„å…³é”®æ´å¯Ÿï¼š<strong>åœ¨æ¯ä¸ªæ—¶é—´æ­¥ï¼Œæˆ‘ä»¬åªéœ€è¦çŸ¥é“"å¢¨æ°´åº”è¯¥å‘å“ªä¸ªæ–¹å‘èšé›†"</strong>ï¼Œè€Œè¿™ä¸ªæ–¹å‘æ°å¥½ä¸æ·»åŠ çš„å™ªå£°æ–¹å‘ç›¸åï¼</p>
        </div>
        
        <h3>3.1.2 æ•°å­¦æ¡†æ¶æ¦‚è§ˆ</h3>
        
        <p>DDPMå®šä¹‰äº†ä¸¤ä¸ªè¿‡ç¨‹ï¼š</p>
        
        <div class="math-block">
            <strong>å‰å‘è¿‡ç¨‹ï¼ˆå›ºå®šï¼‰</strong>ï¼š<br>
            $q(\mathbf{x}_t | \mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1-\beta_t}\mathbf{x}_{t-1}, \beta_t\mathbf{I})$<br><br>
            
            <strong>åå‘è¿‡ç¨‹ï¼ˆå­¦ä¹ ï¼‰</strong>ï¼š<br>
            $p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t) = \mathcal{N}(\mathbf{x}_{t-1}; \boldsymbol{\mu}_\theta(\mathbf{x}_t, t), \sigma_t^2\mathbf{I})$
        </div>
        
        <p>å…³é”®åˆ›æ–°åœ¨äºå¦‚ä½•å‚æ•°åŒ– $\boldsymbol{\mu}_\theta$ï¼š</p>
        
        <div class="code-block">
<pre># æ—©æœŸæ–¹æ³•ï¼šç›´æ¥é¢„æµ‹å‡å€¼ï¼ˆä¸ç¨³å®šï¼‰
mean = model(x_t, t)

# DDPMåˆ›æ–°ï¼šé¢„æµ‹å™ªå£°ï¼ˆç¨³å®šä¸”æœ‰æ•ˆï¼‰
noise_pred = model(x_t, t)
mean = (x_t - beta_t / sqrt(1 - alpha_bar_t) * noise_pred) / sqrt(alpha_t)</pre>
        </div>
        
        <h3>3.1.3 ä¸ºä»€ä¹ˆé¢„æµ‹å™ªå£°æ›´å¥½ï¼Ÿ</h3>
        
        <p>è¿™ä¸ªçœ‹ä¼¼ç®€å•çš„æ”¹å˜å¸¦æ¥äº†å·¨å¤§çš„å¥½å¤„ï¼š</p>
        
        <div class="definition">
            <div class="definition-title">é¢„æµ‹å™ªå£°çš„ä¼˜åŠ¿</div>
            <table style="width: 100%; margin-top: 10px;">
                <tr>
                    <th style="padding: 10px; background-color: #f0f0f0;">æ–¹é¢</th>
                    <th style="padding: 10px; background-color: #f0f0f0;">é¢„æµ‹å‡å€¼</th>
                    <th style="padding: 10px; background-color: #f0f0f0;">é¢„æµ‹å™ªå£°</th>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">è¾“å‡ºèŒƒå›´</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">éœ€è¦åŒ¹é…æ•°æ®åˆ†å¸ƒ</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">æ ‡å‡†é«˜æ–¯ï¼ˆå·²å½’ä¸€åŒ–ï¼‰</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">è®­ç»ƒä¿¡å·</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">éštå˜åŒ–å‰§çƒˆ</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">å„æ—¶é—´æ­¥ç›¸å¯¹ä¸€è‡´</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">æ¢¯åº¦æµ</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">å¯èƒ½æ¢¯åº¦æ¶ˆå¤±</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">æ¢¯åº¦ä¼ æ’­è‰¯å¥½</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">ç‰©ç†æ„ä¹‰</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">é¢„æµ‹å»å™ªåçš„å›¾åƒ</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">é¢„æµ‹æ·»åŠ çš„å™ªå£°</td>
                </tr>
            </table>
        </div>
        
        <h3>3.1.4 DDPM vs æ—©æœŸæ‰©æ•£æ¨¡å‹</h3>
        
        <p>è®©æˆ‘ä»¬å¯¹æ¯”DDPMä¸2015å¹´çš„åŸå§‹æ‰©æ•£æ¨¡å‹ï¼š</p>
        
        <div class="code-block">
<pre># 2015å¹´çš„æ‰©æ•£æ¨¡å‹ï¼ˆå¤æ‚ï¼‰
# éœ€è¦ä¼°è®¡ï¼š
# 1. å‰å‘è¿‡ç¨‹çš„ç†µ
# 2. åå‘è¿‡ç¨‹çš„å®Œæ•´åˆ†å¸ƒ
# 3. å˜åˆ†å‚æ•°çš„ä¼˜åŒ–
# è®­ç»ƒæå…¶ä¸ç¨³å®šï¼Œç”Ÿæˆè´¨é‡å·®

# DDPMï¼ˆ2020å¹´ï¼‰çš„è®­ç»ƒï¼ˆæç®€ï¼‰
for x_0, _ in dataloader:
    t = torch.randint(0, num_timesteps, (batch_size,))
    noise = torch.randn_like(x_0)
    x_t = sqrt_alpha_bar[t] * x_0 + sqrt_one_minus_alpha_bar[t] * noise
    
    noise_pred = model(x_t, t)
    loss = F.mse_loss(noise_pred, noise)
    loss.backward()</pre>
        </div>
        
        <p>è¿™ç§ç®€åŒ–ä¸æ˜¯ä»¥ç‰ºç‰²æ€§èƒ½ä¸ºä»£ä»·çš„â€”â€”ç›¸åï¼ŒDDPMé¦–æ¬¡è®©æ‰©æ•£æ¨¡å‹åœ¨ç”Ÿæˆè´¨é‡ä¸Šä¸GANç«äº‰ï¼ŒåŒæ—¶ä¿æŒäº†è®­ç»ƒçš„ç¨³å®šæ€§ã€‚</p>
        
        <div class="exercise">
            <div class="exercise-title">æ€è€ƒé¢˜ 3.1ï¼šç›´è§‰ç†è§£</div>
            <p>ä¸ºä»€ä¹ˆåœ¨é«˜å™ªå£°æƒ…å†µä¸‹ï¼ˆå¤§çš„tï¼‰ï¼Œé¢„æµ‹å™ªå£°æ¯”é¢„æµ‹åŸå§‹å›¾åƒæ›´å®¹æ˜“ï¼Ÿæç¤ºï¼šè€ƒè™‘ä¿¡å™ªæ¯”ã€‚</p>
            <button class="answer-toggle" onclick="toggleAnswer('answer3_1')">æ˜¾ç¤ºç­”æ¡ˆ</button>
            <div id="answer3_1" class="answer">
                <p><strong>ç­”æ¡ˆï¼š</strong></p>
                <p>å½“tå¾ˆå¤§æ—¶ï¼Œ$\mathbf{x}_t \approx \mathcal{N}(0, \mathbf{I})$ï¼Œå‡ ä¹æ˜¯çº¯å™ªå£°ã€‚æ­¤æ—¶ï¼š</p>
                <ul>
                    <li>åŸå§‹å›¾åƒ $\mathbf{x}_0$ çš„ä¿¡æ¯å‡ ä¹å®Œå…¨ä¸¢å¤±ï¼Œé¢„æµ‹å®ƒéœ€è¦"å‡­ç©ºæƒ³è±¡"</li>
                    <li>ä½†æ·»åŠ çš„å™ªå£° $\boldsymbol{\epsilon}$ æ˜¯å·²çŸ¥çš„ï¼Œä¸”å ä¸»å¯¼åœ°ä½</li>
                    <li>ç½‘ç»œåªéœ€è¦è¯†åˆ«å™ªå£°æ¨¡å¼ï¼Œè€Œä¸æ˜¯é‡å»ºå¤æ‚çš„å›¾åƒç»“æ„</li>
                </ul>
                <p>ç±»æ¯”ï¼šåœ¨é›ªèŠ±å™ªå£°çš„ç”µè§†å±å¹•ä¸Šï¼Œè¯†åˆ«å™ªå£°æ¨¡å¼æ¯”é‡å»ºåŸå§‹èŠ‚ç›®å®¹æ˜“å¾—å¤šã€‚</p>
            </div>
        </div>
        
        <h2>3.2 å‰å‘è¿‡ç¨‹ï¼šæ•°å­¦æ¨å¯¼ä¸æ€§è´¨</h2>
        
        <p>å‰å‘è¿‡ç¨‹æ˜¯æ‰©æ•£æ¨¡å‹çš„åŸºç¡€ï¼Œå®ƒå®šä¹‰äº†å¦‚ä½•å°†æ•°æ®é€æ­¥è½¬æ¢ä¸ºå™ªå£°ã€‚è™½ç„¶è¿™ä¸ªè¿‡ç¨‹åœ¨è®­ç»ƒå’Œæ¨ç†æ—¶éƒ½ä¸éœ€è¦å®é™…æ‰§è¡Œå®Œæ•´çš„é©¬å°”å¯å¤«é“¾ï¼Œä½†ç†è§£å…¶æ•°å­¦æ€§è´¨å¯¹æŒæ¡DDPMè‡³å…³é‡è¦ã€‚</p>
        
        <h3>3.2.1 é©¬å°”å¯å¤«é“¾çš„æ„å»º</h3>
        
        <p>å‰å‘è¿‡ç¨‹å®šä¹‰ä¸ºä¸€ä¸ªé©¬å°”å¯å¤«é“¾ï¼š</p>
        
        <div class="math-block">
            $$\mathbf{x}_0 \to \mathbf{x}_1 \to \mathbf{x}_2 \to \cdots \to \mathbf{x}_T$$
        </div>
        
        <p>å…¶ä¸­æ¯ä¸€æ­¥çš„è½¬ç§»æ¦‚ç‡ä¸ºï¼š</p>
        
        <div class="math-block">
            $$q(\mathbf{x}_t|\mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{1-\beta_t}\mathbf{x}_{t-1}, \beta_t\mathbf{I})$$
        </div>
        
        <div class="definition">
            <div class="definition-title">å…³é”®æ€§è´¨1ï¼šæ–¹å·®è°ƒåº¦çš„çº¦æŸ</div>
            <p>ä¸ºä»€ä¹ˆæ˜¯ $\sqrt{1-\beta_t}$ è€Œä¸æ˜¯å…¶ä»–ç³»æ•°ï¼Ÿè¿™æ˜¯ä¸ºäº†ä¿æŒä¿¡å·çš„æœŸæœ›èƒ½é‡ï¼š</p>
            <div class="math-block">
                $$\mathbb{E}[\|\mathbf{x}_t\|^2 | \mathbf{x}_{t-1}] = (1-\beta_t)\|\mathbf{x}_{t-1}\|^2 + \beta_t \cdot d$$
            </div>
            <p>å…¶ä¸­ $d$ æ˜¯æ•°æ®ç»´åº¦ã€‚å½“ $\beta_t$ å¾ˆå°æ—¶ï¼Œä¿¡å·èƒ½é‡è¿‘ä¼¼ä¿æŒä¸å˜ã€‚</p>
        </div>
        
        <p>è®©æˆ‘ä»¬éªŒè¯è¿™ä¸ªæ€§è´¨ï¼š</p>
        
        <div class="code-block">
<pre>import torch
import matplotlib.pyplot as plt

# éªŒè¯èƒ½é‡ä¿æŒæ€§è´¨
x_0 = torch.randn(1000, 3, 32, 32)  # 1000ä¸ª32x32çš„RGBå›¾åƒ
beta = 0.02  # å…¸å‹çš„betaå€¼

# ä¸€æ­¥å‰å‘è¿‡ç¨‹
noise = torch.randn_like(x_0)
x_1 = torch.sqrt(1 - beta) * x_0 + torch.sqrt(beta) * noise

print(f"åŸå§‹ä¿¡å·èƒ½é‡: {x_0.pow(2).mean():.4f}")
print(f"æ‰©æ•£åä¿¡å·èƒ½é‡: {x_1.pow(2).mean():.4f}")
print(f"ç†è®ºé¢„æœŸ: {(1-beta)*x_0.pow(2).mean() + beta*3*32*32:.4f}")</pre>
        </div>
        
        <h3>3.2.2 é‡å‚æ•°åŒ–æŠ€å·§</h3>
        
        <p>DDPMçš„ä¸€ä¸ªå…³é”®æŠ€å·§æ˜¯ï¼šæˆ‘ä»¬å¯ä»¥ç›´æ¥ä» $\mathbf{x}_0$ é‡‡æ ·ä»»æ„æ—¶åˆ»çš„ $\mathbf{x}_t$ï¼Œè€Œä¸éœ€è¦é€æ­¥æ¨¡æ‹Ÿæ•´ä¸ªé©¬å°”å¯å¤«é“¾ã€‚</p>
        
        <div class="definition">
            <div class="definition-title">å®šç†ï¼šé—­å¼é‡‡æ ·å…¬å¼</div>
            <p>å®šä¹‰ $\alpha_t = 1 - \beta_t$ å’Œ $\bar{\alpha}_t = \prod_{s=1}^{t}\alpha_s$ï¼Œåˆ™ï¼š</p>
            <div class="math-block">
                $$q(\mathbf{x}_t|\mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t}\mathbf{x}_0, (1-\bar{\alpha}_t)\mathbf{I})$$
            </div>
        </div>
        
        <p><strong>è¯æ˜</strong>ï¼ˆè¿™ä¸ªè¯æ˜å¾ˆé‡è¦ï¼Œå€¼å¾—ä»”ç»†ç†è§£ï¼‰ï¼š</p>
        
        <div class="math-block">
            <p>æˆ‘ä»¬ç”¨å½’çº³æ³•è¯æ˜ã€‚</p>
            <p><strong>åŸºç¡€æƒ…å†µ</strong>ï¼ˆ$t=1$ï¼‰ï¼šæ˜¾ç„¶æˆç«‹ï¼Œå› ä¸º $\bar{\alpha}_1 = \alpha_1 = 1 - \beta_1$ã€‚</p>
            
            <p><strong>å½’çº³æ­¥éª¤</strong>ï¼šå‡è®¾å¯¹ $t-1$ æˆç«‹ï¼Œå³ï¼š</p>
            $$\mathbf{x}_{t-1} = \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_{t-1}}\boldsymbol{\epsilon}_{t-1}$$
            
            <p>å…¶ä¸­ $\boldsymbol{\epsilon}_{t-1} \sim \mathcal{N}(0, \mathbf{I})$ã€‚æ ¹æ®å‰å‘è¿‡ç¨‹å®šä¹‰ï¼š</p>
            $$\mathbf{x}_t = \sqrt{\alpha_t}\mathbf{x}_{t-1} + \sqrt{1-\alpha_t}\boldsymbol{\epsilon}_t$$
            
            <p>ä»£å…¥ $\mathbf{x}_{t-1}$ çš„è¡¨è¾¾å¼ï¼š</p>
            $$\mathbf{x}_t = \sqrt{\alpha_t}(\sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_{t-1}}\boldsymbol{\epsilon}_{t-1}) + \sqrt{1-\alpha_t}\boldsymbol{\epsilon}_t$$
            
            $$= \sqrt{\alpha_t\bar{\alpha}_{t-1}}\mathbf{x}_0 + \sqrt{\alpha_t(1-\bar{\alpha}_{t-1})}\boldsymbol{\epsilon}_{t-1} + \sqrt{1-\alpha_t}\boldsymbol{\epsilon}_t$$
            
            <p>æ³¨æ„åˆ° $\alpha_t\bar{\alpha}_{t-1} = \bar{\alpha}_t$ï¼Œä¸”ä¸¤ä¸ªç‹¬ç«‹é«˜æ–¯å™ªå£°çš„çº¿æ€§ç»„åˆä»æ˜¯é«˜æ–¯å™ªå£°ï¼š</p>
            $$\text{Var}[\sqrt{\alpha_t(1-\bar{\alpha}_{t-1})}\boldsymbol{\epsilon}_{t-1} + \sqrt{1-\alpha_t}\boldsymbol{\epsilon}_t] = \alpha_t(1-\bar{\alpha}_{t-1}) + (1-\alpha_t) = 1-\bar{\alpha}_t$$
            
            <p>å› æ­¤ï¼š</p>
            $$\mathbf{x}_t = \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}$$
            
            <p>å…¶ä¸­ $\boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})$ã€‚è¯æ¯•ã€‚</p>
        </div>
        
        <h3>3.2.3 å™ªå£°è°ƒåº¦çš„è®¾è®¡</h3>
        
        <p>å™ªå£°è°ƒåº¦ $\{\beta_t\}_{t=1}^T$ çš„é€‰æ‹©å¯¹æ¨¡å‹æ€§èƒ½æœ‰é‡è¦å½±å“ã€‚DDPMåŸæ–‡ä½¿ç”¨çº¿æ€§è°ƒåº¦ï¼Œä½†åç»­ç ”ç©¶å‘ç°å…¶ä»–è°ƒåº¦å¯èƒ½æ›´ä¼˜ã€‚</p>
        
        <div class="code-block">
<pre>import numpy as np
import matplotlib.pyplot as plt

def linear_beta_schedule(timesteps, beta_start=0.0001, beta_end=0.02):
    """DDPMåŸå§‹çš„çº¿æ€§è°ƒåº¦"""
    return np.linspace(beta_start, beta_end, timesteps)

def cosine_beta_schedule(timesteps, s=0.008):
    """Improved DDPMçš„ä½™å¼¦è°ƒåº¦"""
    steps = timesteps + 1
    t = np.linspace(0, timesteps, steps)
    alphas_cumprod = np.cos(((t / timesteps) + s) / (1 + s) * np.pi * 0.5) ** 2
    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]
    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])
    return np.clip(betas, 0.0001, 0.9999)

def quadratic_beta_schedule(timesteps, beta_start=0.0001, beta_end=0.02):
    """äºŒæ¬¡è°ƒåº¦ï¼ˆè¾ƒå°‘ä½¿ç”¨ï¼‰"""
    t = np.linspace(0, 1, timesteps)
    return beta_start + (beta_end - beta_start) * t ** 2

# å¯è§†åŒ–ä¸åŒè°ƒåº¦
timesteps = 1000
linear_betas = linear_beta_schedule(timesteps)
cosine_betas = cosine_beta_schedule(timesteps)
quadratic_betas = quadratic_beta_schedule(timesteps)

# è®¡ç®—ä¿¡å™ªæ¯”ï¼ˆæ›´ç›´è§‚çš„æŒ‡æ ‡ï¼‰
def compute_snr(betas):
    alphas = 1 - betas
    alphas_cumprod = np.cumprod(alphas)
    return alphas_cumprod / (1 - alphas_cumprod)

plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.plot(linear_betas, label='Linear')
plt.plot(cosine_betas, label='Cosine')
plt.plot(quadratic_betas, label='Quadratic')
plt.xlabel('Timestep')
plt.ylabel('Î²_t')
plt.title('Beta Schedules')
plt.legend()

plt.subplot(1, 3, 2)
plt.semilogy(compute_snr(linear_betas), label='Linear')
plt.semilogy(compute_snr(cosine_betas), label='Cosine')
plt.semilogy(compute_snr(quadratic_betas), label='Quadratic')
plt.xlabel('Timestep')
plt.ylabel('SNR (log scale)')
plt.title('Signal-to-Noise Ratio')
plt.legend()

plt.subplot(1, 3, 3)
# å±•ç¤ºä¸åŒè°ƒåº¦ä¸‹çš„æ ·æœ¬
alphas_cumprod_linear = np.cumprod(1 - linear_betas)
alphas_cumprod_cosine = np.cumprod(1 - cosine_betas)

t_vis = [0, 250, 500, 750, 999]
for i, t in enumerate(t_vis):
    plt.scatter(i, alphas_cumprod_linear[t], color='blue', s=100)
    plt.scatter(i, alphas_cumprod_cosine[t], color='red', s=100)
    
plt.xlabel('Visualization Step')
plt.ylabel('âˆš(á¾±_t)')
plt.title('Signal Preservation at Key Steps')
plt.legend(['Linear', 'Cosine'])
plt.tight_layout()
plt.show()</pre>
        </div>
        
        <div class="definition">
            <div class="definition-title">è°ƒåº¦ç­–ç•¥å¯¹æ¯”</div>
            <table style="width: 100%; margin-top: 10px;">
                <tr>
                    <th style="padding: 10px; background-color: #f0f0f0;">è°ƒåº¦ç±»å‹</th>
                    <th style="padding: 10px; background-color: #f0f0f0;">ç‰¹ç‚¹</th>
                    <th style="padding: 10px; background-color: #f0f0f0;">ä¼˜åŠ¿</th>
                    <th style="padding: 10px; background-color: #f0f0f0;">åŠ£åŠ¿</th>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">çº¿æ€§ (Linear)</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">Î²çº¿æ€§å¢é•¿</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">ç®€å•ç›´è§‚</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">å‰æœŸç ´åè¿‡å¿«</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">ä½™å¼¦ (Cosine)</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">åŸºäºSNRè®¾è®¡</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">æ›´å¥½çš„æ„ŸçŸ¥è´¨é‡</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">æœ«æœŸå¯èƒ½è¿‡æ…¢</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">äºŒæ¬¡ (Quadratic)</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">Î²äºŒæ¬¡å¢é•¿</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">å‰æœŸä¿ç•™æ›´å¤šä¿¡æ¯</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">åæœŸå¯èƒ½å¤ªæ¿€è¿›</td>
                </tr>
            </table>
        </div>
        
        <div class="exercise">
            <div class="exercise-title">ç»ƒä¹  3.2ï¼šå®ç°è‡ªå®šä¹‰å™ªå£°è°ƒåº¦</div>
            <p>è®¾è®¡ä¸€ä¸ª"Så½¢"å™ªå£°è°ƒåº¦ï¼Œä½¿å¾—ï¼š</p>
            <ol>
                <li>å‰æœŸï¼ˆt < 200ï¼‰ï¼šç¼“æ…¢æ·»åŠ å™ªå£°ï¼Œä¿ç•™æ›´å¤šç»“æ„ä¿¡æ¯</li>
                <li>ä¸­æœŸï¼ˆ200 â‰¤ t â‰¤ 800ï¼‰ï¼šå¿«é€Ÿæ·»åŠ å™ªå£°</li>
                <li>åæœŸï¼ˆt > 800ï¼‰ï¼šå†æ¬¡æ”¾ç¼“ï¼Œç¡®ä¿æ”¶æ•›åˆ°çº¯å™ªå£°</li>
            </ol>
            <p>å®ç°è¿™ä¸ªè°ƒåº¦å¹¶ä¸æ ‡å‡†è°ƒåº¦å¯¹æ¯”SNRæ›²çº¿ã€‚</p>
            <button class="answer-toggle" onclick="toggleAnswer('answer3_2')">æ˜¾ç¤ºç­”æ¡ˆ</button>
            <div id="answer3_2" class="answer">
                <pre>def sigmoid_beta_schedule(timesteps, beta_start=0.0001, beta_end=0.02):
    """Så½¢å™ªå£°è°ƒåº¦"""
    t = np.linspace(-6, 6, timesteps)
    sigmoid = 1 / (1 + np.exp(-t))
    betas = beta_start + (beta_end - beta_start) * sigmoid
    return betas

# ä¹Ÿå¯ä»¥åˆ†æ®µè®¾è®¡
def piecewise_beta_schedule(timesteps, beta_start=0.0001, beta_end=0.02):
    """åˆ†æ®µå™ªå£°è°ƒåº¦"""
    betas = np.zeros(timesteps)
    
    # å‰æœŸï¼šç¼“æ…¢å¢é•¿
    t1 = int(0.2 * timesteps)
    betas[:t1] = np.linspace(beta_start, beta_start * 5, t1)
    
    # ä¸­æœŸï¼šå¿«é€Ÿå¢é•¿
    t2 = int(0.8 * timesteps)
    betas[t1:t2] = np.linspace(beta_start * 5, beta_end * 0.8, t2 - t1)
    
    # åæœŸï¼šç¼“æ…¢å¢é•¿åˆ°beta_end
    betas[t2:] = np.linspace(beta_end * 0.8, beta_end, timesteps - t2)
    
    return betas</pre>
                <p><strong>å…³é”®æ´å¯Ÿ</strong>ï¼šå¥½çš„å™ªå£°è°ƒåº¦åº”è¯¥åœ¨ä¿ç•™è¶³å¤Ÿä¿¡æ¯å’Œå……åˆ†æ¢ç´¢å™ªå£°ç©ºé—´ä¹‹é—´å–å¾—å¹³è¡¡ã€‚ä½™å¼¦è°ƒåº¦ä¹‹æ‰€ä»¥ä¼˜äºçº¿æ€§è°ƒåº¦ï¼Œæ­£æ˜¯å› ä¸ºå®ƒæ›´å¥½åœ°å¹³è¡¡äº†è¿™ä¸¤ä¸ªéœ€æ±‚ã€‚</p>
            </div>
        </div>
        
        <h2>3.3 åå‘è¿‡ç¨‹ï¼šä»å™ªå£°åˆ°å›¾åƒ</h2>
        
        <p>åå‘è¿‡ç¨‹æ˜¯æ‰©æ•£æ¨¡å‹çš„æ ¸å¿ƒâ€”â€”å¦‚ä½•ä»çº¯å™ªå£°é€æ­¥æ¢å¤å‡ºæ¸…æ™°çš„æ•°æ®ã€‚DDPMçš„å…³é”®è´¡çŒ®ä¹‹ä¸€æ˜¯æ¨å¯¼å‡ºäº†åœ¨å·²çŸ¥ $\mathbf{x}_0$ æ—¶çš„åå‘æ¡ä»¶åˆ†å¸ƒçš„é—­å¼è§£ã€‚</p>
        
        <h3>3.3.1 åå‘æ¡ä»¶æ¦‚ç‡çš„æ¨å¯¼</h3>
        
        <p>è¿™æ˜¯DDPMä¸­æœ€é‡è¦çš„æ•°å­¦æ¨å¯¼ä¹‹ä¸€ã€‚æˆ‘ä»¬æƒ³è¦è®¡ç®— $q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)$ã€‚</p>
        
        <div class="definition">
            <div class="definition-title">å®šç†ï¼šåå‘è¿‡ç¨‹çš„åéªŒåˆ†å¸ƒ</div>
            <p>ç»™å®š $\mathbf{x}_t$ å’Œ $\mathbf{x}_0$ï¼Œåå‘è¿‡ç¨‹çš„åéªŒåˆ†å¸ƒä¸ºï¼š</p>
            <div class="math-block">
                $$q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1}; \tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0), \tilde{\beta}_t\mathbf{I})$$
            </div>
            <p>å…¶ä¸­ï¼š</p>
            <div class="math-block">
                $$\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0) = \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\mathbf{x}_0 + \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\mathbf{x}_t$$
                
                $$\tilde{\beta}_t = \frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_t}\beta_t$$
            </div>
        </div>
        
        <p><strong>è¯æ˜</strong>ï¼šä½¿ç”¨è´å¶æ–¯å®šç†ï¼š</p>
        
        <div class="math-block">
            $$q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) = \frac{q(\mathbf{x}_t|\mathbf{x}_{t-1}, \mathbf{x}_0)q(\mathbf{x}_{t-1}|\mathbf{x}_0)}{q(\mathbf{x}_t|\mathbf{x}_0)}$$
        </div>
        
        <p>ç”±äºå‰å‘è¿‡ç¨‹çš„é©¬å°”å¯å¤«æ€§è´¨ï¼Œ$q(\mathbf{x}_t|\mathbf{x}_{t-1}, \mathbf{x}_0) = q(\mathbf{x}_t|\mathbf{x}_{t-1})$ã€‚ç°åœ¨æˆ‘ä»¬çŸ¥é“ï¼š</p>
        
        <ul>
            <li>$q(\mathbf{x}_t|\mathbf{x}_{t-1}) = \mathcal{N}(\mathbf{x}_t; \sqrt{\alpha_t}\mathbf{x}_{t-1}, \beta_t\mathbf{I})$</li>
            <li>$q(\mathbf{x}_{t-1}|\mathbf{x}_0) = \mathcal{N}(\mathbf{x}_{t-1}; \sqrt{\bar{\alpha}_{t-1}}\mathbf{x}_0, (1-\bar{\alpha}_{t-1})\mathbf{I})$</li>
            <li>$q(\mathbf{x}_t|\mathbf{x}_0) = \mathcal{N}(\mathbf{x}_t; \sqrt{\bar{\alpha}_t}\mathbf{x}_0, (1-\bar{\alpha}_t)\mathbf{I})$</li>
        </ul>
        
        <p>å°†ä¸‰ä¸ªé«˜æ–¯åˆ†å¸ƒä»£å…¥è´å¶æ–¯å…¬å¼ï¼Œç»è¿‡ç¹çä½†ç›´æ¥çš„ä»£æ•°è¿ç®—ï¼ˆä¸»è¦æ˜¯é…æ–¹ï¼‰ï¼Œå¯ä»¥å¾—åˆ°ä¸Šè¿°ç»“æœã€‚</p>
        
        <div class="visualization" style="background-color: #f8f9fa; padding: 20px; margin: 20px 0; border-radius: 8px;">
            <h4>ğŸ’¡ å…³é”®æ´å¯Ÿ</h4>
            <p>æ³¨æ„ $\tilde{\boldsymbol{\mu}}_t$ æ˜¯ $\mathbf{x}_0$ å’Œ $\mathbf{x}_t$ çš„<strong>çº¿æ€§ç»„åˆ</strong>ï¼è¿™æ„å‘³ç€ï¼š</p>
            <ul>
                <li>å¦‚æœæˆ‘ä»¬çŸ¥é“ $\mathbf{x}_0$ï¼Œåå‘è¿‡ç¨‹å°±æ˜¯ç¡®å®šçš„ï¼ˆé™¤äº†å°çš„é«˜æ–¯å™ªå£°ï¼‰</li>
                <li>å®è·µä¸­æˆ‘ä»¬ä¸çŸ¥é“ $\mathbf{x}_0$ï¼Œæ‰€ä»¥éœ€è¦ç¥ç»ç½‘ç»œæ¥é¢„æµ‹å®ƒ</li>
                <li>è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆæ‰©æ•£æ¨¡å‹æœ¬è´¨ä¸Šæ˜¯åœ¨å­¦ä¹ "å»å™ª"</li>
            </ul>
        </div>
        
        <h3>3.3.2 å‚æ•°åŒ–é€‰æ‹©ï¼šé¢„æµ‹å™ªå£° vs é¢„æµ‹å‡å€¼</h3>
        
        <p>æ—¢ç„¶ $\tilde{\boldsymbol{\mu}}_t$ ä¾èµ–äºæœªçŸ¥çš„ $\mathbf{x}_0$ï¼Œæˆ‘ä»¬éœ€è¦ç”¨ç¥ç»ç½‘ç»œæ¥è¿‘ä¼¼å®ƒã€‚DDPMæä¾›äº†å‡ ç§å‚æ•°åŒ–æ–¹å¼ï¼š</p>
        
        <div class="code-block">
<pre># æ–¹å¼1ï¼šç›´æ¥é¢„æµ‹å‡å€¼ï¼ˆæœ€ç›´æ¥ä½†ä¸ç¨³å®šï¼‰
mu_theta = model(x_t, t)

# æ–¹å¼2ï¼šé¢„æµ‹x_0ï¼ˆéœ€è¦clipåˆ°åˆç†èŒƒå›´ï¼‰
x_0_pred = model(x_t, t)
mu_theta = (sqrt_alpha_bar_prev * beta_t * x_0_pred + 
            sqrt_alpha_t * (1 - alpha_bar_prev) * x_t) / (1 - alpha_bar_t)

# æ–¹å¼3ï¼šé¢„æµ‹å™ªå£°ï¼ˆDDPMçš„é€‰æ‹©ï¼Œæœ€ç¨³å®šï¼‰
epsilon_pred = model(x_t, t)
x_0_pred = (x_t - sqrt_one_minus_alpha_bar_t * epsilon_pred) / sqrt_alpha_bar_t
mu_theta = (sqrt_alpha_bar_prev * beta_t * x_0_pred + 
            sqrt_alpha_t * (1 - alpha_bar_prev) * x_t) / (1 - alpha_bar_t)</pre>
        </div>
        
        <p>ä¸ºä»€ä¹ˆé¢„æµ‹å™ªå£°æ›´å¥½ï¼Ÿè®©æˆ‘ä»¬é€šè¿‡é‡å‚æ•°åŒ–æ¥ç†è§£ï¼š</p>
        
        <div class="math-block">
            <p>ç”±äº $\mathbf{x}_t = \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}$ï¼Œæˆ‘ä»¬å¯ä»¥è¡¨ç¤ºï¼š</p>
            $$\mathbf{x}_0 = \frac{\mathbf{x}_t - \sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}}{\sqrt{\bar{\alpha}_t}}$$
            
            <p>ä»£å…¥ $\tilde{\boldsymbol{\mu}}_t$ çš„è¡¨è¾¾å¼ï¼Œç»è¿‡åŒ–ç®€å¯å¾—ï¼š</p>
            $$\tilde{\boldsymbol{\mu}}_t = \frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}\right)$$
        </div>
        
        <p>è¿™ä¸ªè¡¨è¾¾å¼æ­ç¤ºäº†ä¸€ä¸ªä¼˜é›…çš„äº‹å®ï¼š<strong>åå‘è¿‡ç¨‹çš„å‡å€¼åªéœ€è¦çŸ¥é“æ·»åŠ çš„å™ªå£° $\boldsymbol{\epsilon}$ï¼</strong></p>
        
        <div class="definition">
            <div class="definition-title">ä¸‰ç§å‚æ•°åŒ–çš„å¯¹æ¯”</div>
            <table style="width: 100%; margin-top: 10px;">
                <tr>
                    <th style="padding: 10px; background-color: #f0f0f0;">å‚æ•°åŒ–</th>
                    <th style="padding: 10px; background-color: #f0f0f0;">ä¼˜ç‚¹</th>
                    <th style="padding: 10px; background-color: #f0f0f0;">ç¼ºç‚¹</th>
                    <th style="padding: 10px; background-color: #f0f0f0;">ä½¿ç”¨åœºæ™¯</th>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">é¢„æµ‹ $\boldsymbol{\mu}_\theta$</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">ç›´æ¥ï¼Œæ— éœ€è½¬æ¢</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">ä¸åŒtçš„è¾“å‡ºå°ºåº¦å·®å¼‚å¤§</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">å‡ ä¹ä¸ç”¨</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">é¢„æµ‹ $\mathbf{x}_0$</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">è¯­ä¹‰æ¸…æ™°</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">é«˜å™ªå£°æ—¶é¢„æµ‹å›°éš¾</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">æŸäº›æ¡ä»¶ç”Ÿæˆä»»åŠ¡</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">é¢„æµ‹ $\boldsymbol{\epsilon}$</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">è¾“å‡ºæ ‡å‡†åŒ–ï¼Œè®­ç»ƒç¨³å®š</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">é—´æ¥ï¼Œéœ€è¦è½¬æ¢</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">æ ‡å‡†é€‰æ‹©</td>
                </tr>
            </table>
        </div>
        
        <h3>3.3.3 æ–¹å·®çš„å¤„ç†ï¼šå›ºå®š vs å¯å­¦ä¹ </h3>
        
        <p>DDPMçš„å¦ä¸€ä¸ªç®€åŒ–æ˜¯ä½¿ç”¨å›ºå®šçš„æ–¹å·® $\tilde{\beta}_t$ã€‚ä½†è¿™æ˜¯æœ€ä¼˜çš„å—ï¼Ÿ</p>
        
        <div class="code-block">
<pre># DDPMï¼šå›ºå®šæ–¹å·®ï¼ˆä¸¤ç§é€‰æ‹©ï¼‰
# é€‰æ‹©1ï¼šä½¿ç”¨åéªŒæ–¹å·®
variance = (1 - alpha_bar_prev) / (1 - alpha_bar_t) * beta_t

# é€‰æ‹©2ï¼šä½¿ç”¨Î²_tï¼ˆDDPMè®ºæ–‡çš„é€‰æ‹©ï¼‰
variance = beta_t

# æ”¹è¿›çš„DDPMï¼šå­¦ä¹ æ–¹å·®
# ç½‘ç»œåŒæ—¶é¢„æµ‹å™ªå£°å’Œæ–¹å·®
epsilon_pred, v_pred = model(x_t, t).chunk(2, dim=1)

# å‚æ•°åŒ–æ–¹å·®ï¼ˆåœ¨å¯¹æ•°ç©ºé—´æ’å€¼ï¼‰
min_log = torch.log(beta_t)
max_log = torch.log((1 - alpha_bar_prev) / (1 - alpha_bar_t) * beta_t)
log_variance = v_pred * max_log + (1 - v_pred) * min_log
variance = torch.exp(log_variance)</pre>
        </div>
        
        <div class="visualization" style="background-color: #fff3cd; padding: 20px; margin: 20px 0; border-radius: 8px;">
            <h4>âš ï¸ å®è·µç»éªŒ</h4>
            <p>å°½ç®¡å­¦ä¹ æ–¹å·®ç†è®ºä¸Šæ›´ä¼˜ï¼ˆå¯ä»¥è·å¾—æ›´å¥½çš„ä¼¼ç„¶ï¼‰ï¼Œä½†åœ¨å®è·µä¸­ï¼š</p>
            <ul>
                <li>å›ºå®šæ–¹å·®çš„DDPMå·²ç»èƒ½ç”Ÿæˆé«˜è´¨é‡å›¾åƒ</li>
                <li>å­¦ä¹ æ–¹å·®å¢åŠ äº†è®­ç»ƒçš„å¤æ‚åº¦</li>
                <li>å¯¹äºå¤§å¤šæ•°åº”ç”¨ï¼Œå›ºå®šæ–¹å·®æ˜¯è¶³å¤Ÿçš„</li>
                <li>å¦‚æœè¿½æ±‚æœ€ä¼˜ä¼¼ç„¶ï¼ˆå¦‚å‹ç¼©ä»»åŠ¡ï¼‰ï¼Œæ‰è€ƒè™‘å­¦ä¹ æ–¹å·®</li>
            </ul>
        </div>
        
        <div class="exercise">
            <div class="exercise-title">ç»ƒä¹  3.3ï¼šéªŒè¯ä¸åŒå‚æ•°åŒ–çš„ç­‰ä»·æ€§</div>
            <p>å®ç°ä¸‰ç§å‚æ•°åŒ–æ–¹å¼ï¼ŒéªŒè¯å®ƒä»¬åœ¨æ•°å­¦ä¸Šæ˜¯ç­‰ä»·çš„ï¼š</p>
            <ol>
                <li>ç»™å®šç›¸åŒçš„ $\mathbf{x}_t$ã€$\mathbf{x}_0$ å’Œ $t$</li>
                <li>è®¡ç®—çœŸå®çš„å™ªå£° $\boldsymbol{\epsilon}$</li>
                <li>ç”¨ä¸‰ç§æ–¹å¼è®¡ç®— $\tilde{\boldsymbol{\mu}}_t$</li>
                <li>éªŒè¯ç»“æœç›¸åŒï¼ˆåœ¨æ•°å€¼ç²¾åº¦å†…ï¼‰</li>
            </ol>
            <button class="answer-toggle" onclick="toggleAnswer('answer3_3')">æ˜¾ç¤ºç­”æ¡ˆ</button>
            <div id="answer3_3" class="answer">
                <pre>import torch

# è®¾ç½®
batch_size = 4
channels = 3
size = 32
t = 500
T = 1000

# åˆå§‹åŒ–
x_0 = torch.randn(batch_size, channels, size, size)
epsilon = torch.randn_like(x_0)

# è®¡ç®—alphaç›¸å…³å€¼
betas = torch.linspace(0.0001, 0.02, T)
alphas = 1 - betas
alphas_bar = torch.cumprod(alphas, dim=0)
alpha_t = alphas[t]
alpha_bar_t = alphas_bar[t]
alpha_bar_prev = alphas_bar[t-1]
beta_t = betas[t]

# å‰å‘è¿‡ç¨‹
x_t = torch.sqrt(alpha_bar_t) * x_0 + torch.sqrt(1 - alpha_bar_t) * epsilon

# æ–¹å¼1ï¼šç›´æ¥è®¡ç®—çœŸå®çš„åéªŒå‡å€¼
mu_true = (torch.sqrt(alpha_bar_prev) * beta_t * x_0 + 
           torch.sqrt(alpha_t) * (1 - alpha_bar_prev) * x_t) / (1 - alpha_bar_t)

# æ–¹å¼2ï¼šé€šè¿‡é¢„æµ‹x_0
x_0_pred = x_0  # å‡è®¾å®Œç¾é¢„æµ‹
mu_x0 = (torch.sqrt(alpha_bar_prev) * beta_t * x_0_pred + 
         torch.sqrt(alpha_t) * (1 - alpha_bar_prev) * x_t) / (1 - alpha_bar_t)

# æ–¹å¼3ï¼šé€šè¿‡é¢„æµ‹å™ªå£°
epsilon_pred = epsilon  # å‡è®¾å®Œç¾é¢„æµ‹
x_0_from_eps = (x_t - torch.sqrt(1 - alpha_bar_t) * epsilon_pred) / torch.sqrt(alpha_bar_t)
mu_eps = (torch.sqrt(alpha_bar_prev) * beta_t * x_0_from_eps + 
          torch.sqrt(alpha_t) * (1 - alpha_bar_prev) * x_t) / (1 - alpha_bar_t)

# æˆ–è€…ç›´æ¥ç”¨ç®€åŒ–å…¬å¼
mu_eps_direct = (x_t - beta_t / torch.sqrt(1 - alpha_bar_t) * epsilon_pred) / torch.sqrt(alpha_t)

# éªŒè¯
print(f"æ–¹å¼1å’Œæ–¹å¼2çš„å·®å¼‚: {(mu_true - mu_x0).abs().max():.6f}")
print(f"æ–¹å¼1å’Œæ–¹å¼3çš„å·®å¼‚: {(mu_true - mu_eps).abs().max():.6f}")
print(f"æ–¹å¼1å’Œæ–¹å¼3(ç›´æ¥)çš„å·®å¼‚: {(mu_true - mu_eps_direct).abs().max():.6f}")

# è¾“å‡ºåº”è¯¥éƒ½æ¥è¿‘0ï¼ˆåœ¨æµ®ç‚¹ç²¾åº¦èŒƒå›´å†…ï¼‰</pre>
                <p><strong>å…³é”®æ´å¯Ÿ</strong>ï¼šä¸‰ç§å‚æ•°åŒ–åœ¨æ•°å­¦ä¸Šç­‰ä»·ï¼Œä½†è®­ç»ƒåŠ¨æ€ä¸åŒã€‚é¢„æµ‹å™ªå£°ä¹‹æ‰€ä»¥æ›´ç¨³å®šï¼Œæ˜¯å› ä¸ºå™ªå£° $\boldsymbol{\epsilon} \sim \mathcal{N}(0, \mathbf{I})$ å§‹ç»ˆæ˜¯æ ‡å‡†åŒ–çš„ï¼Œè€Œ $\mathbf{x}_0$ çš„åˆ†å¸ƒå¯èƒ½å¾ˆå¤æ‚ã€‚</p>
            </div>
        </div>
        
        <h2>3.4 è®­ç»ƒç›®æ ‡ï¼šå˜åˆ†ä¸‹ç•Œçš„ç®€åŒ–</h2>
        
        <p>DDPMçš„å¦ä¸€ä¸ªé‡è¦è´¡çŒ®æ˜¯å°†å¤æ‚çš„å˜åˆ†ä¸‹ç•Œï¼ˆELBOï¼‰ç®€åŒ–ä¸ºä¸€ä¸ªç®€å•çš„å»å™ªç›®æ ‡ã€‚è¿™ä¸€èŠ‚æˆ‘ä»¬å°†è¯¦ç»†æ¨å¯¼è¿™ä¸ªè¿‡ç¨‹ã€‚</p>
        
        <h3>3.4.1 å®Œæ•´çš„å˜åˆ†ä¸‹ç•Œ</h3>
        
        <p>æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–æ•°æ®çš„å¯¹æ•°ä¼¼ç„¶ $\log p_\theta(\mathbf{x}_0)$ã€‚ç”±äºç›´æ¥è®¡ç®—å›°éš¾ï¼Œæˆ‘ä»¬ä¼˜åŒ–å…¶å˜åˆ†ä¸‹ç•Œï¼š</p>
        
        <div class="math-block">
            $$\log p_\theta(\mathbf{x}_0) \geq \mathbb{E}_q\left[\log \frac{p_\theta(\mathbf{x}_{0:T})}{q(\mathbf{x}_{1:T}|\mathbf{x}_0)}\right] = -L_{\text{VLB}}$$
        </div>
        
        <p>å…¶ä¸­ $L_{\text{VLB}}$ æ˜¯å˜åˆ†ä¸‹ç•ŒæŸå¤±ã€‚ç»è¿‡å±•å¼€ï¼ˆä½¿ç”¨é©¬å°”å¯å¤«æ€§è´¨ï¼‰ï¼Œå¯ä»¥å¾—åˆ°ï¼š</p>
        
        <div class="math-block">
            $$L_{\text{VLB}} = L_T + \sum_{t=2}^{T} L_{t-1} + L_0$$
        </div>
        
        <p>å…¶ä¸­å„é¡¹å®šä¹‰ä¸ºï¼š</p>
        
        <div class="definition">
            <div class="definition-title">å˜åˆ†ä¸‹ç•Œçš„ä¸‰ä¸ªç»„æˆéƒ¨åˆ†</div>
            <div class="math-block">
                $$L_T = D_{\text{KL}}(q(\mathbf{x}_T|\mathbf{x}_0) \| p(\mathbf{x}_T))$$
                $$L_{t-1} = \mathbb{E}_q\left[D_{\text{KL}}(q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) \| p_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t))\right]$$
                $$L_0 = \mathbb{E}_q\left[-\log p_\theta(\mathbf{x}_0|\mathbf{x}_1)\right]$$
            </div>
            <ul>
                <li>$L_T$ï¼šå…ˆéªŒåŒ¹é…é¡¹ï¼Œé€šå¸¸å¾ˆå°å¯ä»¥å¿½ç•¥ï¼ˆå› ä¸º $q(\mathbf{x}_T|\mathbf{x}_0) \approx \mathcal{N}(0, \mathbf{I})$ï¼‰</li>
                <li>$L_{t-1}$ï¼šå»å™ªåŒ¹é…é¡¹ï¼Œè¿™æ˜¯ä¸»è¦çš„ä¼˜åŒ–ç›®æ ‡</li>
                <li>$L_0$ï¼šé‡å»ºé¡¹ï¼Œå†³å®šæœ€ç»ˆè¾“å‡ºè´¨é‡</li>
            </ul>
        </div>
        
        <p>å…³é”®åœ¨äºå¦‚ä½•å¤„ç† $L_{t-1}$ é¡¹ã€‚ç”±äºæˆ‘ä»¬çŸ¥é“ $q(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)$ çš„é—­å¼è§£ï¼ˆè§3.3.1èŠ‚ï¼‰ï¼Œä¸”å‡è®¾ $p_\theta$ ä¹Ÿæ˜¯é«˜æ–¯åˆ†å¸ƒï¼ŒKLæ•£åº¦å¯ä»¥ç®€åŒ–ä¸ºï¼š</p>
        
        <div class="math-block">
            $$L_{t-1} = \mathbb{E}_q\left[\frac{1}{2\sigma_t^2}\|\tilde{\boldsymbol{\mu}}_t(\mathbf{x}_t, \mathbf{x}_0) - \boldsymbol{\mu}_\theta(\mathbf{x}_t, t)\|^2\right] + C$$
        </div>
        
        <p>å…¶ä¸­ $C$ æ˜¯ä¸ $\theta$ æ— å…³çš„å¸¸æ•°ã€‚</p>
        
        <h3>3.4.2 ç®€åŒ–çš„å»å™ªç›®æ ‡</h3>
        
        <p>DDPMçš„å…³é”®æ´å¯Ÿæ˜¯ï¼šé€šè¿‡é€‰æ‹©å™ªå£°é¢„æµ‹å‚æ•°åŒ–ï¼Œå¯ä»¥å°†ä¸Šè¿°ç›®æ ‡è¿›ä¸€æ­¥ç®€åŒ–ã€‚å›å¿†3.3.2èŠ‚çš„ç»“æœï¼š</p>
        
        <div class="math-block">
            $$\tilde{\boldsymbol{\mu}}_t = \frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}\right)$$
        </div>
        
        <p>å¦‚æœæˆ‘ä»¬å‚æ•°åŒ– $\boldsymbol{\mu}_\theta$ ä¸ºï¼š</p>
        
        <div class="math-block">
            $$\boldsymbol{\mu}_\theta(\mathbf{x}_t, t) = \frac{1}{\sqrt{\alpha_t}}\left(\mathbf{x}_t - \frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\right)$$
        </div>
        
        <p>é‚£ä¹ˆ $L_{t-1}$ å¯ä»¥ç®€åŒ–ä¸ºï¼š</p>
        
        <div class="math-block">
            $$L_{t-1} = \mathbb{E}_{\mathbf{x}_0, \boldsymbol{\epsilon}}\left[\frac{\beta_t^2}{2\sigma_t^2\alpha_t(1-\bar{\alpha}_t)}\|\boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2\right]$$
        </div>
        
        <p>å…¶ä¸­ $\mathbf{x}_t = \sqrt{\bar{\alpha}_t}\mathbf{x}_0 + \sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}$ã€‚</p>
        
        <div class="visualization" style="background-color: #e8f4fd; padding: 20px; margin: 20px 0; border-radius: 8px;">
            <h4>ğŸ¯ DDPMçš„ç®€åŒ–è®­ç»ƒç›®æ ‡</h4>
            <p>Hoç­‰äººå‘ç°ï¼Œå¿½ç•¥æƒé‡ç³»æ•°å¹¶å¯¹æ‰€æœ‰æ—¶é—´æ­¥æ±‚å’Œï¼Œå¾—åˆ°çš„ç®€åŒ–ç›®æ ‡æ•ˆæœæ›´å¥½ï¼š</p>
            <div class="math-block">
                $$L_{\text{simple}} = \mathbb{E}_{t,\mathbf{x}_0,\boldsymbol{\epsilon}}\left[\|\boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta(\mathbf{x}_t, t)\|^2\right]$$
            </div>
            <p>è¿™å°±æ˜¯è‘—åçš„"ç®€å•æŸå¤±"â€”â€”åªéœ€è¦é¢„æµ‹å™ªå£°ï¼</p>
        </div>
        
        <h3>3.4.3 æŸå¤±å‡½æ•°çš„åŠ æƒç­–ç•¥</h3>
        
        <p>è™½ç„¶ç®€å•æŸå¤±æ•ˆæœå¾ˆå¥½ï¼Œä½†ä¸åŒæ—¶é—´æ­¥çš„é‡è¦æ€§ç¡®å®ä¸åŒã€‚åç»­ç ”ç©¶æå‡ºäº†å„ç§åŠ æƒç­–ç•¥ï¼š</p>
        
        <div class="code-block">
<pre>import torch
import matplotlib.pyplot as plt

# ä¸åŒçš„æŸå¤±åŠ æƒç­–ç•¥
def get_loss_weight(t, strategy='simple', snr_gamma=5.0):
    """
    è®¡ç®—æ—¶é—´æ­¥tçš„æŸå¤±æƒé‡
    
    ç­–ç•¥:
    - simple: æ‰€æœ‰æ—¶é—´æ­¥æƒé‡ç›¸åŒï¼ˆDDPMåŸå§‹ï¼‰
    - snr: åŸºäºä¿¡å™ªæ¯”çš„åŠ æƒ
    - truncated_snr: æˆªæ–­çš„SNRåŠ æƒï¼ˆé˜²æ­¢æç«¯å€¼ï¼‰
    - importance: åŸºäºé‡è¦æ€§é‡‡æ ·
    """
    if strategy == 'simple':
        return 1.0
    
    elif strategy == 'snr':
        # æƒé‡ä¸ä¿¡å™ªæ¯”æˆåæ¯”
        snr = alpha_bar[t] / (1 - alpha_bar[t])
        return 1.0 / (1.0 + snr)
    
    elif strategy == 'truncated_snr':
        # Min-SNR-Î³ åŠ æƒï¼ˆHang et al., 2023ï¼‰
        snr = alpha_bar[t] / (1 - alpha_bar[t])
        return torch.minimum(snr, torch.tensor(snr_gamma)) / snr
    
    elif strategy == 'importance':
        # åŸºäºL_tç³»æ•°çš„é‡è¦æ€§åŠ æƒ
        return beta[t]**2 / (2 * sigma[t]**2 * alpha[t] * (1 - alpha_bar[t]))

# å¯è§†åŒ–ä¸åŒåŠ æƒç­–ç•¥
T = 1000
t = torch.arange(T)
beta = torch.linspace(0.0001, 0.02, T)
alpha = 1 - beta
alpha_bar = torch.cumprod(alpha, dim=0)
sigma = beta  # DDPMçš„é€‰æ‹©

plt.figure(figsize=(12, 6))

strategies = ['simple', 'snr', 'truncated_snr', 'importance']
for strategy in strategies:
    weights = torch.tensor([get_loss_weight(i, strategy) for i in range(T)])
    plt.plot(weights, label=strategy)

plt.xlabel('Time Step t')
plt.ylabel('Loss Weight')
plt.title('Different Loss Weighting Strategies')
plt.legend()
plt.yscale('log')
plt.grid(True, alpha=0.3)
plt.show()</pre>
        </div>
        
        <div class="definition">
            <div class="definition-title">åŠ æƒç­–ç•¥å¯¹æ¯”</div>
            <table style="width: 100%; margin-top: 10px;">
                <tr>
                    <th style="padding: 10px; background-color: #f0f0f0;">ç­–ç•¥</th>
                    <th style="padding: 10px; background-color: #f0f0f0;">åŠ¨æœº</th>
                    <th style="padding: 10px; background-color: #f0f0f0;">æ•ˆæœ</th>
                    <th style="padding: 10px; background-color: #f0f0f0;">è®¡ç®—å¼€é”€</th>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">ç®€å• (Simple)</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">ç®€åŒ–è®­ç»ƒ</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">åŸºå‡†ï¼Œæ•ˆæœå·²ç»ä¸é”™</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">æœ€ä½</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">SNRåŠ æƒ</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">å¹³è¡¡ä¸åŒå™ªå£°æ°´å¹³</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">æ”¹å–„é«˜å™ªå£°åŒºåŸŸ</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">ä½</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">Min-SNR-Î³</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">é¿å…æç«¯æƒé‡</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">ç›®å‰æœ€ä¼˜</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">ä½</td>
                </tr>
                <tr>
                    <td style="padding: 10px; border: 1px solid #ddd;">é‡è¦æ€§é‡‡æ ·</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">ç†è®ºæœ€ä¼˜</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">å®è·µä¸­ä¸ç¨³å®š</td>
                    <td style="padding: 10px; border: 1px solid #ddd;">ä¸­ç­‰</td>
                </tr>
            </table>
        </div>
        
        <h3>3.4.4 è®­ç»ƒç®—æ³•æ€»ç»“</h3>
        
        <p>ç»¼åˆä»¥ä¸Šæ¨å¯¼ï¼ŒDDPMçš„è®­ç»ƒç®—æ³•æå…¶ç®€æ´ï¼š</p>
        
        <div class="code-block">
<pre>def train_ddpm(model, dataloader, num_epochs, T=1000):
    """DDPMè®­ç»ƒå¾ªç¯"""
    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)
    
    # é¢„è®¡ç®—å™ªå£°è°ƒåº¦ç›¸å…³å€¼
    betas = linear_beta_schedule(T)
    alphas = 1 - betas
    alphas_bar = torch.cumprod(alphas, dim=0)
    sqrt_alphas_bar = torch.sqrt(alphas_bar)
    sqrt_one_minus_alphas_bar = torch.sqrt(1 - alphas_bar)
    
    for epoch in range(num_epochs):
        for batch_idx, (x_0, _) in enumerate(dataloader):
            batch_size = x_0.shape[0]
            
            # éšæœºé‡‡æ ·æ—¶é—´æ­¥
            t = torch.randint(0, T, (batch_size,), device=x_0.device)
            
            # é‡‡æ ·å™ªå£°
            epsilon = torch.randn_like(x_0)
            
            # å‰å‘æ‰©æ•£ï¼šè®¡ç®—x_t
            x_t = (sqrt_alphas_bar[t, None, None, None] * x_0 + 
                   sqrt_one_minus_alphas_bar[t, None, None, None] * epsilon)
            
            # é¢„æµ‹å™ªå£°
            epsilon_pred = model(x_t, t)
            
            # è®¡ç®—æŸå¤±
            loss = F.mse_loss(epsilon_pred, epsilon)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            if batch_idx % 100 == 0:
                print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}')</pre>
        </div>
        
        <div class="exercise">
            <div class="exercise-title">ç»ƒä¹  3.4ï¼šå®ç°åŠ æƒæŸå¤±</div>
            <p>ä¿®æ”¹ä¸Šè¿°è®­ç»ƒä»£ç ï¼Œå®ç°Min-SNR-Î³åŠ æƒç­–ç•¥ï¼š</p>
            <ol>
                <li>è®¡ç®—æ¯ä¸ªæ—¶é—´æ­¥çš„SNR</li>
                <li>åº”ç”¨Min-SNR-Î³åŠ æƒï¼ˆå»ºè®®Î³=5ï¼‰</li>
                <li>æ¯”è¾ƒåŠ æƒå‰åçš„è®­ç»ƒæ›²çº¿</li>
            </ol>
            <button class="answer-toggle" onclick="toggleAnswer('answer3_4')">æ˜¾ç¤ºç­”æ¡ˆ</button>
            <div id="answer3_4" class="answer">
                <pre>def train_ddpm_weighted(model, dataloader, num_epochs, T=1000, snr_gamma=5.0):
    """å¸¦Min-SNRåŠ æƒçš„DDPMè®­ç»ƒ"""
    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)
    
    # é¢„è®¡ç®—
    betas = linear_beta_schedule(T)
    alphas = 1 - betas
    alphas_bar = torch.cumprod(alphas, dim=0)
    sqrt_alphas_bar = torch.sqrt(alphas_bar)
    sqrt_one_minus_alphas_bar = torch.sqrt(1 - alphas_bar)
    
    # é¢„è®¡ç®—SNRå’Œæƒé‡
    snr = alphas_bar / (1 - alphas_bar)
    snr_clipped = torch.minimum(snr, torch.tensor(snr_gamma))
    loss_weights = snr_clipped / snr
    
    for epoch in range(num_epochs):
        for batch_idx, (x_0, _) in enumerate(dataloader):
            batch_size = x_0.shape[0]
            
            # é‡‡æ ·æ—¶é—´æ­¥
            t = torch.randint(0, T, (batch_size,), device=x_0.device)
            
            # å‰å‘æ‰©æ•£
            epsilon = torch.randn_like(x_0)
            x_t = (sqrt_alphas_bar[t, None, None, None] * x_0 + 
                   sqrt_one_minus_alphas_bar[t, None, None, None] * epsilon)
            
            # é¢„æµ‹å™ªå£°
            epsilon_pred = model(x_t, t)
            
            # è®¡ç®—åŠ æƒæŸå¤±
            mse_loss = (epsilon_pred - epsilon).pow(2).mean(dim=[1,2,3])
            weights = loss_weights[t]
            loss = (weights * mse_loss).mean()
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

# å…³é”®æ”¹è¿›ï¼š
# 1. é«˜SNRï¼ˆä½å™ªå£°ï¼‰åŒºåŸŸçš„æƒé‡è¢«é™ä½ï¼Œé¿å…è¿‡æ‹Ÿåˆç»†èŠ‚
# 2. ä½SNRï¼ˆé«˜å™ªå£°ï¼‰åŒºåŸŸä¿æŒè¾ƒé«˜æƒé‡ï¼Œç¡®ä¿ç»“æ„å­¦ä¹ 
# 3. Î³å‚æ•°æ§åˆ¶æˆªæ–­ç¨‹åº¦ï¼Œé€šå¸¸5-10æ•ˆæœè¾ƒå¥½</pre>
                <p><strong>å®è·µå»ºè®®</strong>ï¼šMin-SNR-Î³åŠ æƒåœ¨é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆä¸­ç‰¹åˆ«æœ‰æ•ˆï¼Œå¯ä»¥æ˜¾è‘—æ”¹å–„ç”Ÿæˆè´¨é‡ã€‚ä½†å¯¹äºä½åˆ†è¾¨ç‡æˆ–ç®€å•æ•°æ®é›†ï¼Œç®€å•æŸå¤±å¯èƒ½å·²ç»è¶³å¤Ÿã€‚</p>
            </div>
        </div>
        
        <h2>3.5 é‡‡æ ·ç®—æ³•ï¼šä»ç†è®ºåˆ°å®è·µ</h2>
        <h3>3.5.1 æ ‡å‡†DDPMé‡‡æ ·</h3>
        <p>[å¾…å®Œæˆï¼š1000æ­¥é‡‡æ ·çš„å®ç°]</p>
        
        <h3>3.5.2 é‡‡æ ·çš„éšæœºæ€§æ§åˆ¶</h3>
        <p>[å¾…å®Œæˆï¼šæ¸©åº¦å‚æ•°çš„ä½œç”¨]</p>
        
        <h3>3.5.3 å¸¸è§é—®é¢˜ä¸è°ƒè¯•æŠ€å·§</h3>
        <p>[å¾…å®Œæˆï¼šé‡‡æ ·è¿‡ç¨‹çš„å¯è§†åŒ–ä¸é—®é¢˜è¯Šæ–­]</p>
        
        <h2>3.6 å®Œæ•´å®ç°ï¼šæ„å»ºä½ çš„ç¬¬ä¸€ä¸ªDDPM</h2>
        <h3>3.6.1 æ¨¡å‹æ¶æ„</h3>
        <p>[å¾…å®Œæˆï¼šç»“åˆç¬¬2ç« çš„U-Netå®ç°DDPM]</p>
        
        <h3>3.6.2 è®­ç»ƒå¾ªç¯</h3>
        <p>[å¾…å®Œæˆï¼šå®Œæ•´çš„è®­ç»ƒä»£ç ]</p>
        
        <h3>3.6.3 è¯„ä¼°ä¸å¯è§†åŒ–</h3>
        <p>[å¾…å®Œæˆï¼šFIDã€ISç­‰æŒ‡æ ‡çš„è®¡ç®—]</p>
        
        <h2>3.7 DDPMçš„å±€é™æ€§ä¸æ”¹è¿›æ–¹å‘</h2>
        <p>[å¾…å®Œæˆï¼šé‡‡æ ·é€Ÿåº¦æ…¢ã€æ–¹å·®å›ºå®šç­‰é—®é¢˜ï¼Œå¼•å‡ºåç»­ç« èŠ‚]</p>
        
        <div class="chapter-summary">
            <h2>æœ¬ç« å°ç»“</h2>
            <p>[å¾…å®Œæˆï¼šæ€»ç»“DDPMçš„å…³é”®è´¡çŒ®ï¼Œé¢„å‘ŠDDIMç­‰æ”¹è¿›æ–¹æ³•]</p>
        </div>
    </div>
</body>
</html>